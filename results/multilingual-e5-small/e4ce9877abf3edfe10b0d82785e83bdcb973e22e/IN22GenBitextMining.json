{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 24.44619107246399,
  "kg_co2_emissions": 0.0007696366564434083,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.4521484375,
        "f1": 0.3946444920479847,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.3946444920479847,
        "precision": 0.3746796384382476,
        "recall": 0.4521484375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.016862302449388845,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.016862302449388845,
        "precision": 0.01401462432654232,
        "recall": 0.0302734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8634440104166667,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.8634440104166667,
        "precision": 0.84912109375,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8305989583333333,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.8305989583333333,
        "precision": 0.8160319010416667,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9037760416666667,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.9037760416666667,
        "precision": 0.8944010416666666,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92470703125,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.92470703125,
        "precision": 0.9165852864583334,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007969121807012432,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.007969121807012432,
        "precision": 0.005811373556542142,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9816080729166667,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9816080729166667,
        "precision": 0.9798177083333333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.3278135111458871,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3278135111458871,
        "precision": 0.32143793066072945,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.25926737007499057,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.25926737007499057,
        "precision": 0.2506453368663808,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.29405629509025866,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.29405629509025866,
        "precision": 0.2852989619905571,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.015325372793483272,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.015325372793483272,
        "precision": 0.013447304377480158,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.31033107979180025,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.31033107979180025,
        "precision": 0.304443958751186,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.3447265625,
        "f1": 0.3095142540364885,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3095142540364885,
        "precision": 0.29972102667607914,
        "recall": 0.3447265625
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.25329562364718616,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.25329562364718616,
        "precision": 0.2473604183997397,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.380859375,
        "f1": 0.3426709734556701,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3426709734556701,
        "precision": 0.3325791028626848,
        "recall": 0.380859375
      },
      {
        "accuracy": 0.328125,
        "f1": 0.30042612149007186,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.30042612149007186,
        "precision": 0.29322551852817436,
        "recall": 0.328125
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.42981068410755907,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.42981068410755907,
        "precision": 0.4140811615367398,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.3176291300636177,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3176291300636177,
        "precision": 0.30812528378793935,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3806853140349234,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3806853140349234,
        "precision": 0.3714205449007276,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.34253036709091395,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.34253036709091395,
        "precision": 0.33336087356318633,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.3210069037187503,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3210069037187503,
        "precision": 0.3134018121436187,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.40178608767719826,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40178608767719826,
        "precision": 0.388848472623892,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.0072049307263449295,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0072049307263449295,
        "precision": 0.00555177154362268,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.32681468918529066,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.32681468918529066,
        "precision": 0.31599148832374424,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.3681640625,
        "f1": 0.33392885528595445,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.33392885528595445,
        "precision": 0.323891137978052,
        "recall": 0.3681640625
      },
      {
        "accuracy": 0.4140625,
        "f1": 0.36033126295936496,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.36033126295936496,
        "precision": 0.34410295348302683,
        "recall": 0.4140625
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.3214280846147595,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3214280846147595,
        "precision": 0.31227284378782133,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.3154296875,
        "f1": 0.2887833823679634,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2887833823679634,
        "precision": 0.282018923103649,
        "recall": 0.3154296875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013294463581385503,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.013294463581385503,
        "precision": 0.01121557024661919,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8732096354166665,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8732096354166665,
        "precision": 0.8605143229166666,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8781575520833333,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8781575520833333,
        "precision": 0.866162109375,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9296875,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9296875,
        "precision": 0.9215494791666667,
        "recall": 0.9462890625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9588216145833333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9588216145833333,
        "precision": 0.9541015625,
        "recall": 0.96875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0065629703778588375,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0065629703778588375,
        "precision": 0.004857389157390599,
        "recall": 0.01953125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833334,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9793294270833334,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010459271938852599,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.010459271938852599,
        "precision": 0.008760864371790383,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.9202473958333333,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9202473958333333,
        "precision": 0.9109700520833333,
        "recall": 0.939453125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8654622395833333,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8654622395833333,
        "precision": 0.8533365885416667,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9138997395833333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.9138997395833333,
        "precision": 0.9049479166666666,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9436848958333333,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9436848958333333,
        "precision": 0.9375,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.007203927389127519,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007203927389127519,
        "precision": 0.005619064324113727,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.97607421875,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.97607421875,
        "precision": 0.9734700520833333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01689741636287689,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.01689741636287689,
        "precision": 0.015096870488069939,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.85595703125,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.85595703125,
        "precision": 0.8415039062499999,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.7965169270833333,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7965169270833333,
        "precision": 0.7812174479166667,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8985677083333333,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.8985677083333333,
        "precision": 0.88818359375,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.91943359375,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.91943359375,
        "precision": 0.9104817708333334,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.010795512585015045,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.010795512585015045,
        "precision": 0.008624532919304696,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9658203125,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9658203125,
        "precision": 0.9620768229166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007018209807056248,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.007018209807056248,
        "precision": 0.006030662337044675,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006495221038726997,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.006495221038726997,
        "precision": 0.005953211812897119,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023664699528464653,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0023664699528464653,
        "precision": 0.001855453459600978,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010658214811265066,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.010658214811265066,
        "precision": 0.009664756647731202,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004931211274005653,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.004931211274005653,
        "precision": 0.003956571686358638,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006066778865319746,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.006066778865319746,
        "precision": 0.004959189370427352,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005679418021761501,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.005679418021761501,
        "precision": 0.004629574407182274,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007070743805069236,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007070743805069236,
        "precision": 0.005978376487077147,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.005528449069124664,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005528449069124664,
        "precision": 0.004651936690891809,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006612425886531905,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.006612425886531905,
        "precision": 0.0049965030037103335,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004183098727743936,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.004183098727743936,
        "precision": 0.0036858995997451367,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06631846004236225,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06631846004236225,
        "precision": 0.05773383421878367,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008051586806420844,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.008051586806420844,
        "precision": 0.006969986010734876,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007835640804305141,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.007835640804305141,
        "precision": 0.006698903595195655,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007204595735947772,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.007204595735947772,
        "precision": 0.005447328102311967,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004323770365183301,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004323770365183301,
        "precision": 0.0037478170211332727,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.002041140187261753,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.002041140187261753,
        "precision": 0.0012594300031082573,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8728515625,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.8728515625,
        "precision": 0.861328125,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876302083333333,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9876302083333333,
        "precision": 0.986328125,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8407877604166667,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.8407877604166667,
        "precision": 0.8262044270833333,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9111328125,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.9111328125,
        "precision": 0.9013671875,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.931640625,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.931640625,
        "precision": 0.92431640625,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01181206683657664,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.01181206683657664,
        "precision": 0.009610055769716179,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.9801432291666667,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8761067708333333,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.8761067708333333,
        "precision": 0.8639322916666667,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8349283854166667,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.8349283854166667,
        "precision": 0.8203450520833333,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9326171875,
        "f1": 0.9136393229166666,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.9136393229166666,
        "precision": 0.905029296875,
        "recall": 0.9326171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9317057291666666,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.9317057291666666,
        "precision": 0.9247233072916666,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.009299935828028728,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.009299935828028728,
        "precision": 0.006972945132124819,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.97705078125,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.97705078125,
        "precision": 0.9744466145833334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8078636532738095,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.8078636532738095,
        "precision": 0.7901041666666667,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.974609375,
        "precision": 0.9718424479166667,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8232770647321428,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8232770647321428,
        "precision": 0.8088743179563491,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166667,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9806315104166667,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8846540178571428,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8846540178571428,
        "precision": 0.8740234375,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9327473958333333,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9327473958333333,
        "precision": 0.9254557291666667,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0005297146953282064,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0005297146953282064,
        "precision": 0.000277790539657005,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9399088541666667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9399088541666667,
        "precision": 0.9332682291666666,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8095912388392857,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8095912388392857,
        "precision": 0.7965010737959957,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6902886284722222,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.6902886284722222,
        "precision": 0.6721218532986111,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8464192708333333,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8464192708333333,
        "precision": 0.8338541666666666,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7118492266197345,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.7118492266197345,
        "precision": 0.694922297754329,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8576915922619047,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8576915922619047,
        "precision": 0.8466796875,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8465657552083332,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8465657552083332,
        "precision": 0.8352794828869048,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.752099609375,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.752099609375,
        "precision": 0.7336681547619047,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.010873335632785312,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.010873335632785312,
        "precision": 0.008214021121992956,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8432779947916667,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8432779947916667,
        "precision": 0.8315848214285715,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8491117931547618,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8491117931547618,
        "precision": 0.8380316840277777,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7747531467013888,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7747531467013888,
        "precision": 0.7582763671875,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8610374813988095,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8610374813988095,
        "precision": 0.8492117745535714,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8536280776515152,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8536280776515152,
        "precision": 0.8414062499999999,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8034830729166667,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.8034830729166667,
        "precision": 0.7864583333333334,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8763020833333334,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.8763020833333334,
        "precision": 0.8653157552083334,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9024088541666666,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.9024088541666666,
        "precision": 0.8931477864583334,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.0097961461888981,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0097961461888981,
        "precision": 0.008037668375696992,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.97802734375,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.97802734375,
        "precision": 0.9754231770833333,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9464518229166666,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.9464518229166666,
        "precision": 0.9404296875,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7653075529454205,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7653075529454205,
        "precision": 0.7539339932528408,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7549068390376984,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7549068390376984,
        "precision": 0.7425304594494048,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.805287458851912,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.805287458851912,
        "precision": 0.7950396825396826,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7701466393849206,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7701466393849206,
        "precision": 0.7587463155334249,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8218284970238096,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8218284970238096,
        "precision": 0.8082194010416667,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011552411361596189,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.011552411361596189,
        "precision": 0.008615292971670541,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8266499613667583,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8266499613667583,
        "precision": 0.8144047196293289,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.798018656148539,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.798018656148539,
        "precision": 0.7855987437042125,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7790884571158009,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.7790884571158009,
        "precision": 0.7645554315476191,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8049818996108058,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8049818996108058,
        "precision": 0.7940789841668748,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7782630997474747,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7782630997474747,
        "precision": 0.7659285583314765,
        "recall": 0.8125
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8963216145833333,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8963216145833333,
        "precision": 0.8864908854166667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.99267578125,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.99267578125,
        "precision": 0.9920247395833334,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9036458333333333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9036458333333333,
        "precision": 0.8932291666666666,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.008614736254795507,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008614736254795507,
        "precision": 0.006290704052508969,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833333,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9949544270833333,
        "precision": 0.9944661458333334,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9560546875,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9560546875,
        "precision": 0.9508463541666667,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.89716796875,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.89716796875,
        "precision": 0.8878092447916667,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8675618489583332,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8675618489583332,
        "precision": 0.8567313058035715,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.846484375,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.846484375,
        "precision": 0.8330403645833333,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.008065679031255202,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008065679031255202,
        "precision": 0.006287143671499167,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9013695126488095,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9013695126488095,
        "precision": 0.8930757068452381,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8808326863354037,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8808326863354037,
        "precision": 0.8738399621212121,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8377197265625,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8377197265625,
        "precision": 0.8256068638392856,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9136579241071429,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9136579241071429,
        "precision": 0.9069986979166667,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8758734809027777,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8758734809027777,
        "precision": 0.8663504464285714,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9514973958333333,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9514973958333333,
        "precision": 0.9462890625,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.006648672681043489,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006648672681043489,
        "precision": 0.004604471254012694,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9125000000000001,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.9125000000000001,
        "precision": 0.903564453125,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.004470033680169081,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004470033680169081,
        "precision": 0.00307254469521062,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166667,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.9689127604166667,
        "precision": 0.9651692708333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008461740275067707,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008461740275067707,
        "precision": 0.006164354424621315,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9397786458333334,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9397786458333334,
        "precision": 0.9336263020833333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9054998224431818,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9054998224431818,
        "precision": 0.8983077144209957,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.86435546875,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.86435546875,
        "precision": 0.8520833333333333,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9173874627976191,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9173874627976191,
        "precision": 0.9098958333333333,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.913090587797619,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.913090587797619,
        "precision": 0.9063096788194445,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005916021574636346,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.005916021574636346,
        "precision": 0.0055048838540351155,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007430855404087556,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.007430855404087556,
        "precision": 0.0067755864681054035,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007348820000400719,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.007348820000400719,
        "precision": 0.0067170040570576055,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005028025343270523,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.005028025343270523,
        "precision": 0.004602144433081291,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.007053786406288562,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.007053786406288562,
        "precision": 0.005894581210019506,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9758138020833333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9758138020833333,
        "precision": 0.9732259114583333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.99755859375,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.99755859375,
        "precision": 0.9973958333333333,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9627278645833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9627278645833333,
        "precision": 0.95849609375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9593098958333334,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9593098958333334,
        "precision": 0.9549153645833333,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}