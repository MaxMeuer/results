{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 9.879918336868286,
  "kg_co2_emissions": 0.00040196275568184616,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.0078125,
        "f1": 0.0006866613526158317,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0006866613526158317,
        "precision": 0.00037712106810425803,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023198911513994613,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0023198911513994613,
        "precision": 0.002149563019842548,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007512543630017452,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0007512543630017452,
        "precision": 0.00044270587696261434,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009290805137844611,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0009290805137844611,
        "precision": 0.0005428538602941177,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08061252170138888,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.08061252170138888,
        "precision": 0.07216674655639499,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09204042294000934,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.09204042294000934,
        "precision": 0.08104939629597832,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.08295636310773029,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.08295636310773029,
        "precision": 0.07250452205029739,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002434675556077694,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0002434675556077694,
        "precision": 0.0001287476629273504,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014995050395968323,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0014995050395968323,
        "precision": 0.0012814376876876877,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.02747765743371212,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.02747765743371212,
        "precision": 0.022501198002154582,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030208710124707177,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0030208710124707177,
        "precision": 0.0026986806341126194,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.037633274456181e-05,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 7.037633274456181e-05,
        "precision": 3.568212469809291e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0006163575250311277,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0006163575250311277,
        "precision": 0.0003498577654078416,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025898813263348468,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0025898813263348468,
        "precision": 0.0020029250454916816,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.0578834874977453,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.0578834874977453,
        "precision": 0.04988451760912698,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002051946011180649,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.002051946011180649,
        "precision": 0.0016385775320199958,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05309631116701066,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.05309631116701066,
        "precision": 0.046161454376786405,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012269189242419942,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0012269189242419942,
        "precision": 0.0011078430995984923,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010162594944032992,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0010162594944032992,
        "precision": 0.000996780403700363,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013870295022622855,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0013870295022622855,
        "precision": 0.0012306591553734965,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002603298131550401,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.002603298131550401,
        "precision": 0.002308829196201638,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.11045386904761904,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.11045386904761904,
        "precision": 0.09740925392909357,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.251953125,
        "f1": 0.22250837869413112,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22250837869413112,
        "precision": 0.2118978921469156,
        "recall": 0.251953125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07441909327651515,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.07441909327651515,
        "precision": 0.0675690223255552,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11313835490882865,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11313835490882865,
        "precision": 0.10348116192788612,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002325923859126984,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002325923859126984,
        "precision": 0.0018529412096949102,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11836382617420321,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11836382617420321,
        "precision": 0.11014557071075626,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003071446572580645,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0003071446572580645,
        "precision": 0.0001720610119047619,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010503584489346372,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.010503584489346372,
        "precision": 0.009076757073443412,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.0575980967743061,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0575980967743061,
        "precision": 0.04968744970681259,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.12418208845174308,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12418208845174308,
        "precision": 0.11852330222649457,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.234375,
        "f1": 0.20636738478535355,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.20636738478535355,
        "precision": 0.19678589567281937,
        "recall": 0.234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000568908658958001,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.000568908658958001,
        "precision": 0.00032485369372569175,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.21937703680867746,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.21937703680867746,
        "precision": 0.21120105209460677,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04063389581224697,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04063389581224697,
        "precision": 0.035107457104527416,
        "recall": 0.0625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09243575158601286,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09243575158601286,
        "precision": 0.08463549676748688,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.2568359375,
        "f1": 0.2335432525373931,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2335432525373931,
        "precision": 0.22535707108030176,
        "recall": 0.2568359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009881771286035057,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009881771286035057,
        "precision": 0.0009823902811680269,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05340180388404804,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05340180388404804,
        "precision": 0.04813194821266814,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.994120654396728e-06,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 3.994120654396728e-06,
        "precision": 2.0011526639344263e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.038346193423633594,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.038346193423633594,
        "precision": 0.03421531649668573,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.043434278395215895,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.043434278395215895,
        "precision": 0.03786562872320479,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.015604018669890087,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015604018669890087,
        "precision": 0.012883155165870009,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.0777361621231191,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0777361621231191,
        "precision": 0.06957422661211704,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11012567077020202,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11012567077020202,
        "precision": 0.10135348135964913,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012621787524131273,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0012621787524131273,
        "precision": 0.0011426332980225989,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.10130661225990958,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10130661225990958,
        "precision": 0.0930587898971688,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016149894212698639,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0016149894212698639,
        "precision": 0.0013468252500704425,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005827832173398835,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005827832173398835,
        "precision": 0.004423863271090255,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.049533023673739934,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.049533023673739934,
        "precision": 0.041740184247830915,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.09791536564155448,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.09791536564155448,
        "precision": 0.09255605917197185,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.373046875,
        "f1": 0.32674836082602127,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.32674836082602127,
        "precision": 0.3118842759345689,
        "recall": 0.373046875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.6613961813842484e-06,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 4.6613961813842484e-06,
        "precision": 2.336273923444976e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.3310546875,
        "f1": 0.29475566872108694,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.29475566872108694,
        "precision": 0.2828549029880859,
        "recall": 0.3310546875
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.19522033955627704,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.19522033955627704,
        "precision": 0.1783141121031746,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08799041904510654,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08799041904510654,
        "precision": 0.0810166327339865,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4161630253427129,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4161630253427129,
        "precision": 0.3958685140814047,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0021125873766447366,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0021125873766447366,
        "precision": 0.002039128124555088,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.2977216224530677,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2977216224530677,
        "precision": 0.27930015469026026,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009820954320113315,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0009820954320113315,
        "precision": 0.000979336825284091,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05366671093611867,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.05366671093611867,
        "precision": 0.0480249694073798,
        "recall": 0.078125
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.13396506921897547,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.13396506921897547,
        "precision": 0.12159629735441824,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015707384869585086,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015707384869585086,
        "precision": 0.012763936744234981,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07250958676739926,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.07250958676739926,
        "precision": 0.065159208865838,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08701847911089275,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08701847911089275,
        "precision": 0.07936828184141831,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.0080128205128203e-05,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 5.0080128205128203e-05,
        "precision": 2.5699013157894735e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.013414417613636364,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.013414417613636364,
        "precision": 0.011700383126845699,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.2243668005045405,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.2243668005045405,
        "precision": 0.2102503687909823,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.09617865536037501,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.09617865536037501,
        "precision": 0.08889343923296503,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11495426457213143,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.11495426457213143,
        "precision": 0.10859943877437815,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010190217391304348,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010190217391304348,
        "precision": 0.0009982638888888888,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.10956000643500644,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.10956000643500644,
        "precision": 0.10306877367424241,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020231341694538617,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0020231341694538617,
        "precision": 0.001988583519345238,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.04972489883737585,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.04972489883737585,
        "precision": 0.043185989577116,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12951050685425686,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.12951050685425686,
        "precision": 0.12186841207837301,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009790761743886745,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0009790761743886745,
        "precision": 0.000977820956829897,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000858233468066104,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.000858233468066104,
        "precision": 0.0006008913982259571,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00032033137077294683,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.00032033137077294683,
        "precision": 0.00017630718329253366,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002957393061216335,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002957393061216335,
        "precision": 0.0026181390467939366,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004957932692307692,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0004957932692307692,
        "precision": 0.0002712673611111111,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.010770816910953628,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.010770816910953628,
        "precision": 0.008441732802490574,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011314227343249656,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.011314227343249656,
        "precision": 0.010149784026737151,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.15942571323414173,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.15942571323414173,
        "precision": 0.1539394996279762,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.012644934275793652,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.012644934275793652,
        "precision": 0.011749136351080984,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.016222912932268154,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.016222912932268154,
        "precision": 0.014491344045209176,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04655955481150793,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.04655955481150793,
        "precision": 0.042067050245761184,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.14432198660714285,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.14432198660714285,
        "precision": 0.13810961174242425,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.085102998550257,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.085102998550257,
        "precision": 0.07938965789901739,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001956702152014652,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.001956702152014652,
        "precision": 0.0015480158161314983,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09069569696418878,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.09069569696418878,
        "precision": 0.08423188383881744,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004979212724715995,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.004979212724715995,
        "precision": 0.004625608842797795,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.13001172908399472,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.13001172908399472,
        "precision": 0.12225191641527175,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11088751132484667,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.11088751132484667,
        "precision": 0.10425995270650584,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008507649034992786,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.008507649034992786,
        "precision": 0.007543915545799105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002706166510164672,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.002706166510164672,
        "precision": 0.0024164542799395877,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0021183830189684567,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0021183830189684567,
        "precision": 0.00204315380921895,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0033824209870445894,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0033824209870445894,
        "precision": 0.003167866217843917,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0026073727598601637,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0026073727598601637,
        "precision": 0.0023036198625542735,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.033406558262643785,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.033406558262643785,
        "precision": 0.02726934523809524,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.049529335418007296,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.049529335418007296,
        "precision": 0.043892131480135654,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.05124895685118305,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.05124895685118305,
        "precision": 0.044135682195395945,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.3445966607546936e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 3.3445966607546936e-05,
        "precision": 1.689176051518168e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0537592008412197e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 2.0537592008412197e-06,
        "precision": 1.0279605263157895e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.037730201475318664,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.037730201475318664,
        "precision": 0.0313882569253663,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006905266498459411,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006905266498459411,
        "precision": 0.000508367778125401,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007066805589615405,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0007066805589615405,
        "precision": 0.0005163658785305328,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001651549635312005,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001651549635312005,
        "precision": 0.0014768762039462525,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004441704063909501,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0004441704063909501,
        "precision": 0.00025646751804516777,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.027881898646058802,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.027881898646058802,
        "precision": 0.023339532567644247,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001017585503501115,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.001017585503501115,
        "precision": 0.000997331503381115,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.08193119125736312,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.08193119125736312,
        "precision": 0.0736086353922666,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00207155986639825,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00207155986639825,
        "precision": 0.0020139283823372212,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011146357171583669,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0011146357171583669,
        "precision": 0.0010497176203756997,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0008122281899279896,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008122281899279896,
        "precision": 0.0005054083163925874,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00224095750004475,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.00224095750004475,
        "precision": 0.0021088118848258475,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.09532430460164834,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.09532430460164834,
        "precision": 0.08533171821623342,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03612239987707039,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.03612239987707039,
        "precision": 0.030603538171897548,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.026106398847041336,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.026106398847041336,
        "precision": 0.023999916583351016,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02896103627792325,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.02896103627792325,
        "precision": 0.02655227607301741,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.20255354996565933,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.20255354996565933,
        "precision": 0.19385381456961492,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.045180444779174114,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.045180444779174114,
        "precision": 0.03903982308813546,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.145585317460317e-06,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 9.145585317460317e-06,
        "precision": 4.583898698143699e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06337297394090333,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.06337297394090333,
        "precision": 0.05862448403850863,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021410870295698927,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.00021410870295698927,
        "precision": 0.00011347541207247981,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.18800455729166665,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.18800455729166665,
        "precision": 0.17605836546266235,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07462434107082712,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.07462434107082712,
        "precision": 0.06823353076175823,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.036319669913419915,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.036319669913419915,
        "precision": 0.03182234974227162,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00024379293919670673,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.00024379293919670673,
        "precision": 0.00012688871678078476,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.041953058397272e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 4.041953058397272e-05,
        "precision": 2.0593886017410228e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003950017507002801,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0003950017507002801,
        "precision": 0.0002232142857142857,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017248674337692824,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0017248674337692824,
        "precision": 0.0014409816167628667,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.08553390320106773,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08553390320106773,
        "precision": 0.07316354523863441,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.685141509433962e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 3.685141509433962e-05,
        "precision": 1.8780048076923078e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.621305418719212e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 9.621305418719212e-06,
        "precision": 4.834467821782178e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.015208300086358269,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.015208300086358269,
        "precision": 0.01242497503234186,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002104804686143522,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.002104804686143522,
        "precision": 0.0014779468957117643,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006628903166615741,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0006628903166615741,
        "precision": 0.000494229187347893,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011343741314309172,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0011343741314309172,
        "precision": 0.0010608852542446292,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016790364583333334,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0016790364583333334,
        "precision": 0.0010433932427580208,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.02371201864483051,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.02371201864483051,
        "precision": 0.020060669381852296,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012316025733773407,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0012316025733773407,
        "precision": 0.0007489112780971691,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03882145224056988,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.03882145224056988,
        "precision": 0.03367996856945903,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003703515663456336,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0003703515663456336,
        "precision": 0.00019675812997882482,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010519628366712707,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0010519628366712707,
        "precision": 0.0010149726005637882,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0015868767799216313,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0015868767799216313,
        "precision": 0.0011284934988647175,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026319775001924393,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0026319775001924393,
        "precision": 0.0023780112882509034,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07681987552952052,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.07681987552952052,
        "precision": 0.0683093030453949,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.020156531881962966,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.020156531881962966,
        "precision": 0.015223024753165473,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.05165401341391141,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.05165401341391141,
        "precision": 0.041658833387152046,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032516830118205164,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.032516830118205164,
        "precision": 0.027277375944368132,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00014787946428571427,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.00014787946428571427,
        "precision": 7.685908564814814e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03130287952065296,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.03130287952065296,
        "precision": 0.025518728547357247,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022530691964285712,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0022530691964285712,
        "precision": 0.0018283876050420168,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.03174288249117119,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.03174288249117119,
        "precision": 0.025667587800534998,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.03559629995464095,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.03559629995464095,
        "precision": 0.028009242528179348,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015766940585254538,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0015766940585254538,
        "precision": 0.0012986687243340816,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008138020833333334,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0008138020833333334,
        "precision": 0.0005011852479849468,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1945224719101123e-05,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 2.1945224719101123e-05,
        "precision": 1.1097301136363637e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004163447229853479,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.004163447229853479,
        "precision": 0.003411708733974359,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013950892857142857,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0013950892857142857,
        "precision": 0.001220703125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.0067010139228145475,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0067010139228145475,
        "precision": 0.00459292754116453,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.10970222548788575,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10970222548788575,
        "precision": 0.10280903811177247,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.10707909513525937,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.10707909513525937,
        "precision": 0.1014943386932319,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004014756944444445,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0004014756944444445,
        "precision": 0.000249596281424581,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.09920837924011751,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.09920837924011751,
        "precision": 0.09356607910950183,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010843151180926916,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0010843151180926916,
        "precision": 0.0010316664988007896,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.059715317234848485,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.059715317234848485,
        "precision": 0.053637670922827174,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.1265715270483193,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1265715270483193,
        "precision": 0.11941155726613562,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.381859756097561e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 2.381859756097561e-05,
        "precision": 1.2056327160493826e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0036845049763266713,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0036845049763266713,
        "precision": 0.003072238656415018,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000751608546875091,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.000751608546875091,
        "precision": 0.0005400422274122739,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002096015963203463,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.002096015963203463,
        "precision": 0.0020292622257236225,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001775568181818182,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0001775568181818182,
        "precision": 9.300595238095238e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011402579104680993,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.011402579104680993,
        "precision": 0.009505085000922505,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07023851120326147,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.07023851120326147,
        "precision": 0.06297890875255031,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.870826341207215e-05,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 8.870826341207215e-05,
        "precision": 4.599795338390229e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0814513563460707,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.0814513563460707,
        "precision": 0.07466952492802675,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004099219445754099,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0004099219445754099,
        "precision": 0.0002197882365640864,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.15181129092261902,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.15181129092261902,
        "precision": 0.14028320312499998,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09472376731224902,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.09472376731224902,
        "precision": 0.08634287590633258,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03393403680705005,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03393403680705005,
        "precision": 0.030040676012355695,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009500157147988506,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0009500157147988506,
        "precision": 0.0006454820774112666,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009938040967110184,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0009938040967110184,
        "precision": 0.0009852405991848366,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0014624843812576114,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0014624843812576114,
        "precision": 0.0009208355093867502,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0026396979787831646,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0026396979787831646,
        "precision": 0.0021581608495670995,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06200126085473651,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.06200126085473651,
        "precision": 0.05358448490528568,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.953694331983806e-06,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 3.953694331983806e-06,
        "precision": 1.9808569979716024e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.3076171875,
        "f1": 0.2760967651929723,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2760967651929723,
        "precision": 0.26532408787525125,
        "recall": 0.3076171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06263919186282467,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.06263919186282467,
        "precision": 0.05640380935919587,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.0926570492154391,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0926570492154391,
        "precision": 0.08494159062460135,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.337890625,
        "f1": 0.3049563576614358,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3049563576614358,
        "precision": 0.2932540034834957,
        "recall": 0.337890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000782139792438228,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000782139792438228,
        "precision": 0.0005574673651132751,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09951938469516594,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09951938469516594,
        "precision": 0.09138342126623376,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016704819732315216,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0016704819732315216,
        "precision": 0.00141068942625134,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.035547372065305,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.035547372065305,
        "precision": 0.0318620007583895,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07196775573357655,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07196775573357655,
        "precision": 0.06470717596205877,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.022730260688024362,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022730260688024362,
        "precision": 0.019543224933582515,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014677508652444385,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0014677508652444385,
        "precision": 0.001253328995231323,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013218976449275361,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0013218976449275361,
        "precision": 0.0009095893141945773,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021414040032975063,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0021414040032975063,
        "precision": 0.0017443676226897517,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010089302028138132,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0010089302028138132,
        "precision": 0.0009929824810957937,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550626240079365,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0019550626240079365,
        "precision": 0.00195409477408143,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004611545138888889,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.004611545138888889,
        "precision": 0.004060872395833333,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03035094156113044,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.03035094156113044,
        "precision": 0.026696401566036004,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024606086078939045,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0024606086078939045,
        "precision": 0.0022269477782809986,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030872955953843164,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0030872955953843164,
        "precision": 0.0027104103909512136,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003610528487616311,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.003610528487616311,
        "precision": 0.002770311052767789,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07156611437766164,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07156611437766164,
        "precision": 0.0645844959077381,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08691560970017546,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08691560970017546,
        "precision": 0.07905435286093604,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.283203125,
        "f1": 0.25029141865079363,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.25029141865079363,
        "precision": 0.2393381349191896,
        "recall": 0.283203125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012369791666666666,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0012369791666666666,
        "precision": 0.0008652001096491227,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08824788283677631,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08824788283677631,
        "precision": 0.0799877474206074,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021515376984126985,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00021515376984126985,
        "precision": 0.0001184944166048008,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.0586985175605938,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.0586985175605938,
        "precision": 0.05339444632701831,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.23991001674107143,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.23991001674107143,
        "precision": 0.2217107247136544,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.015629306890009114,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015629306890009114,
        "precision": 0.013228502093248187,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001759240544150731,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001759240544150731,
        "precision": 0.001472594246031746,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.11233764493392488,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11233764493392488,
        "precision": 0.10388844147389069,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004739413630529226,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004739413630529226,
        "precision": 0.004424222982049665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.2700490048146298,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2700490048146298,
        "precision": 0.25131994470373376,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015099770466150994,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0015099770466150994,
        "precision": 0.0010320132485508592,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.06134055314834267,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.06134055314834267,
        "precision": 0.057477072894553366,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.11698899324990777,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11698899324990777,
        "precision": 0.10871489744658798,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004033536992521367,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004033536992521367,
        "precision": 0.003973176042261565,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05926575751986543,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.05926575751986543,
        "precision": 0.05379758397055106,
        "recall": 0.078125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.022155664478464353,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.022155664478464353,
        "precision": 0.019035581389097014,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006187334191635456,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0006187334191635456,
        "precision": 0.00035638189935064936,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00013225349040139615,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.00013225349040139615,
        "precision": 7.07781147050015e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029002848245779795,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.00029002848245779795,
        "precision": 0.0001628773939674554,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00012226134585289515,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.00012226134585289515,
        "precision": 6.437082811848143e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06272730479042157,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.06272730479042157,
        "precision": 0.05422754329004329,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001725597938268049,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001725597938268049,
        "precision": 0.0015159659500539931,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.17648382274678745,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.17648382274678745,
        "precision": 0.16298865761273607,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013083034766454352,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0013083034766454352,
        "precision": 0.0011749950079872203,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.033528628033151056,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.033528628033151056,
        "precision": 0.029335108017323093,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.058323070788418564,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.058323070788418564,
        "precision": 0.05292124609076586,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014517114601407366,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.014517114601407366,
        "precision": 0.012295057362574873,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022673271261888965,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.00022673271261888965,
        "precision": 0.0001224928366559045,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024000550741129787,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0024000550741129787,
        "precision": 0.0022261942903147062,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0016375631660553065,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0016375631660553065,
        "precision": 0.0013927099573046132,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001824661779537509,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.001824661779537509,
        "precision": 0.0015683831161185666,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.06531679017356101,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.06531679017356101,
        "precision": 0.0558396221386305,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024476462659744408,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0024476462659744408,
        "precision": 0.0017934945913461538,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.0671750992063492,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.0671750992063492,
        "precision": 0.060730613138988594,
        "recall": 0.09375
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.14094377844377845,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14094377844377845,
        "precision": 0.1318691433620633,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032414648116074747,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0032414648116074747,
        "precision": 0.0025338450124430256,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.2830369015957447e-05,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 1.2830369015957447e-05,
        "precision": 6.444490271930822e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009880466805233662,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0009880466805233662,
        "precision": 0.0009823264713364995,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002559962113437329,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.002559962113437329,
        "precision": 0.0023116429809289544,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08264748489357863,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08264748489357863,
        "precision": 0.07386218924304862,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004649811050528204,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004649811050528204,
        "precision": 0.003960955244556704,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008782355339972528,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.008782355339972528,
        "precision": 0.006939529888748639,
        "recall": 0.017578125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}