{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 35.3699631690979,
  "kg_co2_emissions": 0.0019468308135882442,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.16103451143371303,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.16103451143371303,
        "precision": 0.14534419155177639,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.851053448658239,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.851053448658239,
        "precision": 0.839532047017077,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8486930900104553,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8486930900104553,
        "precision": 0.8359946773120426,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.8048791306276336,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8048791306276336,
        "precision": 0.7908848968729207,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004242800146210814,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.004242800146210814,
        "precision": 0.003408727763703319,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8559547571523619,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8559547571523619,
        "precision": 0.8439454424484364,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8527389665114214,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8527389665114214,
        "precision": 0.8419716123308938,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8299269666535135,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8299269666535135,
        "precision": 0.820333143237335,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.5748502994011976,
        "f1": 0.5163065403584366,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5163065403584366,
        "precision": 0.4941600925133859,
        "recall": 0.5748502994011976
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8209691727655799,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.8209691727655799,
        "precision": 0.8075468111396256,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5166526734890009,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.5166526734890009,
        "precision": 0.49480562684155494,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7936824763172069,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7936824763172069,
        "precision": 0.7804280328232422,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.6260811709913506,
        "f1": 0.5772047683225328,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.5772047683225328,
        "precision": 0.5581913755038094,
        "recall": 0.6260811709913506
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.83301333840256,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.83301333840256,
        "precision": 0.8204923486360611,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8445331559104013,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8445331559104013,
        "precision": 0.8326790862719007,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.6593479707252162,
        "f1": 0.6118239711054081,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.6118239711054081,
        "precision": 0.5922377467287646,
        "recall": 0.6593479707252162
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.002061474260476543,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.002061474260476543,
        "precision": 0.0012469272779367057,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.8389886892880905,
        "f1": 0.8075219930509352,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.8075219930509352,
        "precision": 0.7939462345150967,
        "recall": 0.8389886892880905
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8641067072204797,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8641067072204797,
        "precision": 0.8540252827677977,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6788903674133215,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.6788903674133215,
        "precision": 0.6577408674714064,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8510677058581251,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8510677058581251,
        "precision": 0.8411906346038083,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8275829293793366,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8275829293793366,
        "precision": 0.8173320026613439,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.2042581503659348,
        "f1": 0.16427796232061445,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.16427796232061445,
        "precision": 0.1533923590726169,
        "recall": 0.2042581503659348
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.13304235821755359,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.13304235821755359,
        "precision": 0.12463787558757895,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.14770459081836326,
        "f1": 0.11776552148247019,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11776552148247019,
        "precision": 0.11022538898881634,
        "recall": 0.14770459081836326
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008051734112151977,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008051734112151977,
        "precision": 0.006892432067082766,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.1590153027278776,
        "f1": 0.1356602328967123,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1356602328967123,
        "precision": 0.12954036866425625,
        "recall": 0.1590153027278776
      },
      {
        "accuracy": 0.18429807052561545,
        "f1": 0.14350701476828728,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14350701476828728,
        "precision": 0.13339624304240047,
        "recall": 0.18429807052561545
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.08634445212840147,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08634445212840147,
        "precision": 0.08279386017037647,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.12131469269128696,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12131469269128696,
        "precision": 0.11409027314549602,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.18429807052561545,
        "f1": 0.151549243237018,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.151549243237018,
        "precision": 0.14302688664504248,
        "recall": 0.18429807052561545
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.15497407363181853,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.15497407363181853,
        "precision": 0.15051989585961237,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.1643379906852961,
        "f1": 0.13815306401172978,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.13815306401172978,
        "precision": 0.131580772654385,
        "recall": 0.1643379906852961
      },
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.13358389042021776,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.13358389042021776,
        "precision": 0.12868435151115032,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.15642293330719348,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.15642293330719348,
        "precision": 0.1476146795061991,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.16300731869594146,
        "f1": 0.12997563258207137,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12997563258207137,
        "precision": 0.12097593494285745,
        "recall": 0.16300731869594146
      },
      {
        "accuracy": 0.17298735861610112,
        "f1": 0.15007557486964773,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15007557486964773,
        "precision": 0.14430166637612798,
        "recall": 0.17298735861610112
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006864483753739816,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006864483753739816,
        "precision": 0.005604176765302087,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.1643379906852961,
        "f1": 0.13738125203636709,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13738125203636709,
        "precision": 0.12963949210671452,
        "recall": 0.1643379906852961
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.13986036680076025,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.13986036680076025,
        "precision": 0.13073556236159262,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.14770459081836326,
        "f1": 0.12382538766577335,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.12382538766577335,
        "precision": 0.11795216181462215,
        "recall": 0.14770459081836326
      },
      {
        "accuracy": 0.18296739853626082,
        "f1": 0.14592826720066518,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14592826720066518,
        "precision": 0.13589396339114296,
        "recall": 0.18296739853626082
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.14445020336791142,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14445020336791142,
        "precision": 0.13418159543506877,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9454868041694389,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9454868041694389,
        "precision": 0.9407296518074961,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.857329784874695,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.857329784874695,
        "precision": 0.8472351593110076,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.002918207312341152,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002918207312341152,
        "precision": 0.0020078548724232186,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.9007888983936887,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9007888983936887,
        "precision": 0.8934797072521624,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9205588822355288,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9205588822355288,
        "precision": 0.914193834553116,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9346307385229541,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9346307385229541,
        "precision": 0.9294252764312644,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.6573519627411843,
        "f1": 0.6004937215516057,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6004937215516057,
        "precision": 0.5788349442511707,
        "recall": 0.6573519627411843
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9179640718562875,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9179640718562875,
        "precision": 0.9112552672432913,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6115161765860369,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6115161765860369,
        "precision": 0.5929920054071751,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8674001203941324,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8674001203941324,
        "precision": 0.8587000601970661,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.6919494344644045,
        "f1": 0.647467335086215,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.647467335086215,
        "precision": 0.6306952486967458,
        "recall": 0.6919494344644045
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9140607673541806,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9140607673541806,
        "precision": 0.9081725438012863,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053448658239077,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9053448658239077,
        "precision": 0.8973941006875138,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7162126444561574,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7162126444561574,
        "precision": 0.6993703931299329,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0023568584843397244,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023568584843397244,
        "precision": 0.0014986687750835818,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8892242451124688,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8892242451124688,
        "precision": 0.8818529607451763,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9371479263694832,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9371479263694832,
        "precision": 0.9316589044133954,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7797653850548062,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7797653850548062,
        "precision": 0.7654064479912783,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9230871590153028,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9230871590153028,
        "precision": 0.916833000665336,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9141621518867028,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9141621518867028,
        "precision": 0.9076920233606861,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8370829769033361,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8370829769033361,
        "precision": 0.826547194211865,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005548802526070507,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.005548802526070507,
        "precision": 0.004587051657323863,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8991276705847563,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8991276705847563,
        "precision": 0.8920843498188809,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9201485917054778,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9201485917054778,
        "precision": 0.914100370687197,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9284668757722648,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9284668757722648,
        "precision": 0.924153280740107,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.6686626746506986,
        "f1": 0.6145449938804406,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.6145449938804406,
        "precision": 0.5943761947005459,
        "recall": 0.6686626746506986
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9082110910454224,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9082110910454224,
        "precision": 0.9015801729873585,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5345423665606829,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.5345423665606829,
        "precision": 0.5181532437769962,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8758403827266102,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8758403827266102,
        "precision": 0.866828248265374,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.6174318030605456,
        "f1": 0.5725613509985942,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5725613509985942,
        "precision": 0.5567232799488875,
        "recall": 0.6174318030605456
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9246427779361912,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9246427779361912,
        "precision": 0.9190175205145265,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9099261793872573,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9099261793872573,
        "precision": 0.9028831226436017,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.7212242182302062,
        "f1": 0.6743359915016602,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6743359915016602,
        "precision": 0.6562010370792806,
        "recall": 0.7212242182302062
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.003191375786186165,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003191375786186165,
        "precision": 0.0020895094394104774,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9016633399866931,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9016633399866931,
        "precision": 0.8934464404524284,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9421157684630739,
        "f1": 0.9298735861610112,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9298735861610112,
        "precision": 0.9246174318030606,
        "recall": 0.9421157684630739
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7801550818516887,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7801550818516887,
        "precision": 0.7658500459398662,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9265025504546462,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9265025504546462,
        "precision": 0.921789753825682,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9171240011559374,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9171240011559374,
        "precision": 0.9114936793080505,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0028076469465788513,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028076469465788513,
        "precision": 0.0020156917040262475,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.8689288090485695,
        "f1": 0.8416500332667998,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8416500332667998,
        "precision": 0.8294189398979819,
        "recall": 0.8689288090485695
      },
      {
        "accuracy": 0.8602794411177644,
        "f1": 0.8310933688179196,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8310933688179196,
        "precision": 0.8181871946343005,
        "recall": 0.8602794411177644
      },
      {
        "accuracy": 0.8602794411177644,
        "f1": 0.8335794500465158,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8335794500465158,
        "precision": 0.8224750742714814,
        "recall": 0.8602794411177644
      },
      {
        "accuracy": 0.5655355954757152,
        "f1": 0.5011331833687123,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5011331833687123,
        "precision": 0.47693213860878536,
        "recall": 0.5655355954757152
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.8018534359851726,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8018534359851726,
        "precision": 0.7878945812079544,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.4908694691129821,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.4908694691129821,
        "precision": 0.47015025269975635,
        "recall": 0.5449101796407185
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7570747874141088,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7570747874141088,
        "precision": 0.7416550736910018,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5141367139620062,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5141367139620062,
        "precision": 0.4933462560209067,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8162357824034472,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8162357824034472,
        "precision": 0.8014996462102251,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8438752125378872,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8438752125378872,
        "precision": 0.8323020625415836,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5747310093617478,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5747310093617478,
        "precision": 0.5532834043313085,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0027308755969052668,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0027308755969052668,
        "precision": 0.001973046009221939,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.8203592814371258,
        "f1": 0.7862207283364968,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7862207283364968,
        "precision": 0.7721440956470895,
        "recall": 0.8203592814371258
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8578546610482737,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8578546610482737,
        "precision": 0.8467453980927034,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.675902163926116,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.675902163926116,
        "precision": 0.6543806160572627,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8392400384416352,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8392400384416352,
        "precision": 0.8275559991128854,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.823278229865056,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.823278229865056,
        "precision": 0.811465956974939,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006989525875911438,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0006989525875911438,
        "precision": 0.000682429134507075,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0017242306415784277,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0017242306415784277,
        "precision": 0.0015512227503933903,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011609408030438802,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0011609408030438802,
        "precision": 0.0009686054248092961,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0027115028627523016,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0027115028627523016,
        "precision": 0.002421197669927219,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020154647889391846,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0020154647889391846,
        "precision": 0.0020057792505660853,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0013609103788277215,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0013609103788277215,
        "precision": 0.001134510244755983,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0020416049682474005,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0020416049682474005,
        "precision": 0.00201941522227779,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017635428757091062,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0017635428757091062,
        "precision": 0.001352708716275475,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003417071238207762,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.003417071238207762,
        "precision": 0.0031733498053159344,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006829672983143231,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0006829672983143231,
        "precision": 0.0006742036398910168,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009072402779503003,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0009072402779503003,
        "precision": 0.0008025724886270465,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.027547210098307063,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.027547210098307063,
        "precision": 0.024837867504523874,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003239135230980349,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.003239135230980349,
        "precision": 0.003028039392249624,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014554510311336286,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0014554510311336286,
        "precision": 0.0013965137879787507,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002435506692990018,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.002435506692990018,
        "precision": 0.0022609183530753374,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002449371750578472,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.002449371750578472,
        "precision": 0.0023336054114765884,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0017938211950187996,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0017938211950187996,
        "precision": 0.001673212265820153,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.9188290086493679,
        "f1": 0.8999223774672876,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8999223774672876,
        "precision": 0.8916083177560225,
        "recall": 0.9188290086493679
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8887035452903717,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8887035452903717,
        "precision": 0.881931375344549,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5522957906874285,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.5522957906874285,
        "precision": 0.5322344802384723,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.857031967810411,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.857031967810411,
        "precision": 0.8458823094551637,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.49715751277627523,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.49715751277627523,
        "precision": 0.47728509431353744,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8338012287114084,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8338012287114084,
        "precision": 0.8223357517768696,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.5981370592149036,
        "f1": 0.5513400382169238,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5513400382169238,
        "precision": 0.5349386625554877,
        "recall": 0.5981370592149036
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8889237398219434,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8889237398219434,
        "precision": 0.8796850742958526,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8883787979596361,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8883787979596361,
        "precision": 0.879930614960555,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6283618096991351,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.6283618096991351,
        "precision": 0.6094842301928131,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003774430115148965,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.003774430115148965,
        "precision": 0.0026732038011276203,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8485177792563021,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8485177792563021,
        "precision": 0.8376968285650921,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9060989132845421,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9060989132845421,
        "precision": 0.899035262807718,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7481090728595718,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7481090728595718,
        "precision": 0.7317188854614003,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8979279536165764,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8979279536165764,
        "precision": 0.8908848968729208,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8757063074428344,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8757063074428344,
        "precision": 0.8681747615879353,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9148433292145866,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9148433292145866,
        "precision": 0.9089265912619207,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.5895820296583987,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.5895820296583987,
        "precision": 0.5679153551409041,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8968840097582612,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8968840097582612,
        "precision": 0.888917403288661,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5284467288459304,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.5284467288459304,
        "precision": 0.5088549396932631,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8844438107911161,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8844438107911161,
        "precision": 0.8752605899312486,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.588578185744637,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.588578185744637,
        "precision": 0.5723900120357206,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9224883566200931,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9224883566200931,
        "precision": 0.9163561765358172,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9113107119095143,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9113107119095143,
        "precision": 0.903581725438013,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.7112441783100466,
        "f1": 0.6626482964806318,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6626482964806318,
        "precision": 0.6436955635400851,
        "recall": 0.7112441783100466
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0031496092560186826,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0031496092560186826,
        "precision": 0.001985833850877349,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.905921490352628,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.905921490352628,
        "precision": 0.8979818141494789,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9374362386338434,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9374362386338434,
        "precision": 0.931936127744511,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7807717897538257,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7807717897538257,
        "precision": 0.7663107240951552,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9292747837658017,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9292747837658017,
        "precision": 0.9232091372809935,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9180749611887336,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9180749611887336,
        "precision": 0.9120536704369039,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.6114437791084497,
        "f1": 0.5463001739390139,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.5463001739390139,
        "precision": 0.5204901284492103,
        "recall": 0.6114437791084497
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9014215436371124,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9014215436371124,
        "precision": 0.8942068244463455,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.4900895251818792,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.4900895251818792,
        "precision": 0.46688203522686733,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8572808687579146,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8572808687579146,
        "precision": 0.8493565739669121,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.6041250831669993,
        "f1": 0.5411521642530214,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5411521642530214,
        "precision": 0.5179088786701148,
        "recall": 0.6041250831669993
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9144291127889149,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9144291127889149,
        "precision": 0.9086070283675073,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9163688496023826,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9163688496023826,
        "precision": 0.9106105249817825,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6795069287768101,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6795069287768101,
        "precision": 0.6576683856066267,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017467066173581978,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0017467066173581978,
        "precision": 0.0013816419614752027,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8835319260468961,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8835319260468961,
        "precision": 0.8763120931626026,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9282047017076958,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9282047017076958,
        "precision": 0.9234937532342722,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7654415223277499,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7654415223277499,
        "precision": 0.7488001413613604,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9216478341170133,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9216478341170133,
        "precision": 0.9162536039033045,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9155736576835556,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9155736576835556,
        "precision": 0.9103717168836929,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5997175442285223,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5997175442285223,
        "precision": 0.5809905669029527,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.3912175648702595,
        "f1": 0.3515729616727621,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3515729616727621,
        "precision": 0.3391519886362355,
        "recall": 0.3912175648702595
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5453519712472396,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.5453519712472396,
        "precision": 0.5303158045955061,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.3819028609447771,
        "f1": 0.3474019637492692,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.3474019637492692,
        "precision": 0.33710382351227597,
        "recall": 0.3819028609447771
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5925949244458222,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.5925949244458222,
        "precision": 0.5793951178931219,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5764069153290711,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5764069153290711,
        "precision": 0.5566544190322338,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.426480372588157,
        "f1": 0.38422499423303413,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.38422499423303413,
        "precision": 0.37096561585084536,
        "recall": 0.426480372588157
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006212147825900106,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006212147825900106,
        "precision": 0.004920541854011388,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5830675645046902,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5830675645046902,
        "precision": 0.5660550748188168,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.6100614944889312,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6100614944889312,
        "precision": 0.5933659194834279,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.4584974190703907,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.4584974190703907,
        "precision": 0.44011225212662963,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.6487025948103793,
        "f1": 0.6002532453131255,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6002532453131255,
        "precision": 0.5816166848601978,
        "recall": 0.6487025948103793
      },
      {
        "accuracy": 0.635395874916833,
        "f1": 0.5949398345203084,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5949398345203084,
        "precision": 0.5794735226093098,
        "recall": 0.635395874916833
      },
      {
        "accuracy": 0.6340652029274784,
        "f1": 0.5826761100214194,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.5826761100214194,
        "precision": 0.5631501787190409,
        "recall": 0.6340652029274784
      },
      {
        "accuracy": 0.8888888888888888,
        "f1": 0.8662262776035231,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8662262776035231,
        "precision": 0.8564981148813484,
        "recall": 0.8888888888888888
      },
      {
        "accuracy": 0.6526946107784432,
        "f1": 0.6077290485943767,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6077290485943767,
        "precision": 0.5903006710890942,
        "recall": 0.6526946107784432
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9129106865633813,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9129106865633813,
        "precision": 0.9060434686183189,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8922599245952539,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8922599245952539,
        "precision": 0.8837264864210972,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6927542369658138,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6927542369658138,
        "precision": 0.675249765020224,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0034187479156959407,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0034187479156959407,
        "precision": 0.0023390673408803064,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8830835683131092,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8830835683131092,
        "precision": 0.8742237746728766,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9163118208028388,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9163118208028388,
        "precision": 0.909409751924722,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.8070525615435795,
        "f1": 0.7675426111553856,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7675426111553856,
        "precision": 0.7512699708807493,
        "recall": 0.8070525615435795
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.915302727877578,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.915302727877578,
        "precision": 0.9079285872699047,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9145185818838515,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9145185818838515,
        "precision": 0.9081123467351013,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.5755156353958749,
        "f1": 0.5247911731943669,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5247911731943669,
        "precision": 0.5063672358208001,
        "recall": 0.5755156353958749
      },
      {
        "accuracy": 0.5036593479707252,
        "f1": 0.4523532060458208,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4523532060458208,
        "precision": 0.4344152543878093,
        "recall": 0.5036593479707252
      },
      {
        "accuracy": 0.6147704590818364,
        "f1": 0.5626548773293235,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5626548773293235,
        "precision": 0.5438138273717116,
        "recall": 0.6147704590818364
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5369412812211425,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5369412812211425,
        "precision": 0.5167047944775099,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5373623604162526,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5373623604162526,
        "precision": 0.5204374320142784,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004215395739841688,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004215395739841688,
        "precision": 0.002960410235462813,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5552286960470593,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5552286960470593,
        "precision": 0.5347398037018796,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.624750499001996,
        "f1": 0.5674326763648121,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5674326763648121,
        "precision": 0.5460591098207506,
        "recall": 0.624750499001996
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.44811070499693256,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.44811070499693256,
        "precision": 0.42765482954810186,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.5870272735055775,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5870272735055775,
        "precision": 0.567670503149545,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.6002927303451642,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6002927303451642,
        "precision": 0.5815877338082927,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.561205220505042,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.561205220505042,
        "precision": 0.5439929904500762,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8852406298514083,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8852406298514083,
        "precision": 0.8766973988530874,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8547032918290404,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8547032918290404,
        "precision": 0.843634952317587,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6124417284751787,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6124417284751787,
        "precision": 0.5936439530750908,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003453187824300671,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.003453187824300671,
        "precision": 0.0021300390928403984,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8671228970630168,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8671228970630168,
        "precision": 0.8562319804834776,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8967509425593257,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8967509425593257,
        "precision": 0.8877087095649969,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.7937458416500333,
        "f1": 0.756935863722291,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.756935863722291,
        "precision": 0.7420542512857883,
        "recall": 0.7937458416500333
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.891132549715384,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.891132549715384,
        "precision": 0.8838442163292463,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8725712595972076,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8725712595972076,
        "precision": 0.8640108671545798,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5990647012852602,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5990647012852602,
        "precision": 0.5793744207964155,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5922305775100186,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5922305775100186,
        "precision": 0.569464985373169,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.5595475715236194,
        "f1": 0.5078835569538374,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5078835569538374,
        "precision": 0.48827635733823355,
        "recall": 0.5595475715236194
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0040088528696310115,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0040088528696310115,
        "precision": 0.0029934371222383434,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.6407185628742516,
        "f1": 0.5855595686933012,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5855595686933012,
        "precision": 0.5643164029861223,
        "recall": 0.6407185628742516
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6214382484782861,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6214382484782861,
        "precision": 0.5995436664532683,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5079281072295044,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.5079281072295044,
        "precision": 0.48516683964122415,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.7092481703260146,
        "f1": 0.6598932006117635,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6598932006117635,
        "precision": 0.6399400545314599,
        "recall": 0.7092481703260146
      },
      {
        "accuracy": 0.656686626746507,
        "f1": 0.6094071190877578,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6094071190877578,
        "precision": 0.591434761734163,
        "recall": 0.656686626746507
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8917181509995881,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8917181509995881,
        "precision": 0.8822355289421158,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.7272122421823021,
        "f1": 0.6783428333328533,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6783428333328533,
        "precision": 0.6592127747317368,
        "recall": 0.7272122421823021
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.002715438718021734,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002715438718021734,
        "precision": 0.0017380283056767252,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.8997782213351077,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8997782213351077,
        "precision": 0.8909625194056333,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9373253493013972,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9373253493013972,
        "precision": 0.9321579064094034,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.7935135020963365,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7935135020963365,
        "precision": 0.7791984407253869,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.9247948547349744,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9247948547349744,
        "precision": 0.9190729651807497,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9083610556664449,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9083610556664449,
        "precision": 0.900909292526059,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6425156703541112,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.6425156703541112,
        "precision": 0.623654601508105,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0035515346206278146,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0035515346206278146,
        "precision": 0.0025325585383521023,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8572558586530642,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.8572558586530642,
        "precision": 0.8469671767575958,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9198048347748947,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9198048347748947,
        "precision": 0.9136172100243956,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.7590200218942734,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7590200218942734,
        "precision": 0.7431299018125366,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9100592465861926,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9100592465861926,
        "precision": 0.903049456642271,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9121756487025948,
        "f1": 0.8953109653708456,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8953109653708456,
        "precision": 0.8884785983588378,
        "recall": 0.9121756487025948
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0027459031547628545,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0027459031547628545,
        "precision": 0.001679222410904826,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7082184836675854,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7082184836675854,
        "precision": 0.6887684947565187,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.7518296739853626,
        "f1": 0.705975235111081,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.705975235111081,
        "precision": 0.6874104964673828,
        "recall": 0.7518296739853626
      },
      {
        "accuracy": 0.612109115103127,
        "f1": 0.555435094956053,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.555435094956053,
        "precision": 0.5338349589347593,
        "recall": 0.612109115103127
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7080836027507901,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7080836027507901,
        "precision": 0.6885428997704447,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.7618097139055223,
        "f1": 0.7234599583900982,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7234599583900982,
        "precision": 0.707980071602826,
        "recall": 0.7618097139055223
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000709694899167135,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.000709694899167135,
        "precision": 0.0006878054866562744,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.0300565892865365e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 3.0300565892865365e-05,
        "precision": 1.537598060969229e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.816466555670098e-05,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 1.816466555670098e-05,
        "precision": 9.13846128987964e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0645278808530871e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 1.0645278808530871e-05,
        "precision": 5.353278118093316e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00029766679076754577,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.00029766679076754577,
        "precision": 0.00017249909765734985,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9042375566327662,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9042375566327662,
        "precision": 0.8961362988309096,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.8003992015968064,
        "f1": 0.7629113388535721,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7629113388535721,
        "precision": 0.7473802395209581,
        "recall": 0.8003992015968064
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8945901847099451,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8945901847099451,
        "precision": 0.8862893261096854,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8871938662357824,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8871938662357824,
        "precision": 0.8786981592370814,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7688089097270734,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7688089097270734,
        "precision": 0.7535291443974078,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9213351075626524,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9213351075626524,
        "precision": 0.9146152140164115,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.913428698159237,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.913428698159237,
        "precision": 0.9065488071476094,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8204188692212645,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8204188692212645,
        "precision": 0.8079312274921057,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7771620779604812,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7771620779604812,
        "precision": 0.7660512308715901,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9231315147482813,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9231315147482813,
        "precision": 0.9167221113328898,
        "recall": 0.9374584165003327
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}