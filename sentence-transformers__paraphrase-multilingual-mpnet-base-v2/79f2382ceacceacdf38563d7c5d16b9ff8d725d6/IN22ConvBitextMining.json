{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 23.32378125190735,
  "kg_co2_emissions": 0.0008632018609756837,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.01877328834378224,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.01877328834378224,
        "precision": 0.016176311839199545,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.5781769793745841,
        "f1": 0.5213584657637728,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.5213584657637728,
        "precision": 0.49954406836563575,
        "recall": 0.5781769793745841
      },
      {
        "accuracy": 0.5708582834331337,
        "f1": 0.5139113307775982,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.5139113307775982,
        "precision": 0.4915061651588597,
        "recall": 0.5708582834331337
      },
      {
        "accuracy": 0.4630738522954092,
        "f1": 0.4071866848313954,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.4071866848313954,
        "precision": 0.3852289396043992,
        "recall": 0.4630738522954092
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0008213989944560301,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0008213989944560301,
        "precision": 0.0005377491206187679,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5032416648185112,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.5032416648185112,
        "precision": 0.47955279916357757,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.42837077168414495,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.42837077168414495,
        "precision": 0.4049360621558331,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.573519627411843,
        "f1": 0.5135316335915138,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5135316335915138,
        "precision": 0.4901163521922005,
        "recall": 0.573519627411843
      },
      {
        "accuracy": 0.10578842315369262,
        "f1": 0.07012031903502831,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.07012031903502831,
        "precision": 0.060920979109601855,
        "recall": 0.10578842315369262
      },
      {
        "accuracy": 0.47904191616766467,
        "f1": 0.4213530610736199,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.4213530610736199,
        "precision": 0.39841613070155985,
        "recall": 0.47904191616766467
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.12294557164229583,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.12294557164229583,
        "precision": 0.10992838295732507,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.3226879574184963,
        "f1": 0.2622757131240165,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.2622757131240165,
        "precision": 0.23992649621392137,
        "recall": 0.3226879574184963
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.17022573419779008,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.17022573419779008,
        "precision": 0.15494542420690127,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.5395874916833001,
        "f1": 0.4835482954245429,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.4835482954245429,
        "precision": 0.46146833317492,
        "recall": 0.5395874916833001
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.4849348921205209,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.4849348921205209,
        "precision": 0.4610546583600476,
        "recall": 0.5449101796407185
      },
      {
        "accuracy": 0.27345309381237526,
        "f1": 0.21930847300108777,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.21930847300108777,
        "precision": 0.20093752628682768,
        "recall": 0.27345309381237526
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009308924873444504,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0009308924873444504,
        "precision": 0.000687464607409394,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.3107119095143047,
        "f1": 0.263390198919141,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.263390198919141,
        "precision": 0.24648027916490992,
        "recall": 0.3107119095143047
      },
      {
        "accuracy": 0.5508982035928144,
        "f1": 0.4898824389408438,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.4898824389408438,
        "precision": 0.4662823943263065,
        "recall": 0.5508982035928144
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.19008601363890787,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.19008601363890787,
        "precision": 0.17220213991671077,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.5548902195608783,
        "f1": 0.4934144820057206,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.4934144820057206,
        "precision": 0.4691841806582912,
        "recall": 0.5548902195608783
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.4842008291110087,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.4842008291110087,
        "precision": 0.4618208028387669,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.03552799670781166,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03552799670781166,
        "precision": 0.03248755238902076,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02939129774939367,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.02939129774939367,
        "precision": 0.027707959781594467,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.016061270665970222,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.016061270665970222,
        "precision": 0.014525143768270419,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002570894021820981,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002570894021820981,
        "precision": 0.002102762724770984,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.021088083523783795,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.021088083523783795,
        "precision": 0.019889123281032445,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.015247376544400403,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.015247376544400403,
        "precision": 0.013955636726408923,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.03357126065362529,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03357126065362529,
        "precision": 0.031007294744323056,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01869594145043247,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.01869594145043247,
        "precision": 0.01723220226214238,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014662967392801842,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.014662967392801842,
        "precision": 0.013310302668295542,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02985247176863943,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02985247176863943,
        "precision": 0.028273254061677213,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.018947796082415733,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.018947796082415733,
        "precision": 0.01730983913752523,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.028691877521315415,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.028691877521315415,
        "precision": 0.02677632602307063,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03578644659932573,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03578644659932573,
        "precision": 0.03328223406528016,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.02125971522220976,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02125971522220976,
        "precision": 0.019971381424944885,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.03206806684850597,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03206806684850597,
        "precision": 0.03024483857544636,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002641726062773242,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002641726062773242,
        "precision": 0.002441772467129391,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.03707435324448975,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03707435324448975,
        "precision": 0.03430952232670569,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.021092661598028573,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.021092661598028573,
        "precision": 0.019986693719338748,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.026066949901825495,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.026066949901825495,
        "precision": 0.024780189040107335,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.0368946620710525,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0368946620710525,
        "precision": 0.034502621086128366,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.028588903422555077,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.028588903422555077,
        "precision": 0.026933995939234272,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8428476380572189,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8428476380572189,
        "precision": 0.8286981592370813,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6030510407755917,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6030510407755917,
        "precision": 0.5767908627190065,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0004636414391760396,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0004636414391760396,
        "precision": 0.0002466738918082064,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6792098342996546,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6792098342996546,
        "precision": 0.6547571523619428,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6102657119623188,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6102657119623188,
        "precision": 0.5823028546082438,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8634065202927477,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8634065202927477,
        "precision": 0.8513528498558439,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.123454377081062,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.123454377081062,
        "precision": 0.10930280630879431,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6778728257770174,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6778728257770174,
        "precision": 0.6564775211481798,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.3306719893546241,
        "f1": 0.26082438298007155,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.26082438298007155,
        "precision": 0.23787475427616195,
        "recall": 0.3306719893546241
      },
      {
        "accuracy": 0.45708582834331335,
        "f1": 0.38083036945312393,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.38083036945312393,
        "precision": 0.35202797867468527,
        "recall": 0.45708582834331335
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.3089429274060012,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3089429274060012,
        "precision": 0.283538742620579,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.825016633399867,
        "f1": 0.7850188511865159,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7850188511865159,
        "precision": 0.7678040743909006,
        "recall": 0.825016633399867
      },
      {
        "accuracy": 0.7465069860279441,
        "f1": 0.6924500205937332,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6924500205937332,
        "precision": 0.6687181193169217,
        "recall": 0.7465069860279441
      },
      {
        "accuracy": 0.47904191616766467,
        "f1": 0.4038257779774746,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4038257779774746,
        "precision": 0.3760170135918639,
        "recall": 0.47904191616766467
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00025685345030596654,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00025685345030596654,
        "precision": 0.00013481457453743648,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.46565590837047927,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.46565590837047927,
        "precision": 0.43954656823918303,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.7280138136425561,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7280138136425561,
        "precision": 0.7067088046129962,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.2848599578140496,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.2848599578140496,
        "precision": 0.2618363875349903,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8009441434591135,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8009441434591135,
        "precision": 0.784253714792637,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.7997338656021291,
        "f1": 0.7509203814593035,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7509203814593035,
        "precision": 0.7287314260368153,
        "recall": 0.7997338656021291
      },
      {
        "accuracy": 0.6427145708582834,
        "f1": 0.5801022294036265,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5801022294036265,
        "precision": 0.553298957640275,
        "recall": 0.6427145708582834
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00040298247617632377,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00040298247617632377,
        "precision": 0.00021507840056888137,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6818141494788201,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6818141494788201,
        "precision": 0.6569416722111333,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.6706586826347305,
        "f1": 0.6044867936085502,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6044867936085502,
        "precision": 0.5764257199885943,
        "recall": 0.6706586826347305
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8431803060545575,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8431803060545575,
        "precision": 0.8295520070969172,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.19627411842980705,
        "f1": 0.14084715646591894,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.14084715646591894,
        "precision": 0.1252162935421133,
        "recall": 0.19627411842980705
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.6901340176789278,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6901340176789278,
        "precision": 0.6665335994677312,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.2940785096473719,
        "f1": 0.22779873708017423,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.22779873708017423,
        "precision": 0.2065098038650933,
        "recall": 0.2940785096473719
      },
      {
        "accuracy": 0.45442448436460414,
        "f1": 0.379007080005084,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.379007080005084,
        "precision": 0.3507297574163842,
        "recall": 0.45442448436460414
      },
      {
        "accuracy": 0.35395874916833003,
        "f1": 0.2834727038319853,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2834727038319853,
        "precision": 0.2595860781489524,
        "recall": 0.35395874916833003
      },
      {
        "accuracy": 0.8130405854956753,
        "f1": 0.7705699711687736,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7705699711687736,
        "precision": 0.7517853182523841,
        "recall": 0.8130405854956753
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6696622627760352,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6696622627760352,
        "precision": 0.6465909450939391,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.36419225041979525,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.36419225041979525,
        "precision": 0.33615648231416695,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0002826564037475548,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0002826564037475548,
        "precision": 0.0001540329253532216,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.43824793894654174,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.43824793894654174,
        "precision": 0.41361404175775435,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.759148369926813,
        "f1": 0.7085067959319457,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7085067959319457,
        "precision": 0.6863938789088491,
        "recall": 0.759148369926813
      },
      {
        "accuracy": 0.3406520292747838,
        "f1": 0.272152885925341,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.272152885925341,
        "precision": 0.2486014743000771,
        "recall": 0.3406520292747838
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7850077622532713,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7850077622532713,
        "precision": 0.7666999334664004,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7385894876912841,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.7385894876912841,
        "precision": 0.7173209137280993,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000479716555401443,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.000479716555401443,
        "precision": 0.00027716893093283174,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5208524749442913,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.5208524749442913,
        "precision": 0.496048379431613,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.5169660678642715,
        "f1": 0.4518814703445441,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.4518814703445441,
        "precision": 0.4255164274625352,
        "recall": 0.5169660678642715
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.5388381966226277,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5388381966226277,
        "precision": 0.5131116074728849,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.0732634532100817,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.0732634532100817,
        "precision": 0.06500416933550666,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.49567531603459747,
        "f1": 0.43467615034481305,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.43467615034481305,
        "precision": 0.41075151284732125,
        "recall": 0.49567531603459747
      },
      {
        "accuracy": 0.18296739853626082,
        "f1": 0.14073694842157913,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.14073694842157913,
        "precision": 0.12745857491366475,
        "recall": 0.18296739853626082
      },
      {
        "accuracy": 0.3333333333333333,
        "f1": 0.270660185530445,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.270660185530445,
        "precision": 0.24769059764069745,
        "recall": 0.3333333333333333
      },
      {
        "accuracy": 0.22355289421157684,
        "f1": 0.1794844174085691,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.1794844174085691,
        "precision": 0.16503109701712493,
        "recall": 0.22355289421157684
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.5086728659083948,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.5086728659083948,
        "precision": 0.48317811226992863,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.58416500332668,
        "f1": 0.5224736193798071,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.5224736193798071,
        "precision": 0.49752426364202806,
        "recall": 0.58416500332668
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2135686779399354,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.2135686779399354,
        "precision": 0.1956446728402816,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001210499646249764,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.001210499646249764,
        "precision": 0.0009714102518121036,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.32335329341317365,
        "f1": 0.2728637629835235,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.2728637629835235,
        "precision": 0.25476454498410583,
        "recall": 0.32335329341317365
      },
      {
        "accuracy": 0.5721889554224884,
        "f1": 0.5113962551088299,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.5113962551088299,
        "precision": 0.48716563986025063,
        "recall": 0.5721889554224884
      },
      {
        "accuracy": 0.23552894211576847,
        "f1": 0.18582839131741322,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.18582839131741322,
        "precision": 0.1693893573105737,
        "recall": 0.23552894211576847
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5396577695978894,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.5396577695978894,
        "precision": 0.5157146025409498,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.5582168995342648,
        "f1": 0.4936142773468123,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.4936142773468123,
        "precision": 0.4684712585411189,
        "recall": 0.5582168995342648
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.860793718889841e-05,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 7.860793718889841e-05,
        "precision": 4.0536389331458246e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011937860375918756,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0011937860375918756,
        "precision": 0.0010421570592449635,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006808500580448846,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0006808500580448846,
        "precision": 0.0006731683863741936,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009739261880131967,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0009739261880131967,
        "precision": 0.0008534950301417367,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010644436660084322,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0010644436660084322,
        "precision": 0.0009023407149008334,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020988202176139255,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0020988202176139255,
        "precision": 0.0020493712713860667,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014697433963323633,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0014697433963323633,
        "precision": 0.0011686918566081476,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001699937185100687,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001699937185100687,
        "precision": 0.0015506843841117763,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000705207483960286,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.000705207483960286,
        "precision": 0.000685507429641776,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007480781654297173,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0007480781654297173,
        "precision": 0.0007077340347709971,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007167259419549265,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0007167259419549265,
        "precision": 0.0006914496391424887,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.024496302721317222,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.024496302721317222,
        "precision": 0.022104228291853045,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007539710486090454,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0007539710486090454,
        "precision": 0.0007108185177508413,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008073447115288015,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008073447115288015,
        "precision": 0.0007404278455647528,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008864958409347891,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008864958409347891,
        "precision": 0.0007920362838522685,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008138278796179407,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0008138278796179407,
        "precision": 0.0007436981066426284,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006664971395196808,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0006664971395196808,
        "precision": 0.000665917074148646,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5279535833428048,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.5279535833428048,
        "precision": 0.502946487976428,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.718562874251497,
        "f1": 0.6649357369916251,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.6649357369916251,
        "precision": 0.6424444761271109,
        "recall": 0.718562874251497
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.08543385458379,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.08543385458379,
        "precision": 0.07623529203644834,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.5781769793745841,
        "f1": 0.52416014531783,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.52416014531783,
        "precision": 0.5026687366008723,
        "recall": 0.5781769793745841
      },
      {
        "accuracy": 0.20825016633399868,
        "f1": 0.15810699982356669,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.15810699982356669,
        "precision": 0.14314510986167672,
        "recall": 0.20825016633399868
      },
      {
        "accuracy": 0.3592814371257485,
        "f1": 0.2954398082142593,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.2954398082142593,
        "precision": 0.27199912344622923,
        "recall": 0.3592814371257485
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.23262258551679707,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.23262258551679707,
        "precision": 0.21523036917248495,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.6526946107784432,
        "f1": 0.6010096689737409,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.6010096689737409,
        "precision": 0.5802542655836069,
        "recall": 0.6526946107784432
      },
      {
        "accuracy": 0.6713240186294078,
        "f1": 0.619709786775655,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.619709786775655,
        "precision": 0.5976225039099291,
        "recall": 0.6713240186294078
      },
      {
        "accuracy": 0.324018629407851,
        "f1": 0.263388691027531,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.263388691027531,
        "precision": 0.24233719909867615,
        "recall": 0.324018629407851
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007091419402092174,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0007091419402092174,
        "precision": 0.0006874650490332797,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.37059214903526283,
        "f1": 0.3112304109251391,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.3112304109251391,
        "precision": 0.2907041736632555,
        "recall": 0.37059214903526283
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.5970408389570067,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.5970408389570067,
        "precision": 0.5749295060672306,
        "recall": 0.6520292747837658
      },
      {
        "accuracy": 0.281437125748503,
        "f1": 0.22256687276647355,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.22256687276647355,
        "precision": 0.20224892465411426,
        "recall": 0.281437125748503
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.60957291765675,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.60957291765675,
        "precision": 0.5857090052698836,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.5881834215167547,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.5881834215167547,
        "precision": 0.5651031270791749,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.6307385229540918,
        "f1": 0.5648842526587038,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5648842526587038,
        "precision": 0.5395676900167918,
        "recall": 0.6307385229540918
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.06345669428914702,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.06345669428914702,
        "precision": 0.054916537775819216,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.592814371257485,
        "f1": 0.5315105239256935,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.5315105239256935,
        "precision": 0.5072592909419257,
        "recall": 0.592814371257485
      },
      {
        "accuracy": 0.15635395874916833,
        "f1": 0.11238916944173097,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.11238916944173097,
        "precision": 0.09897610890624862,
        "recall": 0.15635395874916833
      },
      {
        "accuracy": 0.40718562874251496,
        "f1": 0.3376760188137434,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.3376760188137434,
        "precision": 0.31151981750784147,
        "recall": 0.40718562874251496
      },
      {
        "accuracy": 0.2262142381902861,
        "f1": 0.18130300246068712,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.18130300246068712,
        "precision": 0.16649982862557713,
        "recall": 0.2262142381902861
      },
      {
        "accuracy": 0.6161011310711909,
        "f1": 0.5547465914731383,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.5547465914731383,
        "precision": 0.530292589424326,
        "recall": 0.6161011310711909
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5273674872477268,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.5273674872477268,
        "precision": 0.50033583626398,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2101584044697817,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.2101584044697817,
        "precision": 0.1898206233036572,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011760932568188978,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0011760932568188978,
        "precision": 0.0009837945502427072,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.3073852295409182,
        "f1": 0.25139294799973444,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.25139294799973444,
        "precision": 0.2319416555943502,
        "recall": 0.3073852295409182
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.5883360263599784,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.5883360263599784,
        "precision": 0.5635311387806398,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.2435129740518962,
        "f1": 0.19056362907484192,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.19056362907484192,
        "precision": 0.17311220050741008,
        "recall": 0.2435129740518962
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5530542090422331,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.5530542090422331,
        "precision": 0.5297814017873899,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.6061210911510313,
        "f1": 0.547847690861663,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.547847690861663,
        "precision": 0.5246692041602221,
        "recall": 0.6061210911510313
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.12652559410297803,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.12652559410297803,
        "precision": 0.11191348809565398,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.6909741843873581,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.6909741843873581,
        "precision": 0.6678341729239933,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.3359946773120426,
        "f1": 0.2588454114343512,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.2588454114343512,
        "precision": 0.23292947072887193,
        "recall": 0.3359946773120426
      },
      {
        "accuracy": 0.4743845642049235,
        "f1": 0.39283083664321183,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.39283083664321183,
        "precision": 0.36302027978674684,
        "recall": 0.4743845642049235
      },
      {
        "accuracy": 0.3812375249500998,
        "f1": 0.3022799518807503,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.3022799518807503,
        "precision": 0.2755666636904162,
        "recall": 0.3812375249500998
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8312633991276704,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.8312633991276704,
        "precision": 0.8162840984697272,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.7717897538256819,
        "f1": 0.7183685538974961,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7183685538974961,
        "precision": 0.6954590818363274,
        "recall": 0.7717897538256819
      },
      {
        "accuracy": 0.4823685961410512,
        "f1": 0.4008575109373513,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.4008575109373513,
        "precision": 0.3711563645196379,
        "recall": 0.4823685961410512
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008683543679430916,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0008683543679430916,
        "precision": 0.0007705829402566057,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.49787368928498427,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.49787368928498427,
        "precision": 0.46916867323553946,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.7877578176979375,
        "f1": 0.7394264381290327,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.7394264381290327,
        "precision": 0.7186523777841144,
        "recall": 0.7877578176979375
      },
      {
        "accuracy": 0.36194278110445777,
        "f1": 0.28351649828695735,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.28351649828695735,
        "precision": 0.25739819063172353,
        "recall": 0.36194278110445777
      },
      {
        "accuracy": 0.8689288090485695,
        "f1": 0.8323923581408612,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8323923581408612,
        "precision": 0.8158128188068307,
        "recall": 0.8689288090485695
      },
      {
        "accuracy": 0.8310046573519627,
        "f1": 0.78814751449482,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.78814751449482,
        "precision": 0.7688733643823463,
        "recall": 0.8310046573519627
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.10199815901869343,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10199815901869343,
        "precision": 0.09610923085811543,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.08863517501459009,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.08863517501459009,
        "precision": 0.08289984838065148,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.06572444084262553,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.06572444084262553,
        "precision": 0.06070874863290032,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.09248170326014638,
        "f1": 0.0773933761957714,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.0773933761957714,
        "precision": 0.07249205293117468,
        "recall": 0.09248170326014638
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.11826731145447192,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.11826731145447192,
        "precision": 0.11118329983047656,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.09001432675744864,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09001432675744864,
        "precision": 0.08537608543596567,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.10166926008894248,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.10166926008894248,
        "precision": 0.09625710099761997,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000376895288744159,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.000376895288744159,
        "precision": 0.00024414059457297918,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.10966245232089847,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.10966245232089847,
        "precision": 0.10389739324531032,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.1217564870259481,
        "f1": 0.09919457621068802,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.09919457621068802,
        "precision": 0.09256533140687909,
        "recall": 0.1217564870259481
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.0768451459575605,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0768451459575605,
        "precision": 0.07111970143407269,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.12308715901530273,
        "f1": 0.10360412001705113,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.10360412001705113,
        "precision": 0.09808053367038337,
        "recall": 0.12308715901530273
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.10235622747657501,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.10235622747657501,
        "precision": 0.09624598602828582,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.1525858003901916,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.1525858003901916,
        "precision": 0.1369673972938033,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.38855622089155023,
        "f1": 0.32083773770400514,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.32083773770400514,
        "precision": 0.29497196084022426,
        "recall": 0.38855622089155023
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.22406250510042924,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.22406250510042924,
        "precision": 0.2050986192174404,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.6118361161275333,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.6118361161275333,
        "precision": 0.590484639187234,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5529169654918158,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.5529169654918158,
        "precision": 0.5283818606173896,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.32335329341317365,
        "f1": 0.2606622401033578,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.2606622401033578,
        "precision": 0.23975939415061173,
        "recall": 0.32335329341317365
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0001816565364830823,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0001816565364830823,
        "precision": 9.652319167735827e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.33998669328010644,
        "f1": 0.2858621529280212,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.2858621529280212,
        "precision": 0.2674342032625466,
        "recall": 0.33998669328010644
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6122770332351171,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.6122770332351171,
        "precision": 0.5871510946361246,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.21168893574083195,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.21168893574083195,
        "precision": 0.19416378882446747,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6031904445078098,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.6031904445078098,
        "precision": 0.5802474896287271,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.667332002661344,
        "f1": 0.6113122960428349,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.6113122960428349,
        "precision": 0.5887455248233692,
        "recall": 0.667332002661344
      },
      {
        "accuracy": 0.13040585495675316,
        "f1": 0.10260976787335833,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.10260976787335833,
        "precision": 0.09376526878728358,
        "recall": 0.13040585495675316
      },
      {
        "accuracy": 0.20758483033932135,
        "f1": 0.17137026552607157,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.17137026552607157,
        "precision": 0.15900286473992006,
        "recall": 0.20758483033932135
      },
      {
        "accuracy": 0.2741184298070526,
        "f1": 0.23550182686077564,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.23550182686077564,
        "precision": 0.2233055832376167,
        "recall": 0.2741184298070526
      },
      {
        "accuracy": 0.19827012641383898,
        "f1": 0.15823973293700505,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.15823973293700505,
        "precision": 0.14632385307701343,
        "recall": 0.19827012641383898
      },
      {
        "accuracy": 0.25016633399866933,
        "f1": 0.21463582252005403,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21463582252005403,
        "precision": 0.20209633642767375,
        "recall": 0.25016633399866933
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007413248331800885,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007413248331800885,
        "precision": 0.0007038213912771478,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.22752009209095037,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.22752009209095037,
        "precision": 0.21397894446796642,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.2102461743180306,
        "f1": 0.17191692105516632,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.17191692105516632,
        "precision": 0.16022950527440605,
        "recall": 0.2102461743180306
      },
      {
        "accuracy": 0.1650033266799734,
        "f1": 0.13347342389258557,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.13347342389258557,
        "precision": 0.12335413666061196,
        "recall": 0.1650033266799734
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2291001326584958,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2291001326584958,
        "precision": 0.21520008726403766,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.25083166999334666,
        "f1": 0.21029802326408725,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.21029802326408725,
        "precision": 0.19735829978853175,
        "recall": 0.25083166999334666
      },
      {
        "accuracy": 0.14105123087159016,
        "f1": 0.1113239130205198,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.1113239130205198,
        "precision": 0.10243718911383581,
        "recall": 0.14105123087159016
      },
      {
        "accuracy": 0.3812375249500998,
        "f1": 0.3301794507879615,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.3301794507879615,
        "precision": 0.3132144150548518,
        "recall": 0.3812375249500998
      },
      {
        "accuracy": 0.34530938123752497,
        "f1": 0.2979930894513494,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.2979930894513494,
        "precision": 0.28141623199008425,
        "recall": 0.34530938123752497
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.15182427906978804,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.15182427906978804,
        "precision": 0.13977411477411475,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004623908139252848,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0004623908139252848,
        "precision": 0.00034213415654760134,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.21689953426480374,
        "f1": 0.18378639546304212,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.18378639546304212,
        "precision": 0.1729678283570499,
        "recall": 0.21689953426480374
      },
      {
        "accuracy": 0.4337990685296075,
        "f1": 0.3787877950161226,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.3787877950161226,
        "precision": 0.3591446068084896,
        "recall": 0.4337990685296075
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.14355225243448796,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.14355225243448796,
        "precision": 0.13133000071948261,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.3652694610778443,
        "f1": 0.3124794903334598,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.3124794903334598,
        "precision": 0.2948921353395015,
        "recall": 0.3652694610778443
      },
      {
        "accuracy": 0.3579507651363939,
        "f1": 0.31190783177772685,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.31190783177772685,
        "precision": 0.2967310710045828,
        "recall": 0.3579507651363939
      },
      {
        "accuracy": 0.3093812375249501,
        "f1": 0.2700658308941742,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2700658308941742,
        "precision": 0.25636554372716197,
        "recall": 0.3093812375249501
      },
      {
        "accuracy": 0.2368596141051231,
        "f1": 0.19854931021278385,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.19854931021278385,
        "precision": 0.1853230673739656,
        "recall": 0.2368596141051231
      },
      {
        "accuracy": 0.23353293413173654,
        "f1": 0.19898916046620635,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.19898916046620635,
        "precision": 0.18663515459922644,
        "recall": 0.23353293413173654
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00027734917286216694,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00027734917286216694,
        "precision": 0.00016118462147751884,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.21687370809127293,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21687370809127293,
        "precision": 0.20337691620126752,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.2588157019294744,
        "f1": 0.21377848843084854,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.21377848843084854,
        "precision": 0.19907502405825478,
        "recall": 0.2588157019294744
      },
      {
        "accuracy": 0.1709913506320692,
        "f1": 0.13838267028553122,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.13838267028553122,
        "precision": 0.12707261624133762,
        "recall": 0.1709913506320692
      },
      {
        "accuracy": 0.3499667332002661,
        "f1": 0.30590700537648746,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.30590700537648746,
        "precision": 0.29160284128174435,
        "recall": 0.3499667332002661
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.23488897116118376,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.23488897116118376,
        "precision": 0.21982543463003593,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6509425593257928,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6509425593257928,
        "precision": 0.6251275227323131,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.4351297405189621,
        "f1": 0.3668376718276917,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3668376718276917,
        "precision": 0.3409931699851859,
        "recall": 0.4351297405189621
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0003190284492070547,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003190284492070547,
        "precision": 0.00019303743860683023,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.4821326562843528,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4821326562843528,
        "precision": 0.4587240862190961,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.7524950099800399,
        "f1": 0.7020181858505211,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7020181858505211,
        "precision": 0.679570488652325,
        "recall": 0.7524950099800399
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.30881962902920984,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.30881962902920984,
        "precision": 0.2835564321093263,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7506336533282641,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7506336533282641,
        "precision": 0.7297135886956245,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7160567753382124,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7160567753382124,
        "precision": 0.6947660235085384,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.313373253493014,
        "f1": 0.2514637489628683,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.2514637489628683,
        "precision": 0.23007727930382618,
        "recall": 0.313373253493014
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00018393587706574634,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.00018393587706574634,
        "precision": 0.00010141213727955052,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.38389886892880903,
        "f1": 0.32628069055214765,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.32628069055214765,
        "precision": 0.3050058852953064,
        "recall": 0.38389886892880903
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.6120304364815342,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.6120304364815342,
        "precision": 0.5891367651347691,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.28542914171656686,
        "f1": 0.22550292909574343,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.22550292909574343,
        "precision": 0.20508937843973654,
        "recall": 0.28542914171656686
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6393662890668879,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.6393662890668879,
        "precision": 0.6171746454181584,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.6560212907518297,
        "f1": 0.5970651770052968,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.5970651770052968,
        "precision": 0.5723742990210057,
        "recall": 0.6560212907518297
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001376073972858462,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0001376073972858462,
        "precision": 7.269398098503343e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.35528942115768464,
        "f1": 0.30611317048442793,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.30611317048442793,
        "precision": 0.28847063707343146,
        "recall": 0.35528942115768464
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.276097433283062,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.276097433283062,
        "precision": 0.260758891573578,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.2102461743180306,
        "f1": 0.16872483236010052,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.16872483236010052,
        "precision": 0.15538436853307114,
        "recall": 0.2102461743180306
      },
      {
        "accuracy": 0.4018629407850965,
        "f1": 0.3500639140514189,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3500639140514189,
        "precision": 0.33224874698330586,
        "recall": 0.4018629407850965
      },
      {
        "accuracy": 0.36593479707252163,
        "f1": 0.316871456584713,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.316871456584713,
        "precision": 0.29924205233258183,
        "recall": 0.36593479707252163
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 9.482701462301195e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 9.482701462301195e-05,
        "precision": 4.860758765050814e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 5.785530388498365e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 5.785530388498365e-05,
        "precision": 3.0242545212605094e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004758565375213587,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0004758565375213587,
        "precision": 0.00034907766685200406,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.5547218382837006e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 2.5547218382837006e-05,
        "precision": 1.2905816996209068e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.0065597498900334e-06,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 1.0065597498900334e-06,
        "precision": 5.036608589533021e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.40718562874251496,
        "f1": 0.3526701809577235,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.3526701809577235,
        "precision": 0.3326831786163123,
        "recall": 0.40718562874251496
      },
      {
        "accuracy": 0.2967398536260812,
        "f1": 0.23962547764942974,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.23962547764942974,
        "precision": 0.2190990627617374,
        "recall": 0.2967398536260812
      },
      {
        "accuracy": 0.4916833000665336,
        "f1": 0.4368002091055983,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4368002091055983,
        "precision": 0.4170119765652485,
        "recall": 0.4916833000665336
      },
      {
        "accuracy": 0.4491017964071856,
        "f1": 0.400609411288054,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.400609411288054,
        "precision": 0.38251501368094265,
        "recall": 0.4491017964071856
      },
      {
        "accuracy": 0.29607451763140386,
        "f1": 0.23624019568384708,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.23624019568384708,
        "precision": 0.21578232424040808,
        "recall": 0.29607451763140386
      },
      {
        "accuracy": 0.7225548902195609,
        "f1": 0.6719038114247695,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6719038114247695,
        "precision": 0.6511844036794137,
        "recall": 0.7225548902195609
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6431612964547095,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.6431612964547095,
        "precision": 0.619656982331633,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.30538922155688625,
        "f1": 0.2658342438333827,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2658342438333827,
        "precision": 0.2526953504196387,
        "recall": 0.30538922155688625
      },
      {
        "accuracy": 0.2721224218230206,
        "f1": 0.23790630520450068,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.23790630520450068,
        "precision": 0.22737730411579626,
        "recall": 0.2721224218230206
      },
      {
        "accuracy": 0.7631403858948769,
        "f1": 0.7180876342552989,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7180876342552989,
        "precision": 0.6985584386781992,
        "recall": 0.7631403858948769
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}