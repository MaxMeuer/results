{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 18.283475637435913,
  "kg_co2_emissions": 0.0009096058780083627,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.091796875,
        "f1": 0.06262701057622932,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.06262701057622932,
        "precision": 0.05515444299623987,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.7158766889100658,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.7158766889100658,
        "precision": 0.7100982814872783,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.744140625,
        "f1": 0.7198071676587301,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.7198071676587301,
        "precision": 0.709431640625,
        "recall": 0.744140625
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.6286604790982484,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.6286604790982484,
        "precision": 0.6176847647794913,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006987657746208936,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0006987657746208936,
        "precision": 0.0005123499993910069,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6623272343975469,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.6623272343975469,
        "precision": 0.6505998883928572,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5859117231110447,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.5859117231110447,
        "precision": 0.5711907478007796,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.75,
        "f1": 0.720734303131764,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.720734303131764,
        "precision": 0.7097737630208334,
        "recall": 0.75
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.22406691073683258,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.22406691073683258,
        "precision": 0.20816136350373482,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5823567708333333,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.5823567708333333,
        "precision": 0.5681477864583333,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.3662109375,
        "f1": 0.3111025855654762,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.3111025855654762,
        "precision": 0.2911985367063492,
        "recall": 0.3662109375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.45828993055555556,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.45828993055555556,
        "precision": 0.43739027086195054,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.482421875,
        "f1": 0.4370384942100133,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4370384942100133,
        "precision": 0.42009257967509916,
        "recall": 0.482421875
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6891213809742647,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.6891213809742647,
        "precision": 0.6809828490736693,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.644723849826389,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.644723849826389,
        "precision": 0.6327274836546986,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4736049107142857,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.4736049107142857,
        "precision": 0.455078125,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018437002336570594,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0018437002336570594,
        "precision": 0.0015074941339278107,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5920843562330236,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.5920843562330236,
        "precision": 0.5800248212755026,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6607407211899399,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.6607407211899399,
        "precision": 0.6526507608251634,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.4568111359126984,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.4568111359126984,
        "precision": 0.4388125465029762,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6434446304563493,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.6434446304563493,
        "precision": 0.6335025046569163,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6600577427151416,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.6600577427151416,
        "precision": 0.6483448402326921,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07679829386598719,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.07679829386598719,
        "precision": 0.07410036521669683,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.07739825581395349,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.07739825581395349,
        "precision": 0.07531596716067379,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04444358463823239,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04444358463823239,
        "precision": 0.04125647503722637,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029957780934343438,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029957780934343438,
        "precision": 0.0026522634054723018,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05890661497790403,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.05890661497790403,
        "precision": 0.055709942258710454,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.0365607441678293,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0365607441678293,
        "precision": 0.03424890689563765,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07720735537429288,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07720735537429288,
        "precision": 0.07398705017918367,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.0781867162408093,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0781867162408093,
        "precision": 0.07383019179894179,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.058468129641151306,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.058468129641151306,
        "precision": 0.055986919030016756,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.09172625590349442,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.09172625590349442,
        "precision": 0.088322406540627,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.051113197990338186,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.051113197990338186,
        "precision": 0.04731364190867162,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0840499686716792,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.0840499686716792,
        "precision": 0.08108554734969493,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07677424396082033,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07677424396082033,
        "precision": 0.07367873975683877,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0543647716549575,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0543647716549575,
        "precision": 0.05177363137435675,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0791751850962459,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0791751850962459,
        "precision": 0.0759061201609886,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0020182291666666664,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020182291666666664,
        "precision": 0.001708984375,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.08383759292922979,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08383759292922979,
        "precision": 0.08088757964600643,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.05315028213902692,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.05315028213902692,
        "precision": 0.05041219655699414,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05756002804356254,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.05756002804356254,
        "precision": 0.05417446385243354,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07031086968730331,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07031086968730331,
        "precision": 0.06758426380751784,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.06024275923154662,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.06024275923154662,
        "precision": 0.05692078590814225,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833333,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9793294270833333,
        "precision": 0.9768880208333333,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8798502604166667,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8798502604166667,
        "precision": 0.8670247395833334,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002674651893439811,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0002674651893439811,
        "precision": 0.0001450105986918047,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8608072916666666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8608072916666666,
        "precision": 0.8465494791666666,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7410016741071428,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7410016741071428,
        "precision": 0.7181477864583333,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.41548626612103173,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.41548626612103173,
        "precision": 0.38763014871413304,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8014322916666666,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8014322916666666,
        "precision": 0.7833170572916667,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.5925579737103175,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5925579737103175,
        "precision": 0.565725368923611,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.654296875,
        "f1": 0.5790876116071428,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5790876116071428,
        "precision": 0.5481329055059524,
        "recall": 0.654296875
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.6984700520833333,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6984700520833333,
        "precision": 0.674755859375,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.970703125,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.970703125,
        "precision": 0.9674479166666666,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8240931919642858,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8240931919642858,
        "precision": 0.8086263020833333,
        "recall": 0.859375
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7885959201388889,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7885959201388889,
        "precision": 0.7711995442708334,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00013030061422159226,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00013030061422159226,
        "precision": 6.793850050420354e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9235026041666666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9235026041666666,
        "precision": 0.9153645833333333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.91064453125,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.91064453125,
        "precision": 0.900390625,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6517182849702381,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.6517182849702381,
        "precision": 0.6271620360975829,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8941080729166666,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8941080729166666,
        "precision": 0.883056640625,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8856119791666667,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8856119791666667,
        "precision": 0.873291015625,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8822265625,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8822265625,
        "precision": 0.8702311197916667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.517053521033474e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 6.517053521033474e-05,
        "precision": 3.304636995902095e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8486979166666666,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8486979166666666,
        "precision": 0.833251953125,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.75126953125,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.75126953125,
        "precision": 0.7293131510416666,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.537109375,
        "f1": 0.46844695560515875,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.46844695560515875,
        "precision": 0.4432919456845238,
        "recall": 0.537109375
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8062499999999999,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8062499999999999,
        "precision": 0.7888997395833333,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.611328125,
        "f1": 0.544438244047619,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.544438244047619,
        "precision": 0.5187031447285353,
        "recall": 0.611328125
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.5905133928571429,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.5905133928571429,
        "precision": 0.5582139756944444,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6943684895833333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6943684895833333,
        "precision": 0.67138671875,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9685872395833333,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9685872395833333,
        "precision": 0.9651692708333334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.861328125,
        "f1": 0.8250325520833333,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8250325520833333,
        "precision": 0.8085774739583333,
        "recall": 0.861328125
      },
      {
        "accuracy": 0.80859375,
        "f1": 0.7619652157738095,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7619652157738095,
        "precision": 0.7409179687499999,
        "recall": 0.80859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011916238837159395,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00011916238837159395,
        "precision": 6.078473179757829e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.90234375,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.90234375,
        "precision": 0.8926106770833333,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.90966796875,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.90966796875,
        "precision": 0.9002278645833333,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.701171875,
        "f1": 0.6366466703869047,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.6366466703869047,
        "precision": 0.6109305245535714,
        "recall": 0.701171875
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8833658854166666,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8833658854166666,
        "precision": 0.871337890625,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8923177083333333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8923177083333333,
        "precision": 0.8814290364583333,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005717714777209969,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0005717714777209969,
        "precision": 0.00036791511633488727,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7868675595238095,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7868675595238095,
        "precision": 0.7727647569444445,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6488018437725469,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.6488018437725469,
        "precision": 0.6270844959077381,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8701488095238095,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8701488095238095,
        "precision": 0.8612386067708333,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.30921820150335777,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.30921820150335777,
        "precision": 0.2862615059636544,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6901340060763889,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.6901340060763889,
        "precision": 0.6703834170386904,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.46875,
        "f1": 0.40291251717032966,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.40291251717032966,
        "precision": 0.3781202900831807,
        "recall": 0.46875
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5228639632936507,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.5228639632936507,
        "precision": 0.4955810546875001,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.6123046875,
        "f1": 0.5528041294642857,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5528041294642857,
        "precision": 0.5283962673611111,
        "recall": 0.6123046875
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8290604848710317,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8290604848710317,
        "precision": 0.8186324114960748,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.768603515625,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.768603515625,
        "precision": 0.7519949776785714,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5926269531249999,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5926269531249999,
        "precision": 0.5691662016369047,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014957812362024815,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0014957812362024815,
        "precision": 0.0010039448375759878,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7205337317136886,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7205337317136886,
        "precision": 0.7046549479166666,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.8001325334821427,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8001325334821427,
        "precision": 0.7861095610119048,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.591796875,
        "f1": 0.5304719206574675,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.5304719206574675,
        "precision": 0.5062755766369047,
        "recall": 0.591796875
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7710672790750915,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.7710672790750915,
        "precision": 0.7556966145833334,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7608568948412698,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7608568948412698,
        "precision": 0.7450788225446429,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9299654150197627e-06,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 1.9299654150197627e-06,
        "precision": 9.659371909000989e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.2380880485614295e-05,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 2.2380880485614295e-05,
        "precision": 1.125861528822055e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2346967963386728e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.2346967963386728e-06,
        "precision": 1.1186282932416954e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.914828431372549e-06,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 1.914828431372549e-06,
        "precision": 9.583537782139352e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010674549624594607,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0010674549624594607,
        "precision": 0.0010237902171517078,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.3731773997569864e-06,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 2.3731773997569864e-06,
        "precision": 1.1880322384428224e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.061324451410658e-06,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 3.061324451410658e-06,
        "precision": 1.5330651491365778e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9357036669970267e-06,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 1.9357036669970267e-06,
        "precision": 9.68812003968254e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.8233595646386345e-05,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 3.8233595646386345e-05,
        "precision": 1.945910701806928e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9110812133072406e-06,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 1.9110812133072406e-06,
        "precision": 9.564764936336925e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04876345890484817,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.04876345890484817,
        "precision": 0.042415146358485756,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00017957450929752066,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00017957450929752066,
        "precision": 9.866613883143744e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1183568329718005e-06,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 2.1183568329718005e-06,
        "precision": 1.060328447339848e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 2.1028268886131787e-05,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 2.1028268886131787e-05,
        "precision": 1.0556982841065839e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5968828846092428e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 1.5968828846092428e-05,
        "precision": 8.03444566538669e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.944620253164557e-06,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 4.944620253164557e-06,
        "precision": 2.4785850253807105e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6852608816964286,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.6852608816964286,
        "precision": 0.6651460193452381,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8477957589285714,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8477957589285714,
        "precision": 0.8380517756982601,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.3180347628015367,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.3180347628015367,
        "precision": 0.2965043325272817,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.7049530564692983,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.7049530564692983,
        "precision": 0.6894422743055555,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.3931693686088217,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.3931693686088217,
        "precision": 0.36807570684523805,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5076543898809524,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.5076543898809524,
        "precision": 0.4809353298611111,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5557212969322345,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5557212969322345,
        "precision": 0.5340603298611111,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8184105282738094,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8184105282738094,
        "precision": 0.8083025698260073,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.761662241838023,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.761662241838023,
        "precision": 0.7454020182291666,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6121930803571428,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.6121930803571428,
        "precision": 0.589311290922619,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00028975214097496705,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.00028975214097496705,
        "precision": 0.00015784876511166482,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.771484375,
        "f1": 0.7376844618055556,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.7376844618055556,
        "precision": 0.7235978951790845,
        "recall": 0.771484375
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7786724668560605,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.7786724668560605,
        "precision": 0.7662662003391473,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5656775841346153,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.5656775841346153,
        "precision": 0.5427920386904761,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7919456845238095,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.7919456845238095,
        "precision": 0.7797309027777778,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7818739149305556,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.7818739149305556,
        "precision": 0.7695723628584956,
        "recall": 0.8125
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.6966208251766616,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.6966208251766616,
        "precision": 0.6786598488136575,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.2089681694173882,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.2089681694173882,
        "precision": 0.1932853577628968,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6250372023809524,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6250372023809524,
        "precision": 0.6060167100694445,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.3349609375,
        "f1": 0.28231685577876986,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.28231685577876986,
        "precision": 0.26421712239583334,
        "recall": 0.3349609375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.4516353546626984,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.4516353546626984,
        "precision": 0.4283989800347222,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.44921875,
        "f1": 0.39857087899080085,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.39857087899080085,
        "precision": 0.38003859747023805,
        "recall": 0.44921875
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6701980364945603,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.6701980364945603,
        "precision": 0.6549152236652237,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6240800865800866,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.6240800865800866,
        "precision": 0.6065140335648148,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.43112993777056274,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.43112993777056274,
        "precision": 0.41046232413419914,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00017336035976890757,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00017336035976890757,
        "precision": 9.132218068955874e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5682168363320707,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.5682168363320707,
        "precision": 0.5496725415426587,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6876240079365079,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.6876240079365079,
        "precision": 0.6721952174040262,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4223082527281746,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.4223082527281746,
        "precision": 0.4004568917410714,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6279720487091411,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.6279720487091411,
        "precision": 0.6088415897253788,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.6982421875,
        "f1": 0.6561732700892857,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.6561732700892857,
        "precision": 0.6392907873376623,
        "recall": 0.6982421875
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.4326622812950938,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.4326622812950938,
        "precision": 0.4031870039682539,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8041666666666667,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8041666666666667,
        "precision": 0.7855631510416666,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.642578125,
        "f1": 0.5760332115800866,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5760332115800866,
        "precision": 0.5493760850694445,
        "recall": 0.642578125
      },
      {
        "accuracy": 0.658203125,
        "f1": 0.5806222098214285,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.5806222098214285,
        "precision": 0.5487141927083333,
        "recall": 0.658203125
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6712425595238095,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6712425595238095,
        "precision": 0.6451985677083334,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9745117187500001,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9745117187500001,
        "precision": 0.9717610677083333,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8233398437499999,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8233398437499999,
        "precision": 0.8067057291666666,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7888857886904762,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7888857886904762,
        "precision": 0.768798828125,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013625843056380192,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00013625843056380192,
        "precision": 7.00003055006131e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.92578125,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.92578125,
        "precision": 0.9171549479166667,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9189127604166667,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9189127604166667,
        "precision": 0.91015625,
        "recall": 0.9375
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6272344680059524,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.6272344680059524,
        "precision": 0.5986909412202381,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8853841145833333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8853841145833333,
        "precision": 0.87353515625,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8876627604166667,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.8876627604166667,
        "precision": 0.87548828125,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.27871935786733093,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.27871935786733093,
        "precision": 0.2639015139485557,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2929225532901489,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.2929225532901489,
        "precision": 0.2823824179292929,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.267578125,
        "f1": 0.22294671979143965,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.22294671979143965,
        "precision": 0.20872868674860012,
        "recall": 0.267578125
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.31431886933595915,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.31431886933595915,
        "precision": 0.30109129833959725,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.390625,
        "f1": 0.3574780324885224,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3574780324885224,
        "precision": 0.3468928205752216,
        "recall": 0.390625
      },
      {
        "accuracy": 0.306640625,
        "f1": 0.26786526732815796,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.26786526732815796,
        "precision": 0.25488526682374335,
        "recall": 0.306640625
      },
      {
        "accuracy": 0.3837890625,
        "f1": 0.3484029121919747,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3484029121919747,
        "precision": 0.33620262815241225,
        "recall": 0.3837890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00012871359481292518,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00012871359481292518,
        "precision": 6.843714448236632e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.3654228305905695,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.3654228305905695,
        "precision": 0.3543225523727948,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.29924943109066904,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.29924943109066904,
        "precision": 0.2884569319492941,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.25341796875,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.25341796875,
        "precision": 0.2413720881982601,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.32128170803244893,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.32128170803244893,
        "precision": 0.31180584148706086,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.3828125,
        "f1": 0.3436359117989354,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.3436359117989354,
        "precision": 0.33078453369829897,
        "recall": 0.3828125
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3482800456921551,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.3482800456921551,
        "precision": 0.3258471292162698,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.525390625,
        "f1": 0.4551022219967532,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.4551022219967532,
        "precision": 0.4282552083333333,
        "recall": 0.525390625
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.4669828869047619,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.4669828869047619,
        "precision": 0.44515206473214286,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.7685546875,
        "f1": 0.7271423075622294,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.7271423075622294,
        "precision": 0.7104142818986567,
        "recall": 0.7685546875
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6692553323412698,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6692553323412698,
        "precision": 0.6475613064236111,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5455171130952381,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.5455171130952381,
        "precision": 0.5222819010416666,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00037056413090420445,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.00037056413090420445,
        "precision": 0.0001973965913987729,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.609327017383658,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.609327017383658,
        "precision": 0.5887951078869048,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7197986421130952,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.7197986421130952,
        "precision": 0.700296843998016,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.4726422991071429,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.4726422991071429,
        "precision": 0.448162780145202,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6633951822916666,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.6633951822916666,
        "precision": 0.6437042124542124,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7118939112103174,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.7118939112103174,
        "precision": 0.6944254557291667,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.3125,
        "f1": 0.2639198811545255,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2639198811545255,
        "precision": 0.2467610433186605,
        "recall": 0.3125
      },
      {
        "accuracy": 0.4716796875,
        "f1": 0.42134016699446386,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.42134016699446386,
        "precision": 0.40376280620421245,
        "recall": 0.4716796875
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5054617325617199,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5054617325617199,
        "precision": 0.4894040890845521,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.3994140625,
        "f1": 0.3506428610834631,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3506428610834631,
        "precision": 0.3350287619798594,
        "recall": 0.3994140625
      },
      {
        "accuracy": 0.5625,
        "f1": 0.5195948040674603,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5195948040674603,
        "precision": 0.5042576753758394,
        "recall": 0.5625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007201465164181624,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007201465164181624,
        "precision": 0.0004076959008443633,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.546875,
        "f1": 0.5053750335854829,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5053750335854829,
        "precision": 0.49113698308743037,
        "recall": 0.546875
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.37577261605581913,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.37577261605581913,
        "precision": 0.35920233033026,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.3759765625,
        "f1": 0.3259500915750916,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.3259500915750916,
        "precision": 0.3090982829019938,
        "recall": 0.3759765625
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.479622882284393,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.479622882284393,
        "precision": 0.4648586453151882,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.4537752666170635,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4537752666170635,
        "precision": 0.4381288767733143,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.3136923650351385,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.3136923650351385,
        "precision": 0.2965304904513889,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.5576171875,
        "f1": 0.5213518451294583,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.5213518451294583,
        "precision": 0.5084833758906024,
        "recall": 0.5576171875
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.46644655257936507,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.46644655257936507,
        "precision": 0.4474961973976993,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.35752315989132394,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.35752315989132394,
        "precision": 0.3405359604779412,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00046463010767967665,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00046463010767967665,
        "precision": 0.00026732227132874426,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.43958732297034103,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.43958732297034103,
        "precision": 0.4260779255089717,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6298041449652778,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.6298041449652778,
        "precision": 0.6164550021453381,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.3935546875,
        "f1": 0.33944498697916664,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.33944498697916664,
        "precision": 0.3192899132309174,
        "recall": 0.3935546875
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.45961714764030615,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.45961714764030615,
        "precision": 0.4440497856635552,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5097447824498605,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5097447824498605,
        "precision": 0.494403605926524,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.623326433821423,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.623326433821423,
        "precision": 0.6115099968773567,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.49723391842532466,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.49723391842532466,
        "precision": 0.4751345063356782,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.61328125,
        "f1": 0.5750279017857143,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5750279017857143,
        "precision": 0.5591482736013986,
        "recall": 0.61328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007598105786254627,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007598105786254627,
        "precision": 0.0005455303127130198,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.6169724742818323,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6169724742818323,
        "precision": 0.6039496058050746,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5224067544868326,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5224067544868326,
        "precision": 0.5036732879750457,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.44159930781024526,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44159930781024526,
        "precision": 0.4230620236967893,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.631653800843254,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.631653800843254,
        "precision": 0.6194286254833129,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.625,
        "f1": 0.580210642222361,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.580210642222361,
        "precision": 0.5634296974940607,
        "recall": 0.625
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7934105282738094,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7934105282738094,
        "precision": 0.7746907552083333,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7566917782738096,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7566917782738096,
        "precision": 0.7365234375,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0009839200792694648,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009839200792694648,
        "precision": 0.0006626007418955688,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9076171875,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9076171875,
        "precision": 0.898193359375,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8882486979166666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8882486979166666,
        "precision": 0.877197265625,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6592385912698412,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6592385912698412,
        "precision": 0.6329857235863096,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8917317708333333,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8917317708333333,
        "precision": 0.8805338541666666,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8722594246031745,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8722594246031745,
        "precision": 0.8607177734375,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5691429501488094,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5691429501488094,
        "precision": 0.5479747953869047,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003761290874880933,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0003761290874880933,
        "precision": 0.00021257377421307505,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6943160187251983,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.6943160187251983,
        "precision": 0.6793805803571429,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.8125,
        "f1": 0.782941158234127,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.782941158234127,
        "precision": 0.770298101963141,
        "recall": 0.8125
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5419634510454823,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.5419634510454823,
        "precision": 0.5196923828125,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.7802734375,
        "f1": 0.7449716605392156,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.7449716605392156,
        "precision": 0.7301717122395833,
        "recall": 0.7802734375
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7522406684027778,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.7522406684027778,
        "precision": 0.7398848276289682,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00040182860538025896,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00040182860538025896,
        "precision": 0.00021747187274531024,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.7646484375,
        "f1": 0.7346082261029412,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7346082261029412,
        "precision": 0.722900144018308,
        "recall": 0.7646484375
      },
      {
        "accuracy": 0.6435546875,
        "f1": 0.6006937398538961,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6006937398538961,
        "precision": 0.5845621744791667,
        "recall": 0.6435546875
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.4772050161210318,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4772050161210318,
        "precision": 0.4553180028521825,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6431240127443023,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6431240127443023,
        "precision": 0.6274349524715735,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6444117731227106,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6444117731227106,
        "precision": 0.6287523239054145,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011955572458868607,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0011955572458868607,
        "precision": 0.0010996242465101524,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787064352360043,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009787064352360043,
        "precision": 0.0009776356456043956,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000995509285234764,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.000995509285234764,
        "precision": 0.0009860687353757621,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014820672535516286,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0014820672535516286,
        "precision": 0.0013107545576501228,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009878195208093523,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0009878195208093523,
        "precision": 0.0009822075553420698,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7639346168154761,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7639346168154761,
        "precision": 0.746347191220238,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.587149677579365,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.587149677579365,
        "precision": 0.5605573381696428,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8114009796626984,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8114009796626984,
        "precision": 0.7966227213541666,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.828125,
        "f1": 0.789391966540404,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.789391966540404,
        "precision": 0.7724202473958333,
        "recall": 0.828125
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5558671254960317,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.5558671254960317,
        "precision": 0.5294677734375,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8142113095238095,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8142113095238095,
        "precision": 0.7981770833333334,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8272786458333333,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8272786458333333,
        "precision": 0.8140834263392858,
        "recall": 0.859375
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.531849135022963,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.531849135022963,
        "precision": 0.5201763649761697,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.5556640625,
        "f1": 0.5174670186584249,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5174670186584249,
        "precision": 0.5042622024315908,
        "recall": 0.5556640625
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.8031933867296919,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8031933867296919,
        "precision": 0.7908650716145833,
        "recall": 0.8310546875
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}