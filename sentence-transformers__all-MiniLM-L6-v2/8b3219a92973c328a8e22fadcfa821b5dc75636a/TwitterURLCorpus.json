{
  "dataset_revision": "8b6510b0b1fa4e4c4f879467980e9be563ec1cdf",
  "evaluation_time": 17.345029592514038,
  "kg_co2_emissions": 0.0025752538607362978,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.882504754142896,
          "accuracy_threshold": 0.659544825553894,
          "ap": 0.847016560244036,
          "f1": 0.7657057281916886,
          "f1_threshold": 0.6311962604522705,
          "precision": 0.745226643346451,
          "recall": 0.7873421619956883
        },
        "dot": {
          "accuracy": 0.882504754142896,
          "accuracy_threshold": 0.6595449447631836,
          "ap": 0.8470165485442009,
          "f1": 0.7657057281916886,
          "f1_threshold": 0.6311962604522705,
          "precision": 0.745226643346451,
          "recall": 0.7873421619956883
        },
        "euclidean": {
          "accuracy": 0.882504754142896,
          "accuracy_threshold": 0.8251729011535645,
          "ap": 0.8470165776928925,
          "f1": 0.7657057281916886,
          "f1_threshold": 0.8588407039642334,
          "precision": 0.745226643346451,
          "recall": 0.7873421619956883
        },
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8470165976888938,
        "manhattan": {
          "accuracy": 0.8827376101214732,
          "accuracy_threshold": 12.611679077148438,
          "ap": 0.8463518544746138,
          "f1": 0.7655138674594514,
          "f1_threshold": 13.285348892211914,
          "precision": 0.7486934118513066,
          "recall": 0.7831074838312289
        },
        "max": {
          "accuracy": 0.8827376101214732,
          "ap": 0.8470165976888938,
          "f1": 0.7657057281916886
        },
        "similarity": {
          "accuracy": 0.882504754142896,
          "accuracy_threshold": 0.6595449447631836,
          "ap": 0.8470165976888938,
          "f1": 0.7657057281916886,
          "f1_threshold": 0.6311963796615601,
          "precision": 0.745226643346451,
          "recall": 0.7873421619956883
        }
      }
    ]
  },
  "task_name": "TwitterURLCorpus"
}