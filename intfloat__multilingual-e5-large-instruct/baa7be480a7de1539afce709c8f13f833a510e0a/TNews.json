{
  "dataset_revision": "317f262bf1e6126357bbe89e875451e4b0938fe4",
  "evaluation_time": 967.1664762496948,
  "kg_co2_emissions": 0.020090183592229416,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "f1_weighted": 0.0,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.0,
        "scores_per_experiment": [
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.49894999999999995,
        "f1": 0.48328351252078827,
        "f1_weighted": 0.5004299442486942,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.49894999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.494,
            "f1": 0.4763657429917386,
            "f1_weighted": 0.49626109783110717
          },
          {
            "accuracy": 0.5015,
            "f1": 0.4812876064474513,
            "f1_weighted": 0.5021910826197361
          },
          {
            "accuracy": 0.506,
            "f1": 0.49198299863806866,
            "f1_weighted": 0.5085486809825316
          },
          {
            "accuracy": 0.5033,
            "f1": 0.4892291780387318,
            "f1_weighted": 0.5068708475570798
          },
          {
            "accuracy": 0.5042,
            "f1": 0.48904795965289133,
            "f1_weighted": 0.506002754498653
          },
          {
            "accuracy": 0.5018,
            "f1": 0.48766378393896376,
            "f1_weighted": 0.5010772913847416
          },
          {
            "accuracy": 0.4956,
            "f1": 0.47800349701318257,
            "f1_weighted": 0.49544905240402576
          },
          {
            "accuracy": 0.4997,
            "f1": 0.4838544991004254,
            "f1_weighted": 0.500444691576007
          },
          {
            "accuracy": 0.4868,
            "f1": 0.47406844970858397,
            "f1_weighted": 0.49033124370986314
          },
          {
            "accuracy": 0.4966,
            "f1": 0.48133140967784555,
            "f1_weighted": 0.49712269992319663
          }
        ]
      }
    ]
  },
  "task_name": "TNews"
}