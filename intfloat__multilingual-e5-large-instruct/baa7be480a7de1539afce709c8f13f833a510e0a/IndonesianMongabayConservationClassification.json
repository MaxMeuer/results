{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 1111.0559120178223,
  "kg_co2_emissions": 0.02314997797949864,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.23643807574206752,
        "f1": 0.2337077702069878,
        "f1_weighted": 0.23522058202423013,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2337077702069878,
        "scores_per_experiment": [
          {
            "accuracy": 0.22824974411463664,
            "f1": 0.23137959357955698,
            "f1_weighted": 0.22626451884389784
          },
          {
            "accuracy": 0.23848515864892528,
            "f1": 0.24271346577993477,
            "f1_weighted": 0.23781679601696398
          },
          {
            "accuracy": 0.2374616171954964,
            "f1": 0.24152130769556476,
            "f1_weighted": 0.23795818921222295
          },
          {
            "accuracy": 0.2047082906857728,
            "f1": 0.20433285744837634,
            "f1_weighted": 0.2137061665915531
          },
          {
            "accuracy": 0.2906857727737973,
            "f1": 0.2985354964054047,
            "f1_weighted": 0.2982040114738282
          },
          {
            "accuracy": 0.21494370522006143,
            "f1": 0.21802905010152437,
            "f1_weighted": 0.22223710423375811
          },
          {
            "accuracy": 0.29273285568065505,
            "f1": 0.28685707757806456,
            "f1_weighted": 0.2961097713803863
          },
          {
            "accuracy": 0.23132036847492324,
            "f1": 0.22228598754184026,
            "f1_weighted": 0.22316816553764554
          },
          {
            "accuracy": 0.22210849539406347,
            "f1": 0.19918147983924842,
            "f1_weighted": 0.20200952057674068
          },
          {
            "accuracy": 0.20368474923234392,
            "f1": 0.1922413861003629,
            "f1_weighted": 0.19473157637530475
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2434959349593496,
        "f1": 0.2364549679569953,
        "f1_weighted": 0.24647523998533544,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2364549679569953,
        "scores_per_experiment": [
          {
            "accuracy": 0.2540650406504065,
            "f1": 0.25133786848072565,
            "f1_weighted": 0.2576583153586638
          },
          {
            "accuracy": 0.2621951219512195,
            "f1": 0.2651854396049485,
            "f1_weighted": 0.26551084780948714
          },
          {
            "accuracy": 0.2459349593495935,
            "f1": 0.2433201653377922,
            "f1_weighted": 0.24833402446621822
          },
          {
            "accuracy": 0.18902439024390244,
            "f1": 0.1893877745133267,
            "f1_weighted": 0.19758608836907418
          },
          {
            "accuracy": 0.2764227642276423,
            "f1": 0.28607278301989764,
            "f1_weighted": 0.29587563106067905
          },
          {
            "accuracy": 0.241869918699187,
            "f1": 0.24394591635970944,
            "f1_weighted": 0.25019249094101914
          },
          {
            "accuracy": 0.2804878048780488,
            "f1": 0.2699335174215656,
            "f1_weighted": 0.2852282934768473
          },
          {
            "accuracy": 0.21747967479674796,
            "f1": 0.2008676481046867,
            "f1_weighted": 0.21325120569319628
          },
          {
            "accuracy": 0.2621951219512195,
            "f1": 0.22894342120481823,
            "f1_weighted": 0.2503783581140195
          },
          {
            "accuracy": 0.20528455284552846,
            "f1": 0.18555514552248245,
            "f1_weighted": 0.20073714456414982
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}