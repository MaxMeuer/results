{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 991.4683396816254,
  "kg_co2_emissions": 0.020416102647611428,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.2894211576846307,
        "f1": 0.23779319667543222,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.23779319667543222,
        "precision": 0.22075533876931083,
        "recall": 0.2894211576846307
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8649161993473371,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8649161993473371,
        "precision": 0.8543199315654404,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.8480372588157019,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8480372588157019,
        "precision": 0.834985584386782,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8135855273579824,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8135855273579824,
        "precision": 0.7992348636061211,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007569192720118491,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.007569192720118491,
        "precision": 0.005625875793360517,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8613883344422265,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8613883344422265,
        "precision": 0.8481370592149036,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.851912048918037,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.851912048918037,
        "precision": 0.8408738079396761,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8815628003252755,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8815628003252755,
        "precision": 0.8715846085606566,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5699479348181943,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5699479348181943,
        "precision": 0.5475659791528055,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.8303393213572854,
        "f1": 0.7969003791359082,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7969003791359082,
        "precision": 0.782651363938789,
        "recall": 0.8303393213572854
      },
      {
        "accuracy": 0.6327345309381237,
        "f1": 0.5823575072078065,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.5823575072078065,
        "precision": 0.5610952697779046,
        "recall": 0.6327345309381237
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7854402306498116,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7854402306498116,
        "precision": 0.7699553274403573,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6294648797642809,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.6294648797642809,
        "precision": 0.609647371922821,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8332372292452133,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8332372292452133,
        "precision": 0.8217176757595919,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8537813262364161,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8537813262364161,
        "precision": 0.8429363495231759,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.7445109780439122,
        "f1": 0.7023524379811804,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.7023524379811804,
        "precision": 0.6844042074580996,
        "recall": 0.7445109780439122
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005221221948094282,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.005221221948094282,
        "precision": 0.0036787172166087537,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.8489687292082502,
        "f1": 0.8205050217026265,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.8205050217026265,
        "precision": 0.8082612552672432,
        "recall": 0.8489687292082502
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.8506447422615089,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8506447422615089,
        "precision": 0.838534043025061,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.7658017298735862,
        "f1": 0.72346418274562,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.72346418274562,
        "precision": 0.7052117986249723,
        "recall": 0.7658017298735862
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8516300731869594,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8516300731869594,
        "precision": 0.8404191616766468,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8325522743686415,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8325522743686415,
        "precision": 0.8219125241580332,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.3153692614770459,
        "f1": 0.26728827046192316,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.26728827046192316,
        "precision": 0.25351558606745145,
        "recall": 0.3153692614770459
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.2306471528065865,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2306471528065865,
        "precision": 0.21760202597112108,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.25681969394544246,
        "f1": 0.20827133710682402,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.20827133710682402,
        "precision": 0.19387192719728372,
        "recall": 0.25681969394544246
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.00807925218515802,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00807925218515802,
        "precision": 0.006546586960758619,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.2634730538922156,
        "f1": 0.21868760582177701,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.21868760582177701,
        "precision": 0.20635021443404675,
        "recall": 0.2634730538922156
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2238203243262534,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2238203243262534,
        "precision": 0.2119441267961494,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.2987358616101131,
        "f1": 0.2502954805425336,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2502954805425336,
        "precision": 0.23575091464313022,
        "recall": 0.2987358616101131
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.18911964100534326,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18911964100534326,
        "precision": 0.17623854973860845,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.27278775781769793,
        "f1": 0.22488202598149187,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22488202598149187,
        "precision": 0.21189399246446916,
        "recall": 0.27278775781769793
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.24695391933415883,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.24695391933415883,
        "precision": 0.23438436391929687,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.2217823603323567,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2217823603323567,
        "precision": 0.21028654040770975,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.25748502994011974,
        "f1": 0.22174270228687712,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.22174270228687712,
        "precision": 0.21003918828270124,
        "recall": 0.25748502994011974
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.2378073519537969,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2378073519537969,
        "precision": 0.22442848328576873,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2188330639084304,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2188330639084304,
        "precision": 0.20576368951784238,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.29740518962075846,
        "f1": 0.2591235186045565,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2591235186045565,
        "precision": 0.24671700308759525,
        "recall": 0.29740518962075846
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.008226454490980589,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008226454490980589,
        "precision": 0.006586426589523842,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.25815036593479707,
        "f1": 0.21629040501910426,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21629040501910426,
        "precision": 0.20440930299902832,
        "recall": 0.25815036593479707
      },
      {
        "accuracy": 0.28077178975382566,
        "f1": 0.23164181986243743,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.23164181986243743,
        "precision": 0.21815155043221912,
        "recall": 0.28077178975382566
      },
      {
        "accuracy": 0.2381902860944777,
        "f1": 0.20014010222015266,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.20014010222015266,
        "precision": 0.1898464295375079,
        "recall": 0.2381902860944777
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.22169230733596057,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.22169230733596057,
        "precision": 0.20857360032343397,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.26280771789753826,
        "f1": 0.2198868575864013,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2198868575864013,
        "precision": 0.2071240433079635,
        "recall": 0.26280771789753826
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9488578398758039,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9488578398758039,
        "precision": 0.9445553337768907,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8690396983810157,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8690396983810157,
        "precision": 0.8594884305463147,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01218699340681584,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01218699340681584,
        "precision": 0.00971180333541983,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9086620409973704,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9086620409973704,
        "precision": 0.9017742293191395,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9278443113772457,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9278443113772457,
        "precision": 0.9222507366219941,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.9627411842980705,
        "f1": 0.9543579507651364,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9543579507651364,
        "precision": 0.9507318695941449,
        "recall": 0.9627411842980705
      },
      {
        "accuracy": 0.7438456420492349,
        "f1": 0.6975651870861451,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6975651870861451,
        "precision": 0.6782443050407122,
        "recall": 0.7438456420492349
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9107024047143807,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9107024047143807,
        "precision": 0.9031825238412065,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6771890082269324,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6771890082269324,
        "precision": 0.6589976132391302,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8847447961220417,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8847447961220417,
        "precision": 0.8763805721889555,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.7458416500332667,
        "f1": 0.7081329404682697,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7081329404682697,
        "precision": 0.6932241337430958,
        "recall": 0.7458416500332667
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9261477045908184,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9261477045908184,
        "precision": 0.9201042359724994,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9163355828026486,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9163355828026486,
        "precision": 0.9097582612552674,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8120605350146268,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8120605350146268,
        "precision": 0.7980206254158351,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.0072708807692516446,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0072708807692516446,
        "precision": 0.005613453365418976,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9103127079174982,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9103127079174982,
        "precision": 0.9031825238412067,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9426258593923265,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9426258593923265,
        "precision": 0.9374584165003327,
        "recall": 0.9540918163672655
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8187545543832969,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8187545543832969,
        "precision": 0.8056965434210942,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9358837879795963,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9358837879795963,
        "precision": 0.9303614992237748,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9269144251180179,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9269144251180179,
        "precision": 0.9215901530272789,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8529306466432215,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8529306466432215,
        "precision": 0.843075753255394,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.010292688125384362,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.010292688125384362,
        "precision": 0.007922212325946849,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9104362703165098,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9104362703165098,
        "precision": 0.9039033045021069,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9365713018407629,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9365713018407629,
        "precision": 0.9310711909514304,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.9733865602129075,
        "f1": 0.9668662674650699,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9668662674650699,
        "precision": 0.9641273009536484,
        "recall": 0.9733865602129075
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.7138342362893261,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.7138342362893261,
        "precision": 0.6954598739029877,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9204828438361371,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9204828438361371,
        "precision": 0.9143379906852961,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.7039254823685961,
        "f1": 0.6598923845430831,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.6598923845430831,
        "precision": 0.6423784945741033,
        "recall": 0.7039254823685961
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8915644900674841,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8915644900674841,
        "precision": 0.8842046066596965,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.67482285586078,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.67482285586078,
        "precision": 0.6575903748059437,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9322022621423819,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9322022621423819,
        "precision": 0.9261698824573076,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9170547793302285,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9170547793302285,
        "precision": 0.9107119095143048,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8102319171181447,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.8102319171181447,
        "precision": 0.7962360992301113,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.00926886999224829,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00926886999224829,
        "precision": 0.00729671341306128,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9260811709913507,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9260811709913507,
        "precision": 0.9203260146373918,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9400088711465956,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9400088711465956,
        "precision": 0.9350742958527388,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8201169090390648,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.8201169090390648,
        "precision": 0.8061052498178245,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9377689066311821,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9377689066311821,
        "precision": 0.9324683965402528,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9300953648259038,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9300953648259038,
        "precision": 0.9245287203371035,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005484929428299056,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.005484929428299056,
        "precision": 0.004063097443110576,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8488134841428253,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8488134841428253,
        "precision": 0.8370148591705477,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8368485251718785,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8368485251718785,
        "precision": 0.8240804106073567,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8708044229002312,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8708044229002312,
        "precision": 0.8607525689362016,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5611306487553993,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5611306487553993,
        "precision": 0.5385079048252701,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.8008797220374066,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8008797220374066,
        "precision": 0.78697235159311,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5761725226795087,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.5761725226795087,
        "precision": 0.557802384648692,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.781360079264271,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.781360079264271,
        "precision": 0.7660409340050061,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.6320691949434465,
        "f1": 0.5844496672839986,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5844496672839986,
        "precision": 0.565360020699342,
        "recall": 0.6320691949434465
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.8235565905226585,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8235565905226585,
        "precision": 0.810568545448785,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.8410987548712101,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8410987548712101,
        "precision": 0.830028831226436,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.7225548902195609,
        "f1": 0.6743048294944503,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.6743048294944503,
        "precision": 0.6549592154852223,
        "recall": 0.7225548902195609
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005817686724267204,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.005817686724267204,
        "precision": 0.004462033907866969,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.806017114400348,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.806017114400348,
        "precision": 0.7925883276182676,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8566031957249521,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8566031957249521,
        "precision": 0.8456365047682414,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7133300498569959,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.7133300498569959,
        "precision": 0.693634952317587,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.839400563951462,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.839400563951462,
        "precision": 0.8276114437791086,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.846307385229541,
        "f1": 0.82154478920946,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.82154478920946,
        "precision": 0.8111998225770681,
        "recall": 0.846307385229541
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006981044375373364,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.006981044375373364,
        "precision": 0.0060018010238775295,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007553882503982303,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.007553882503982303,
        "precision": 0.006993887098540696,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006874298136735769,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.006874298136735769,
        "precision": 0.0058733272893074975,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.005912865031141785,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.005912865031141785,
        "precision": 0.005458147927419909,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005100696695960469,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.005100696695960469,
        "precision": 0.004493134892077397,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005791811411834024,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.005791811411834024,
        "precision": 0.004888703813695827,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0036067848383064447,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0036067848383064447,
        "precision": 0.0027822981040150217,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007960145140684277,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007960145140684277,
        "precision": 0.00682255468333444,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005440697796877278,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005440697796877278,
        "precision": 0.004504486914312654,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004871602955741583,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.004871602955741583,
        "precision": 0.004508357251400576,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006285577738483444,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.006285577738483444,
        "precision": 0.005333798222920145,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.04258150365934797,
        "f1": 0.029537859199573635,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.029537859199573635,
        "precision": 0.026488714104302598,
        "recall": 0.04258150365934797
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005467505927051952,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.005467505927051952,
        "precision": 0.0043321608282547285,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009059503181215369,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.009059503181215369,
        "precision": 0.007791894428779614,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0058438084455356845,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0058438084455356845,
        "precision": 0.005213620037372819,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004855894620809235,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004855894620809235,
        "precision": 0.004164774828714494,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0036940384755443606,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0036940384755443606,
        "precision": 0.003329142275549362,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9109130944460285,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9109130944460285,
        "precision": 0.9033884611728922,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9303076386908722,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9303076386908722,
        "precision": 0.9246174318030606,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6408231156734151,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6408231156734151,
        "precision": 0.6217913379590027,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8597598453885879,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8597598453885879,
        "precision": 0.8502344517314577,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.6340652029274784,
        "f1": 0.5847500765664438,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.5847500765664438,
        "precision": 0.5649528984359323,
        "recall": 0.6340652029274784
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8585980663824975,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8585980663824975,
        "precision": 0.8486138833444223,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6419246163757142,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.6419246163757142,
        "precision": 0.6236484942572768,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8894021480847828,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8894021480847828,
        "precision": 0.8806719893546241,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8895542248835662,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8895542248835662,
        "precision": 0.8811709913506321,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7191163128288877,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.7191163128288877,
        "precision": 0.7012486232017757,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.00558447456500707,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.00558447456500707,
        "precision": 0.004081124963729855,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8695529575769096,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8695529575769096,
        "precision": 0.8601352849855843,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9135506764249279,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9135506764249279,
        "precision": 0.9069305832778888,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7893245255520706,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7893245255520706,
        "precision": 0.7758522877285353,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.9121756487025948,
        "f1": 0.8969320618023213,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8969320618023213,
        "precision": 0.8906021290751829,
        "recall": 0.9121756487025948
      },
      {
        "accuracy": 0.9001996007984032,
        "f1": 0.8831596067125009,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8831596067125009,
        "precision": 0.8762974051896207,
        "recall": 0.9001996007984032
      },
      {
        "accuracy": 0.9667332002661344,
        "f1": 0.9577511643379907,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9577511643379907,
        "precision": 0.9536482590374805,
        "recall": 0.9667332002661344
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.678531825238412,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.678531825238412,
        "precision": 0.6598670384099525,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.904812597028166,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.904812597028166,
        "precision": 0.8970059880239521,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6540031049013084,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.6540031049013084,
        "precision": 0.6359835883787979,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8965624306941672,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8965624306941672,
        "precision": 0.8879463295630959,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.7318695941450433,
        "f1": 0.6890330450210689,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.6890330450210689,
        "precision": 0.671919412737776,
        "recall": 0.7318695941450433
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.933954313595032,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.933954313595032,
        "precision": 0.9284209359059659,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9157019294743846,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9157019294743846,
        "precision": 0.9092038145930361,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7849560138981296,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.7849560138981296,
        "precision": 0.7694111776447106,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.00889930508600242,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00889930508600242,
        "precision": 0.006907883302798785,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.916566866267465,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.916566866267465,
        "precision": 0.9097582612552674,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9403193612774451,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9403193612774451,
        "precision": 0.9350188511865158,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8277497914224461,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.8277497914224461,
        "precision": 0.8166500332667999,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9333333333333333,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9333333333333333,
        "precision": 0.9275005544466622,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.925361974463771,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.925361974463771,
        "precision": 0.9202373031714348,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6907248994075341,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.6907248994075341,
        "precision": 0.6718272449809376,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.914748281215347,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.914748281215347,
        "precision": 0.9072410734087382,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6459281335470134,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.6459281335470134,
        "precision": 0.6274558026803536,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8979110561944893,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8979110561944893,
        "precision": 0.8907314999630368,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6885937600508458,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6885937600508458,
        "precision": 0.6734443404603084,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.941029053005101,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.941029053005101,
        "precision": 0.9362053670436905,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9309603016189842,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9309603016189842,
        "precision": 0.9251607895320471,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.8423153692614771,
        "f1": 0.8071872128758355,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.8071872128758355,
        "precision": 0.7928447338127976,
        "recall": 0.8423153692614771
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.0063715674363289,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0063715674363289,
        "precision": 0.005203616849653895,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9248835662009314,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9248835662009314,
        "precision": 0.918651585717454,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.955511199822577,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.955511199822577,
        "precision": 0.9514304723885563,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8389227317371031,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.8389227317371031,
        "precision": 0.8273468935145581,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.948502994011976,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.948502994011976,
        "precision": 0.9441117764471058,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9268589804517949,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9268589804517949,
        "precision": 0.9218848018249216,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.687433118371242,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.687433118371242,
        "precision": 0.6684348474767637,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.4920355057081604,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.4920355057081604,
        "precision": 0.47206330484773595,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6375613851661756,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6375613851661756,
        "precision": 0.617718531191585,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.4737773130986704,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.4737773130986704,
        "precision": 0.45359598263789874,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.6825322899175195,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.6825322899175195,
        "precision": 0.6652750055444666,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.6679973386560213,
        "f1": 0.6198988266852538,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6198988266852538,
        "precision": 0.599740994202072,
        "recall": 0.6679973386560213
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5583626397997655,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.5583626397997655,
        "precision": 0.5396223426163546,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.00773111921351612,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00773111921351612,
        "precision": 0.005772985732012873,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.716566866267465,
        "f1": 0.6686748676768637,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.6686748676768637,
        "precision": 0.6486927853694321,
        "recall": 0.716566866267465
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6752732629978139,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6752732629978139,
        "precision": 0.6559463084413184,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.603459747172322,
        "f1": 0.5419558670057673,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.5419558670057673,
        "precision": 0.5178946340123985,
        "recall": 0.603459747172322
      },
      {
        "accuracy": 0.7125748502994012,
        "f1": 0.6672021037290498,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6672021037290498,
        "precision": 0.6486759525681681,
        "recall": 0.7125748502994012
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6552588425841919,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6552588425841919,
        "precision": 0.6381607396078454,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.675808700060197,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.675808700060197,
        "precision": 0.6549681301178307,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8714127300953647,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8714127300953647,
        "precision": 0.8612663561765358,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6670669723563936,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6670669723563936,
        "precision": 0.6505177069548326,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9257611760605772,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9257611760605772,
        "precision": 0.919738301175427,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8925260589931249,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8925260589931249,
        "precision": 0.8839432246617875,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7893213572854291,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.7893213572854291,
        "precision": 0.7737255647435288,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.011020202536462739,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.011020202536462739,
        "precision": 0.008731498561514173,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9099135063206919,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9099135063206919,
        "precision": 0.9023286759813705,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9210467952982923,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9210467952982923,
        "precision": 0.914604125083167,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.8323353293413174,
        "f1": 0.7955343281690587,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7955343281690587,
        "precision": 0.7799686341602509,
        "recall": 0.8323353293413174
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9163672654690619,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9163672654690619,
        "precision": 0.9099578620536704,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9192187054462504,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9192187054462504,
        "precision": 0.9126192060323798,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6104811540939284,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6104811540939284,
        "precision": 0.5915317753142104,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.58416500332668,
        "f1": 0.5320882045432943,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5320882045432943,
        "precision": 0.512540551412807,
        "recall": 0.58416500332668
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.6420699246048547,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6420699246048547,
        "precision": 0.6235626630337209,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.6733200266134398,
        "f1": 0.6233654864393388,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6233654864393388,
        "precision": 0.604429460167983,
        "recall": 0.6733200266134398
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6243724191827985,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6243724191827985,
        "precision": 0.6060667265757086,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.003178428541041605,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003178428541041605,
        "precision": 0.002189185055382368,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6414927240276541,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6414927240276541,
        "precision": 0.6212804549630897,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.6966067864271457,
        "f1": 0.6436365364509077,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6436365364509077,
        "precision": 0.6233408677520454,
        "recall": 0.6966067864271457
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5247858779794907,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.5247858779794907,
        "precision": 0.5038415066858181,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.639743264793165,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.639743264793165,
        "precision": 0.6210754589280147,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6623757775454382,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6623757775454382,
        "precision": 0.6446437812206275,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6533393530399518,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6533393530399518,
        "precision": 0.6345114004794644,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8927700155245066,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8927700155245066,
        "precision": 0.8851408294522066,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8643543600629429,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8643543600629429,
        "precision": 0.8542145866996166,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.7890884896872921,
        "f1": 0.7496741965803843,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7496741965803843,
        "precision": 0.7337269904635173,
        "recall": 0.7890884896872921
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008949279053498533,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008949279053498533,
        "precision": 0.007209282899708304,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.874685549535849,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.874685549535849,
        "precision": 0.8654357950765137,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9067991002122737,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9067991002122737,
        "precision": 0.8983144821468174,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7940299295588717,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7940299295588717,
        "precision": 0.780696015376654,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9032157906409404,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9032157906409404,
        "precision": 0.8953980927034819,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8855843867819916,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8855843867819916,
        "precision": 0.8777888667110224,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.7258815701929474,
        "f1": 0.6809666381522669,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6809666381522669,
        "precision": 0.6635253302917974,
        "recall": 0.7258815701929474
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6518069680744331,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6518069680744331,
        "precision": 0.6319091974780598,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.5972371902511623,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5972371902511623,
        "precision": 0.5765022864324262,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.009505851413417305,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009505851413417305,
        "precision": 0.007321810376457668,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6618126181499435,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6618126181499435,
        "precision": 0.643248687809566,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.6777614084001309,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6777614084001309,
        "precision": 0.657991952602731,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.6280771789753826,
        "f1": 0.5756624797542961,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.5756624797542961,
        "precision": 0.5554972066449112,
        "recall": 0.6280771789753826
      },
      {
        "accuracy": 0.7671324018629407,
        "f1": 0.7214066575843023,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7214066575843023,
        "precision": 0.7031951969077718,
        "recall": 0.7671324018629407
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.6845333143237334,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6845333143237334,
        "precision": 0.6681905623023388,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9044023064981148,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9044023064981148,
        "precision": 0.8954931407027215,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7893134366188259,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7893134366188259,
        "precision": 0.7742974368722871,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.00891688005434504,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00891688005434504,
        "precision": 0.0074318334250408164,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.915302727877578,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.915302727877578,
        "precision": 0.9084830339321356,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9375027722333111,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9375027722333111,
        "precision": 0.931991572410734,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.863606121091151,
        "f1": 0.833236701200773,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.833236701200773,
        "precision": 0.820498685169344,
        "recall": 0.863606121091151
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9289326109685391,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9289326109685391,
        "precision": 0.9240075404746063,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9222444000887113,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9222444000887113,
        "precision": 0.9165446884009758,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.7332905617336754,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.7332905617336754,
        "precision": 0.7147120128998476,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007072510904206155,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.007072510904206155,
        "precision": 0.005663545378510579,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.879047196612067,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.879047196612067,
        "precision": 0.8702872033710356,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9241516966067864,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9241516966067864,
        "precision": 0.918385451319583,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8064347495485221,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.8064347495485221,
        "precision": 0.7926923929917941,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053131831574945,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9053131831574945,
        "precision": 0.8973719228210246,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9046277814740888,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9046277814740888,
        "precision": 0.8984198270126414,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.010622327066809791,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010622327066809791,
        "precision": 0.0084968102110938,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7874695054335773,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7874695054335773,
        "precision": 0.7706660752568937,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.7979057757500871,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7979057757500871,
        "precision": 0.7815147482812153,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.6554758208450823,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6554758208450823,
        "precision": 0.6334616481323069,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7893250535965107,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7893250535965107,
        "precision": 0.773325571080062,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.8349966733200266,
        "f1": 0.8026840978936786,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8026840978936786,
        "precision": 0.7890552228875581,
        "recall": 0.8349966733200266
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006950569831690684,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.006950569831690684,
        "precision": 0.00586736485757037,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0056794324573608375,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0056794324573608375,
        "precision": 0.004695781848908974,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006040717403287407,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.006040717403287407,
        "precision": 0.005275615582882696,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005454394126116676,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.005454394126116676,
        "precision": 0.004939098682927858,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004253610297556834,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004253610297556834,
        "precision": 0.003915759399545924,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9127871241643697,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9127871241643697,
        "precision": 0.9048569527611444,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7992500956572813,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7992500956572813,
        "precision": 0.7843646041250832,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9078858156702467,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9078858156702467,
        "precision": 0.900443557329785,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9026613439787092,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9026613439787092,
        "precision": 0.8951763140385895,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8169708202642334,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.8169708202642334,
        "precision": 0.804759792584144,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9224788518201692,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9224788518201692,
        "precision": 0.9168219117320914,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9202990843709405,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9202990843709405,
        "precision": 0.9153359946773121,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8362633706945084,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8362633706945084,
        "precision": 0.8254443493964452,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.8283433133732535,
        "f1": 0.8012013011015007,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8012013011015007,
        "precision": 0.7897989734816082,
        "recall": 0.8283433133732535
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9290973608338877,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9290973608338877,
        "precision": 0.9241516966067864,
        "recall": 0.9407850964737192
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}