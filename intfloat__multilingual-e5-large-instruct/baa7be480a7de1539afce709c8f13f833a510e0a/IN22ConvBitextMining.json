{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 59.290581464767456,
  "kg_co2_emissions": 0.013270833532756838,
  "mteb_version": "1.12.66",
  "scores": {
    "test": [
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9067991002122737,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9067991002122737,
        "precision": 0.8983144821468174,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.28875582168995345,
        "f1": 0.23828022589910575,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.23828022589910575,
        "precision": 0.22100283559864398,
        "recall": 0.28875582168995345
      },
      {
        "accuracy": 0.7890884896872921,
        "f1": 0.7496741965803843,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7496741965803843,
        "precision": 0.7337269904635173,
        "recall": 0.7890884896872921
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9254601907296518,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9254601907296518,
        "precision": 0.9182967398536259,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6533393530399518,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6533393530399518,
        "precision": 0.6345114004794644,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8855843867819916,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8855843867819916,
        "precision": 0.8777888667110224,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9034280645059087,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9034280645059087,
        "precision": 0.8957307607008206,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7808636694864238,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7808636694864238,
        "precision": 0.7664744584904264,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.6852960745176314,
        "f1": 0.6383603164042285,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6383603164042285,
        "precision": 0.6188456420492349,
        "recall": 0.6852960745176314
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.874685549535849,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.874685549535849,
        "precision": 0.8654357950765137,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8643543600629429,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8643543600629429,
        "precision": 0.8542145866996166,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9032157906409404,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9032157906409404,
        "precision": 0.8953980927034819,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.012401159237245185,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.012401159237245185,
        "precision": 0.010002443126880527,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8927700155245066,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8927700155245066,
        "precision": 0.8851408294522066,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9072299844754934,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9072299844754934,
        "precision": 0.8992792193390997,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8644636652620685,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8644636652620685,
        "precision": 0.8546407185628743,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7940299295588717,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7940299295588717,
        "precision": 0.7806960153766541,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.00900472371972164,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00900472371972164,
        "precision": 0.0072473020994041504,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6103982511168139,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.6103982511168139,
        "precision": 0.5897538256819694,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7944534211999281,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.7944534211999281,
        "precision": 0.7799955644267023,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8682096125209896,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8682096125209896,
        "precision": 0.8586382789975604,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9039920159680638,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9039920159680638,
        "precision": 0.8955976935018851,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8874283179672402,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8874283179672402,
        "precision": 0.8799512086937237,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.2907518296739854,
        "f1": 0.23931031635622452,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.23931031635622452,
        "precision": 0.22219448327232752,
        "recall": 0.2907518296739854
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7654548046763615,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7654548046763615,
        "precision": 0.7496588832916178,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.9627411842980705,
        "f1": 0.9544023064981149,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9544023064981149,
        "precision": 0.9507873142603681,
        "recall": 0.9627411842980705
      },
      {
        "accuracy": 0.7172322022621423,
        "f1": 0.6751122094435467,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6751122094435467,
        "precision": 0.6580386845356905,
        "recall": 0.7172322022621423
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9202990843709405,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9202990843709405,
        "precision": 0.9153359946773121,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9478154801508094,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9478154801508094,
        "precision": 0.9429696163229098,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8297933234060978,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8297933234060978,
        "precision": 0.8175482368596142,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.7178975382568197,
        "f1": 0.6702109009494239,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6702109009494239,
        "precision": 0.6509111406815997,
        "recall": 0.7178975382568197
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9053892215568862,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9053892215568862,
        "precision": 0.8980483477489466,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9131514748281215,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9131514748281215,
        "precision": 0.90645375914837,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9224788518201692,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9224788518201692,
        "precision": 0.9168219117320914,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.011335279959407212,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.011335279959407212,
        "precision": 0.009063266676823887,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9258150365934797,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9258150365934797,
        "precision": 0.9202373031714348,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.930671989354624,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.930671989354624,
        "precision": 0.9239299179418939,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9037147926369483,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9037147926369483,
        "precision": 0.8961806545638882,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8169708202642334,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.8169708202642334,
        "precision": 0.804759792584144,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006065281089350597,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.006065281089350597,
        "precision": 0.0045769327417932255,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6477705963733907,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.6477705963733907,
        "precision": 0.6294197319646421,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.8762475049900199,
        "f1": 0.8523286759813705,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8523286759813705,
        "precision": 0.8418190074876701,
        "recall": 0.8762475049900199
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.90016791813199,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.90016791813199,
        "precision": 0.8916056775338214,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.9600798403193613,
        "f1": 0.9499667332002663,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9499667332002663,
        "precision": 0.945220669771568,
        "recall": 0.9600798403193613
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.2217823603323567,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2217823603323567,
        "precision": 0.21028654040770975,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.28077178975382566,
        "f1": 0.23164181986243743,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.23164181986243743,
        "precision": 0.21815155043221912,
        "recall": 0.28077178975382566
      },
      {
        "accuracy": 0.29740518962075846,
        "f1": 0.2591235186045565,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2591235186045565,
        "precision": 0.24671700308759525,
        "recall": 0.29740518962075846
      },
      {
        "accuracy": 0.2987358616101131,
        "f1": 0.2502954805425336,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2502954805425336,
        "precision": 0.23575091464313022,
        "recall": 0.2987358616101131
      },
      {
        "accuracy": 0.25748502994011974,
        "f1": 0.22174270228687712,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.22174270228687712,
        "precision": 0.21003918828270124,
        "recall": 0.25748502994011974
      },
      {
        "accuracy": 0.26280771789753826,
        "f1": 0.2198868575864013,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2198868575864013,
        "precision": 0.2071240433079635,
        "recall": 0.26280771789753826
      },
      {
        "accuracy": 0.3153692614770459,
        "f1": 0.26728827046192316,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.26728827046192316,
        "precision": 0.25351558606745145,
        "recall": 0.3153692614770459
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.21719746992725167,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.21719746992725167,
        "precision": 0.2059094773416131,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.18911964100534326,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18911964100534326,
        "precision": 0.17623854973860845,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.25815036593479707,
        "f1": 0.21629040501910426,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21629040501910426,
        "precision": 0.20440930299902832,
        "recall": 0.25815036593479707
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2188330639084304,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2188330639084304,
        "precision": 0.20576368951784238,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.22169230733596057,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.22169230733596057,
        "precision": 0.20857360032343397,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.00807925218515802,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00807925218515802,
        "precision": 0.006546586960758619,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.2378073519537969,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2378073519537969,
        "precision": 0.22442848328576873,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2238203243262534,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2238203243262534,
        "precision": 0.2119441267961494,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.27278775781769793,
        "f1": 0.22488202598149187,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22488202598149187,
        "precision": 0.21189399246446916,
        "recall": 0.27278775781769793
      },
      {
        "accuracy": 0.2381902860944777,
        "f1": 0.20014010222015266,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.20014010222015266,
        "precision": 0.1898464295375079,
        "recall": 0.2381902860944777
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.008226454490980589,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008226454490980589,
        "precision": 0.006586426589523842,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.24695391933415883,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.24695391933415883,
        "precision": 0.23438436391929687,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.25681969394544246,
        "f1": 0.20827133710682402,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.20827133710682402,
        "precision": 0.19387192719728372,
        "recall": 0.25681969394544246
      },
      {
        "accuracy": 0.2634730538922156,
        "f1": 0.21868760582177701,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.21868760582177701,
        "precision": 0.20635021443404675,
        "recall": 0.2634730538922156
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.2306471528065865,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2306471528065865,
        "precision": 0.21760202597112108,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.7857618097139055,
        "f1": 0.7431929791211229,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7431929791211229,
        "precision": 0.7251386116655577,
        "recall": 0.7857618097139055
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.7979057757500871,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7979057757500871,
        "precision": 0.7815147482812153,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.3073852295409182,
        "f1": 0.25494624027558155,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25494624027558155,
        "precision": 0.23643533039740622,
        "recall": 0.3073852295409182
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8386370116909039,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8386370116909039,
        "precision": 0.8261160219244051,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.6373918829008649,
        "f1": 0.5845498664859943,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5845498664859943,
        "precision": 0.5625180855220776,
        "recall": 0.6373918829008649
      },
      {
        "accuracy": 0.8349966733200266,
        "f1": 0.8026840978936786,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8026840978936786,
        "precision": 0.7890552228875581,
        "recall": 0.8349966733200266
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.8356081487818015,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8356081487818015,
        "precision": 0.8218895542248835,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.685602340292959,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.685602340292959,
        "precision": 0.6685240629851408,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5561232033287922,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5561232033287922,
        "precision": 0.5326540041609902,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7874695054335773,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7874695054335773,
        "precision": 0.7706660752568937,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7412207331369008,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7412207331369008,
        "precision": 0.721686785159839,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7893250535965107,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7893250535965107,
        "precision": 0.773325571080062,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.010075345655447106,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010075345655447106,
        "precision": 0.008367720407804325,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7874251497005988,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7874251497005988,
        "precision": 0.7714681747615879,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.8020361393614888,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8020361393614888,
        "precision": 0.7871423819028608,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.8190286094477711,
        "f1": 0.7830503015133753,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7830503015133753,
        "precision": 0.7677430852580553,
        "recall": 0.8190286094477711
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.6554758208450823,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6554758208450823,
        "precision": 0.6334616481323069,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.010397860175676232,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010397860175676232,
        "precision": 0.008356350389995255,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.6813040585495675,
        "f1": 0.6311984496615235,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6311984496615235,
        "precision": 0.610791908246998,
        "recall": 0.6813040585495675
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6712300747230886,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6712300747230886,
        "precision": 0.6507104837943161,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.7764471057884231,
        "f1": 0.7320375122770332,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7320375122770332,
        "precision": 0.7127411842980705,
        "recall": 0.7764471057884231
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8136504768241294,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8136504768241294,
        "precision": 0.7977109273516458,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8979110561944893,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8979110561944893,
        "precision": 0.8907314999630368,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9654025282767797,
        "f1": 0.9561765358172543,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9561765358172543,
        "precision": 0.9520958083832335,
        "recall": 0.9654025282767797
      },
      {
        "accuracy": 0.30206254158349966,
        "f1": 0.23827868184155607,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.23827868184155607,
        "precision": 0.2164437651246642,
        "recall": 0.30206254158349966
      },
      {
        "accuracy": 0.8423153692614771,
        "f1": 0.8071872128758355,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.8071872128758355,
        "precision": 0.7928447338127976,
        "recall": 0.8423153692614771
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6885937600508458,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6885937600508458,
        "precision": 0.6734443404603084,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9268589804517949,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9268589804517949,
        "precision": 0.9218848018249216,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.9680638722554891,
        "f1": 0.9600354845863829,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9600354845863829,
        "precision": 0.9566422710135286,
        "recall": 0.9680638722554891
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8510793228358099,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.8510793228358099,
        "precision": 0.8403829906324917,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6907248994075341,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.6907248994075341,
        "precision": 0.6718272449809376,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9248835662009314,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9248835662009314,
        "precision": 0.918651585717454,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9309603016189842,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9309603016189842,
        "precision": 0.9251607895320471,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.948502994011976,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.948502994011976,
        "precision": 0.9441117764471058,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.011891654937441641,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.011891654937441641,
        "precision": 0.010006662363603678,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.941029053005101,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.941029053005101,
        "precision": 0.9362053670436905,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.9634065202927479,
        "f1": 0.9542692392991794,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9542692392991794,
        "precision": 0.9504546462630294,
        "recall": 0.9634065202927479
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9152583721445996,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9152583721445996,
        "precision": 0.9078509647371923,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8395437119988018,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.8395437119988018,
        "precision": 0.8278458955105662,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007036903431006212,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007036903431006212,
        "precision": 0.005868952844331208,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6459281335470134,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.6459281335470134,
        "precision": 0.6274558026803536,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.8786981592370814,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8786981592370814,
        "precision": 0.8698444381079111,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.924097836073884,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.924097836073884,
        "precision": 0.9182967398536261,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.9753825681969395,
        "f1": 0.9695497893102684,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9695497893102684,
        "precision": 0.9671213129296962,
        "recall": 0.9753825681969395
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6405431708824922,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6405431708824922,
        "precision": 0.6225414490883553,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.6777614084001309,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6777614084001309,
        "precision": 0.657991952602731,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.281437125748503,
        "f1": 0.23201115805906222,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23201115805906222,
        "precision": 0.2140319889321885,
        "recall": 0.281437125748503
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.5972371902511623,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5972371902511623,
        "precision": 0.5765022864324262,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.7571523619427811,
        "f1": 0.7109975815564638,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7109975815564638,
        "precision": 0.6922385387954251,
        "recall": 0.7571523619427811
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.6845333143237334,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6845333143237334,
        "precision": 0.6681905623023388,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.7431803060545575,
        "f1": 0.6993161012123088,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6993161012123088,
        "precision": 0.6829563096030162,
        "recall": 0.7431803060545575
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6116132813737604,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6116132813737604,
        "precision": 0.5931882267211609,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.4772169945822641,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4772169945822641,
        "precision": 0.4560286833739927,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6618126181499435,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6618126181499435,
        "precision": 0.643248687809566,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6518069680744331,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6518069680744331,
        "precision": 0.6319091974780598,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.7671324018629407,
        "f1": 0.7214066575843023,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7214066575843023,
        "precision": 0.7031951969077718,
        "recall": 0.7671324018629407
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.01404412812377445,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01404412812377445,
        "precision": 0.011383084535339727,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.7258815701929474,
        "f1": 0.6809666381522669,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6809666381522669,
        "precision": 0.6635253302917974,
        "recall": 0.7258815701929474
      },
      {
        "accuracy": 0.7245508982035929,
        "f1": 0.6790418829340985,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6790418829340985,
        "precision": 0.6613281373760415,
        "recall": 0.7245508982035929
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6417223753551099,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6417223753551099,
        "precision": 0.6237267309593246,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.6280771789753826,
        "f1": 0.5756624797542961,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.5756624797542961,
        "precision": 0.5554972066449112,
        "recall": 0.6280771789753826
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.009524332968825008,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009524332968825008,
        "precision": 0.007333691376362621,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.5881570192947438,
        "f1": 0.5408357887399804,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5408357887399804,
        "precision": 0.5219782656908405,
        "recall": 0.5881570192947438
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.5519896714507493,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5519896714507493,
        "precision": 0.5307411631762929,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.6912840984697272,
        "f1": 0.6424822313045866,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6424822313045866,
        "precision": 0.6242918924056648,
        "recall": 0.6912840984697272
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.665004910813294,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.665004910813294,
        "precision": 0.6450451189972147,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8888223552894211,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8888223552894211,
        "precision": 0.8792636948325571,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.928587269904635,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.928587269904635,
        "precision": 0.9219560878243511,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.3147039254823686,
        "f1": 0.25982074274900385,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.25982074274900385,
        "precision": 0.240808486442219,
        "recall": 0.3147039254823686
      },
      {
        "accuracy": 0.8290086493679308,
        "f1": 0.7924531888603745,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.7924531888603745,
        "precision": 0.7770237303171434,
        "recall": 0.8290086493679308
      },
      {
        "accuracy": 0.9534264803725881,
        "f1": 0.9426702151253049,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9426702151253049,
        "precision": 0.9377023730317144,
        "recall": 0.9534264803725881
      },
      {
        "accuracy": 0.7518296739853626,
        "f1": 0.7055561316040359,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.7055561316040359,
        "precision": 0.6865406752632301,
        "recall": 0.7518296739853626
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9403098564775211,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9403098564775211,
        "precision": 0.9349079618540695,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.8356952761144377,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8356952761144377,
        "precision": 0.8228495390172037,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.6794110192313785,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.6794110192313785,
        "precision": 0.6583502547574404,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9220131166238951,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.9220131166238951,
        "precision": 0.9149700598802394,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9061100022177867,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9061100022177867,
        "precision": 0.8979659728162722,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9356287425149701,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9356287425149701,
        "precision": 0.9303678357570573,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007174236753848271,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.007174236753848271,
        "precision": 0.005421743437668211,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9285650920381459,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9285650920381459,
        "precision": 0.9221556886227545,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9278237176440769,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9278237176440769,
        "precision": 0.9220115324905744,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9060672306181288,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9060672306181288,
        "precision": 0.8978154801508094,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8416500332667998,
        "f1": 0.8066755378132624,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.8066755378132624,
        "precision": 0.7913838988689287,
        "recall": 0.8416500332667998
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.008834803012040026,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.008834803012040026,
        "precision": 0.007189824577024895,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.7458416500332667,
        "f1": 0.7014342167036779,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.7014342167036779,
        "precision": 0.6831955137344359,
        "recall": 0.7458416500332667
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8314978508591284,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.8314978508591284,
        "precision": 0.8180583277888666,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8865380350410291,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8865380350410291,
        "precision": 0.8762696828565092,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.9547571523619428,
        "f1": 0.9436365364509076,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9436365364509076,
        "precision": 0.9383455311599025,
        "recall": 0.9547571523619428
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8847447961220417,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8847447961220417,
        "precision": 0.8763805721889555,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9427367487247728,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9427367487247728,
        "precision": 0.937569305832779,
        "recall": 0.9540918163672655
      },
      {
        "accuracy": 0.31736526946107785,
        "f1": 0.25862358976131433,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25862358976131433,
        "precision": 0.23742698123935646,
        "recall": 0.31736526946107785
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8120605350146268,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8120605350146268,
        "precision": 0.7980206254158351,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.9627411842980705,
        "f1": 0.9543579507651364,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9543579507651364,
        "precision": 0.9507318695941449,
        "recall": 0.9627411842980705
      },
      {
        "accuracy": 0.7458416500332667,
        "f1": 0.7081329404682697,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7081329404682697,
        "precision": 0.6932241337430958,
        "recall": 0.7458416500332667
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9269144251180179,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9269144251180179,
        "precision": 0.9215901530272789,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8506278448394218,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8506278448394218,
        "precision": 0.8403249057440674,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.7438456420492349,
        "f1": 0.6975651870861451,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6975651870861451,
        "precision": 0.6782443050407122,
        "recall": 0.7438456420492349
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9103127079174982,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9103127079174982,
        "precision": 0.9031825238412067,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9163355828026486,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9163355828026486,
        "precision": 0.9097582612552674,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9358837879795963,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9358837879795963,
        "precision": 0.9303614992237748,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.012434838265439141,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.012434838265439141,
        "precision": 0.010061535710072952,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9261477045908184,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9261477045908184,
        "precision": 0.9201042359724994,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9278443113772457,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9278443113772457,
        "precision": 0.9222507366219941,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9105123087159015,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9105123087159015,
        "precision": 0.9030716345087603,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8194198903779742,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8194198903779742,
        "precision": 0.8063618794157715,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007949864681768492,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007949864681768492,
        "precision": 0.00628671002669959,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6771890082269324,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6771890082269324,
        "precision": 0.6589976132391302,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8690396983810157,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8690396983810157,
        "precision": 0.8594884305463147,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9086620409973704,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9086620409973704,
        "precision": 0.9017742293191395,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9489687292082502,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9489687292082502,
        "precision": 0.944666223109337,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7854402306498116,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7854402306498116,
        "precision": 0.7699553274403573,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.8506447422615089,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8506447422615089,
        "precision": 0.838534043025061,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.2894211576846307,
        "f1": 0.23779319667543222,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.23779319667543222,
        "precision": 0.22075533876931083,
        "recall": 0.2894211576846307
      },
      {
        "accuracy": 0.7445109780439122,
        "f1": 0.7023524379811804,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.7023524379811804,
        "precision": 0.6844042074580996,
        "recall": 0.7445109780439122
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8815628003252755,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8815628003252755,
        "precision": 0.8715846085606566,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6294648797642809,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.6294648797642809,
        "precision": 0.609647371922821,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8325522743686415,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8325522743686415,
        "precision": 0.8219125241580332,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8656924246744606,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8656924246744606,
        "precision": 0.855096156892564,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5699479348181943,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5699479348181943,
        "precision": 0.5475659791528055,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.8489687292082502,
        "f1": 0.8205050217026265,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.8205050217026265,
        "precision": 0.8082612552672432,
        "recall": 0.8489687292082502
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8537813262364161,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8537813262364161,
        "precision": 0.8429363495231759,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8516300731869594,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8516300731869594,
        "precision": 0.8404191616766468,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008012750049903365,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.008012750049903365,
        "precision": 0.005958543790699173,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8332372292452133,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8332372292452133,
        "precision": 0.8217176757595919,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.851912048918037,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.851912048918037,
        "precision": 0.8408738079396761,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.8303393213572854,
        "f1": 0.7969003791359082,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7969003791359082,
        "precision": 0.782651363938789,
        "recall": 0.8303393213572854
      },
      {
        "accuracy": 0.7664670658682635,
        "f1": 0.7241295187402973,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.7241295187402973,
        "precision": 0.7058771346196496,
        "recall": 0.7664670658682635
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005276666614317391,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.005276666614317391,
        "precision": 0.0037167364163046,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.6327345309381237,
        "f1": 0.5823575072078065,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.5823575072078065,
        "precision": 0.5610952697779046,
        "recall": 0.6327345309381237
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8135855273579824,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8135855273579824,
        "precision": 0.7992348636061211,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8613883344422265,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8613883344422265,
        "precision": 0.8481370592149036,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.8480372588157019,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8480372588157019,
        "precision": 0.834985584386782,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6375613851661756,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6375613851661756,
        "precision": 0.617718531191585,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6752732629978139,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6752732629978139,
        "precision": 0.6559463084413184,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.20511306908512494,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.20511306908512494,
        "precision": 0.188558069047091,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5583626397997655,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.5583626397997655,
        "precision": 0.5396223426163546,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.7445109780439122,
        "f1": 0.6932040680543675,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6932040680543675,
        "precision": 0.6727212242182302,
        "recall": 0.7445109780439122
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.4737773130986704,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.4737773130986704,
        "precision": 0.45359598263789874,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6552588425841919,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6552588425841919,
        "precision": 0.6381607396078454,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.6822829717041293,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.6822829717041293,
        "precision": 0.6628992929891133,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5556157526217406,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5556157526217406,
        "precision": 0.5381160958506268,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.716566866267465,
        "f1": 0.6686748676768637,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.6686748676768637,
        "precision": 0.6486927853694321,
        "recall": 0.716566866267465
      },
      {
        "accuracy": 0.6679973386560213,
        "f1": 0.6198988266852538,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6198988266852538,
        "precision": 0.599740994202072,
        "recall": 0.6679973386560213
      },
      {
        "accuracy": 0.7125748502994012,
        "f1": 0.6672021037290498,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6672021037290498,
        "precision": 0.6486759525681681,
        "recall": 0.7125748502994012
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.009230885747012564,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.009230885747012564,
        "precision": 0.007775745113060802,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.6825322899175195,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.6825322899175195,
        "precision": 0.6652750055444666,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.6591325765976463,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6591325765976463,
        "precision": 0.639848873681209,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.687433118371242,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.687433118371242,
        "precision": 0.6684348474767637,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.6041250831669993,
        "f1": 0.5426212030004445,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.5426212030004445,
        "precision": 0.5185599700070759,
        "recall": 0.6041250831669993
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.007426139111608135,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007426139111608135,
        "precision": 0.0055671924124470985,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.4920355057081604,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.4920355057081604,
        "precision": 0.47206330484773595,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.6161011310711909,
        "f1": 0.5615441075520916,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5615441075520916,
        "precision": 0.5404030563212199,
        "recall": 0.6161011310711909
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6357618097139055,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6357618097139055,
        "precision": 0.6149320406805436,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.761144377910845,
        "f1": 0.7139181953553212,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.7139181953553212,
        "precision": 0.6940895985806166,
        "recall": 0.761144377910845
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8627095016316574,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8627095016316574,
        "precision": 0.8519516522510533,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9128631625637613,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9128631625637613,
        "precision": 0.9049123974273674,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.2827677977378576,
        "f1": 0.23231636774550946,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23231636774550946,
        "precision": 0.2150036122062657,
        "recall": 0.2827677977378576
      },
      {
        "accuracy": 0.810379241516966,
        "f1": 0.7693998246892458,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7693998246892458,
        "precision": 0.7519587808509963,
        "recall": 0.810379241516966
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9391217564870259,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9391217564870259,
        "precision": 0.9338766910623197,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6841374637781824,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6841374637781824,
        "precision": 0.6658033140069067,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9035484586382792,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9035484586382792,
        "precision": 0.8961743180306054,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9195719671767575,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9195719671767575,
        "precision": 0.9127918765643318,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7941629967578071,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7941629967578071,
        "precision": 0.7800011088933245,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.720558882235529,
        "f1": 0.6753751755747762,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6753751755747762,
        "precision": 0.656530877638662,
        "recall": 0.720558882235529
      },
      {
        "accuracy": 0.8982035928143712,
        "f1": 0.8779552007096917,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8779552007096917,
        "precision": 0.8686737635839433,
        "recall": 0.8982035928143712
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9078858156702467,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9078858156702467,
        "precision": 0.900443557329785,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.010131629342412112,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010131629342412112,
        "precision": 0.008838489661055058,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9116877356398314,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9116877356398314,
        "precision": 0.9045242847638058,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9059563412856826,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9059563412856826,
        "precision": 0.8981925038811265,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8891676963533252,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8891676963533252,
        "precision": 0.8802838766910622,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7992500956572813,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7992500956572813,
        "precision": 0.7843646041250832,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.005206089675311725,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005206089675311725,
        "precision": 0.0035955186778719055,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6595671091679075,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6595671091679075,
        "precision": 0.6395993726832051,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8088157019294745,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8088157019294745,
        "precision": 0.7958590754997941,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8658920254728638,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8658920254728638,
        "precision": 0.855772581820486,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9346750942559325,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9346750942559325,
        "precision": 0.9288486519025442,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8584165003326679,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.8584165003326679,
        "precision": 0.8479004953056849,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9241516966067864,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9241516966067864,
        "precision": 0.918385451319583,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.2874251497005988,
        "f1": 0.23711287972765016,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.23711287972765016,
        "precision": 0.21989651260814816,
        "recall": 0.2874251497005988
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.7332905617336754,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.7332905617336754,
        "precision": 0.7147120128998476,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9456864049678422,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9456864049678422,
        "precision": 0.9410844976713241,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.7012641383898869,
        "f1": 0.6564495347928482,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.6564495347928482,
        "precision": 0.6382428265162796,
        "recall": 0.7012641383898869
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9054040068012122,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9054040068012122,
        "precision": 0.899196052339765,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9132306814941544,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9132306814941544,
        "precision": 0.9066533599467731,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8330814561353483,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.8330814561353483,
        "precision": 0.8206761081012579,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.6859614105123087,
        "f1": 0.6357464964251391,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.6357464964251391,
        "precision": 0.6150067589688348,
        "recall": 0.6859614105123087
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.879047196612067,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.879047196612067,
        "precision": 0.8702872033710356,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9046478471628172,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9046478471628172,
        "precision": 0.8967065868263473,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.009161894411365256,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.009161894411365256,
        "precision": 0.00707456178847016,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053005100909292,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9053005100909292,
        "precision": 0.8978820137502773,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9107816113804138,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9107816113804138,
        "precision": 0.9045686404967842,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8786553876374236,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8786553876374236,
        "precision": 0.8690396983810158,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.8376580172987359,
        "f1": 0.8057694135538448,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.8057694135538448,
        "precision": 0.7920270569971167,
        "recall": 0.8376580172987359
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006628953574421282,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.006628953574421282,
        "precision": 0.005330877381171923,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.6699933466400533,
        "f1": 0.6224794278686494,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.6224794278686494,
        "precision": 0.603440497552274,
        "recall": 0.6699933466400533
      },
      {
        "accuracy": 0.8762475049900199,
        "f1": 0.8543912175648704,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8543912175648704,
        "precision": 0.8448943383075119,
        "recall": 0.8762475049900199
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8927605107245825,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8927605107245825,
        "precision": 0.8846196495897094,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9255615752621741,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9255615752621741,
        "precision": 0.9190507873142605,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8836105566644489,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8836105566644489,
        "precision": 0.8741406076735417,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9367709026391662,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9367709026391662,
        "precision": 0.9310268352184521,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.281437125748503,
        "f1": 0.23034993025012981,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23034993025012981,
        "precision": 0.2122031310155063,
        "recall": 0.281437125748503
      },
      {
        "accuracy": 0.8110445775116434,
        "f1": 0.7706491778348066,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7706491778348066,
        "precision": 0.7535151918385451,
        "recall": 0.8110445775116434
      },
      {
        "accuracy": 0.9634065202927479,
        "f1": 0.9536165763710673,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9536165763710673,
        "precision": 0.9491017964071856,
        "recall": 0.9634065202927479
      },
      {
        "accuracy": 0.7704590818363274,
        "f1": 0.7310416684668181,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7310416684668181,
        "precision": 0.7146326394829389,
        "recall": 0.7704590818363274
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9290973608338877,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9290973608338877,
        "precision": 0.9241516966067864,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.941494788201375,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.941494788201375,
        "precision": 0.9363162563761366,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.830340905490606,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.830340905490606,
        "precision": 0.8172496277286698,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6770866156095696,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6770866156095696,
        "precision": 0.658068783068783,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9070303836770901,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9070303836770901,
        "precision": 0.8995342648037259,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9134397870924817,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9134397870924817,
        "precision": 0.9065979152805501,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.012650913949056531,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.012650913949056531,
        "precision": 0.010298460471469716,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9182523841206475,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9182523841206475,
        "precision": 0.9117542692392993,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9263473053892215,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9263473053892215,
        "precision": 0.9201596806387226,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9026961949117638,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9026961949117638,
        "precision": 0.8951208693723665,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8178981143052999,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.8178981143052999,
        "precision": 0.8050232867598137,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.009354010989776921,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009354010989776921,
        "precision": 0.007102064724641484,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6542021776552714,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6542021776552714,
        "precision": 0.6368268753498294,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.8472832113550677,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8472832113550677,
        "precision": 0.8372588157019295,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.895276114437791,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.895276114437791,
        "precision": 0.8872255489021956,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9416056775338213,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9416056775338213,
        "precision": 0.9369815923708139,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0036067848383064447,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0036067848383064447,
        "precision": 0.0027822981040150217,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009059503181215369,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.009059503181215369,
        "precision": 0.007791894428779614,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0068539880874513934,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0068539880874513934,
        "precision": 0.0054840442401642864,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006285577738483444,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.006285577738483444,
        "precision": 0.005333798222920145,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006874298136735769,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.006874298136735769,
        "precision": 0.0058733272893074975,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007960145140684277,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007960145140684277,
        "precision": 0.00682255468333444,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0036940384755443606,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0036940384755443606,
        "precision": 0.003329142275549362,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0060594774820018115,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0060594774820018115,
        "precision": 0.0055249003620733775,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.00521085370334241,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.00521085370334241,
        "precision": 0.0046482342361172935,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.005912865031141785,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.005912865031141785,
        "precision": 0.005458147927419909,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005467505927051952,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.005467505927051952,
        "precision": 0.0043321608282547285,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004871602955741583,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.004871602955741583,
        "precision": 0.004508357251400576,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004855894620809235,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004855894620809235,
        "precision": 0.004164774828714494,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005440697796877278,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005440697796877278,
        "precision": 0.004504486914312654,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007553882503982303,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.007553882503982303,
        "precision": 0.006993887098540696,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005100696695960469,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.005100696695960469,
        "precision": 0.004493134892077397,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0058438084455356845,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0058438084455356845,
        "precision": 0.005213620037372819,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.02955868092215314,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.02955868092215314,
        "precision": 0.026506338705668854,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005791811411834024,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.005791811411834024,
        "precision": 0.004888703813695827,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004167707511953729,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.004167707511953729,
        "precision": 0.00342135570091999,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006981044375373364,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.006981044375373364,
        "precision": 0.0060018010238775295,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007406422152113251,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.007406422152113251,
        "precision": 0.006526923396233775,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8913062763362164,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8913062763362164,
        "precision": 0.8829230428032823,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9375027722333111,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9375027722333111,
        "precision": 0.931991572410734,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.3033932135728543,
        "f1": 0.25523508058438193,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25523508058438193,
        "precision": 0.2389931776658324,
        "recall": 0.3033932135728543
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7893134366188259,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7893134366188259,
        "precision": 0.7742974368722871,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.9620758483033932,
        "f1": 0.9525837214459968,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9525837214459968,
        "precision": 0.9482923042803282,
        "recall": 0.9620758483033932
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.676444465566222,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.676444465566222,
        "precision": 0.6595557562124429,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9222444000887113,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9222444000887113,
        "precision": 0.9165446884009758,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9410068751386116,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9410068751386116,
        "precision": 0.935595475715236,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8250768304660521,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8250768304660521,
        "precision": 0.8130073186959414,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.7318695941450433,
        "f1": 0.6869726636193701,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6869726636193701,
        "precision": 0.667831004657352,
        "recall": 0.7318695941450433
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.915302727877578,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.915302727877578,
        "precision": 0.9084830339321356,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9044023064981148,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9044023064981148,
        "precision": 0.8954931407027215,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9289326109685391,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9289326109685391,
        "precision": 0.9240075404746063,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.01237281801902918,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01237281801902918,
        "precision": 0.0100728816200562,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9306719893546243,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9306719893546243,
        "precision": 0.9248392104679529,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.895187402971834,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.895187402971834,
        "precision": 0.8864715014415613,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.863606121091151,
        "f1": 0.8333475905332193,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8333475905332193,
        "precision": 0.8206095745017901,
        "recall": 0.863606121091151
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008951995009619676,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008951995009619676,
        "precision": 0.007453052473993871,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.7065868263473054,
        "f1": 0.6634778062921776,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6634778062921776,
        "precision": 0.6461362988309096,
        "recall": 0.7065868263473054
      },
      {
        "accuracy": 0.8589487691284099,
        "f1": 0.8306498114881349,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8306498114881349,
        "precision": 0.8183743623863385,
        "recall": 0.8589487691284099
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.895621455501695,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.895621455501695,
        "precision": 0.8868263473053892,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9495897094699488,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9495897094699488,
        "precision": 0.9453870037702372,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8965624306941672,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8965624306941672,
        "precision": 0.8879463295630959,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9403193612774451,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9403193612774451,
        "precision": 0.9350188511865158,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.3087159015302728,
        "f1": 0.2517431227012066,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.2517431227012066,
        "precision": 0.23304342031886943,
        "recall": 0.3087159015302728
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7849560138981296,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.7849560138981296,
        "precision": 0.7694111776447106,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.9667332002661344,
        "f1": 0.9577511643379907,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9577511643379907,
        "precision": 0.9536482590374805,
        "recall": 0.9667332002661344
      },
      {
        "accuracy": 0.7318695941450433,
        "f1": 0.6890330450210689,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.6890330450210689,
        "precision": 0.671919412737776,
        "recall": 0.7318695941450433
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.925361974463771,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.925361974463771,
        "precision": 0.9202373031714348,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9388999778221334,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9388999778221334,
        "precision": 0.9341317365269461,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.848195672147768,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.848195672147768,
        "precision": 0.8374362386338433,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.678531825238412,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.678531825238412,
        "precision": 0.6598670384099525,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.916566866267465,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.916566866267465,
        "precision": 0.9097582612552674,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9157019294743846,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9157019294743846,
        "precision": 0.9092038145930361,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9333333333333333,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9333333333333333,
        "precision": 0.9275005544466622,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.013206082220298081,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.013206082220298081,
        "precision": 0.011157283961777948,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.933954313595032,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.933954313595032,
        "precision": 0.9284209359059659,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.904812597028166,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.904812597028166,
        "precision": 0.8970059880239521,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.8542914171656687,
        "f1": 0.8270844554277688,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.8270844554277688,
        "precision": 0.8159846972721225,
        "recall": 0.8542914171656687
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.008944428883621226,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.008944428883621226,
        "precision": 0.0069375159143264305,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6540031049013084,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.6540031049013084,
        "precision": 0.6359835883787979,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8551009092925261,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.8551009092925261,
        "precision": 0.8435636663181574,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9064759370148592,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9064759370148592,
        "precision": 0.8990907074739412,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.959414504324684,
        "f1": 0.9514304723885563,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9514304723885563,
        "precision": 0.947771124417831,
        "recall": 0.959414504324684
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8714127300953647,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8714127300953647,
        "precision": 0.8612663561765358,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9210467952982923,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9210467952982923,
        "precision": 0.914604125083167,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.2880904856952761,
        "f1": 0.23749864388586941,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.23749864388586941,
        "precision": 0.21988512153182813,
        "recall": 0.2880904856952761
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7893213572854291,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.7893213572854291,
        "precision": 0.7737255647435288,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9483699268130404,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9483699268130404,
        "precision": 0.9438789088489687,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6670669723563936,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6670669723563936,
        "precision": 0.6505177069548326,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9192187054462504,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9192187054462504,
        "precision": 0.9126192060323798,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9507651363938789,
        "f1": 0.9383677090263918,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9383677090263918,
        "precision": 0.9331226436016855,
        "recall": 0.9507651363938789
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8129740518962076,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.8129740518962076,
        "precision": 0.7991350632069194,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.7425149700598802,
        "f1": 0.6941038557805026,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.6941038557805026,
        "precision": 0.6737155318991647,
        "recall": 0.7425149700598802
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9099135063206919,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9099135063206919,
        "precision": 0.9023286759813705,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8925260589931249,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8925260589931249,
        "precision": 0.8839432246617875,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9159237081392769,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9159237081392769,
        "precision": 0.9096251940563317,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.013382943761232367,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.013382943761232367,
        "precision": 0.011766151740856249,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9257611760605772,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9257611760605772,
        "precision": 0.919738301175427,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9222887558216898,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9222887558216898,
        "precision": 0.9158904413395432,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.7950907708392739,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7950907708392739,
        "precision": 0.7796359661629122,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01103208353636769,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.01103208353636769,
        "precision": 0.008738322520433939,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.675808700060197,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.675808700060197,
        "precision": 0.6549681301178307,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.825827709660045,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.825827709660045,
        "precision": 0.8133732534930139,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8850521179862496,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.8850521179862496,
        "precision": 0.8755821689953427,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.9567531603459747,
        "f1": 0.9465291638944333,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9465291638944333,
        "precision": 0.942137946329563,
        "recall": 0.9567531603459747
      },
      {
        "accuracy": 0.8283433133732535,
        "f1": 0.79520166017172,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.79520166017172,
        "precision": 0.7813547508158286,
        "recall": 0.8283433133732535
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8299179418939897,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8299179418939897,
        "precision": 0.8177164190138242,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.2554890219560878,
        "f1": 0.21250709813584065,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.21250709813584065,
        "precision": 0.1975522499973598,
        "recall": 0.2554890219560878
      },
      {
        "accuracy": 0.7005988023952096,
        "f1": 0.6535361511409415,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6535361511409415,
        "precision": 0.6345436111903178,
        "recall": 0.7005988023952096
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.844246427779362,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.844246427779362,
        "precision": 0.8327482600935695,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5853219486952022,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5853219486952022,
        "precision": 0.567077749263378,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.8283433133732535,
        "f1": 0.8012013011015007,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8012013011015007,
        "precision": 0.7897989734816082,
        "recall": 0.8283433133732535
      },
      {
        "accuracy": 0.8542914171656687,
        "f1": 0.8257680406383001,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8257680406383001,
        "precision": 0.814294427018978,
        "recall": 0.8542914171656687
      },
      {
        "accuracy": 0.7544910179640718,
        "f1": 0.717000918797326,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.717000918797326,
        "precision": 0.7020598607424954,
        "recall": 0.7544910179640718
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5705129903732697,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5705129903732697,
        "precision": 0.5520089690748373,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.8051949012028854,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8051949012028854,
        "precision": 0.7928199157241074,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.8349966733200266,
        "f1": 0.8049250704939329,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8049250704939329,
        "precision": 0.7924215061939613,
        "recall": 0.8349966733200266
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8355980346998312,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8355980346998312,
        "precision": 0.8247790134017678,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01078179172227011,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01078179172227011,
        "precision": 0.008756112612427952,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.8562874251497006,
        "f1": 0.8296312137629503,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8296312137629503,
        "precision": 0.8185248550518011,
        "recall": 0.8562874251497006
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8273358045813135,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8273358045813135,
        "precision": 0.8156591578747268,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.8303393213572854,
        "f1": 0.7947617991530168,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7947617991530168,
        "precision": 0.7802355606247822,
        "recall": 0.8303393213572854
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007375817984865544,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007375817984865544,
        "precision": 0.005817299052252376,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5868263473053892,
        "f1": 0.5391047778273327,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5391047778273327,
        "precision": 0.5206431293257641,
        "recall": 0.5868263473053892
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.732487934184541,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.732487934184541,
        "precision": 0.7167783480657731,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.8349966733200266,
        "f1": 0.8042834964990654,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8042834964990654,
        "precision": 0.7915996290247788,
        "recall": 0.8349966733200266
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8393995078625818,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8393995078625818,
        "precision": 0.8282601463739189,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008925724795130688,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.008925724795130688,
        "precision": 0.007713823607855496,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0056794324573608375,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0056794324573608375,
        "precision": 0.004695781848908974,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007261486511953777,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.007261486511953777,
        "precision": 0.006003838901636981,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005922718591408833,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.005922718591408833,
        "precision": 0.004726212557900451,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.00766287862143459,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.00766287862143459,
        "precision": 0.00661742592286255,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006541833519887244,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.006541833519887244,
        "precision": 0.005516938246665289,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004253610297556834,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004253610297556834,
        "precision": 0.003915759399545924,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0056113027076711754,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0056113027076711754,
        "precision": 0.005269354191999806,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004729812204427841,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.004729812204427841,
        "precision": 0.004213543386004914,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0074482937891948205,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0074482937891948205,
        "precision": 0.006570930647345146,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006950569831690684,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.006950569831690684,
        "precision": 0.00586736485757037,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005650119032351239,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.005650119032351239,
        "precision": 0.004960426782700788,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005454394126116676,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.005454394126116676,
        "precision": 0.004939098682927858,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.03090138404509662,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.03090138404509662,
        "precision": 0.02691686052298161,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.006123827813006796,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.006123827813006796,
        "precision": 0.00525408116289736,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006815035718233786,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.006815035718233786,
        "precision": 0.006526784522156098,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006726646936528041,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.006726646936528041,
        "precision": 0.006017715843968609,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006040717403287407,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.006040717403287407,
        "precision": 0.005275615582882696,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005112873912126972,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.005112873912126972,
        "precision": 0.004004448753061434,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.00567739650080644,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.00567739650080644,
        "precision": 0.00488323627141371,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0048152156542727725,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0048152156542727725,
        "precision": 0.004335191927416834,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006027537911727766,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.006027537911727766,
        "precision": 0.005095038101496598,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6104811540939284,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6104811540939284,
        "precision": 0.5915317753142104,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.6966067864271457,
        "f1": 0.6436365364509077,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6436365364509077,
        "precision": 0.6233408677520454,
        "recall": 0.6966067864271457
      },
      {
        "accuracy": 0.3073852295409182,
        "f1": 0.25667289759106127,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25667289759106127,
        "precision": 0.2380139192514442,
        "recall": 0.3073852295409182
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6243724191827985,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6243724191827985,
        "precision": 0.6060667265757086,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6702583437114376,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6702583437114376,
        "precision": 0.6500971195581974,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.58416500332668,
        "f1": 0.5320882045432943,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5320882045432943,
        "precision": 0.512540551412807,
        "recall": 0.58416500332668
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6623757775454382,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6623757775454382,
        "precision": 0.6446437812206275,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.7272122421823021,
        "f1": 0.680369914701252,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.680369914701252,
        "precision": 0.6630432497198965,
        "recall": 0.7272122421823021
      },
      {
        "accuracy": 0.6094477711244178,
        "f1": 0.5584983952249422,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5584983952249422,
        "precision": 0.5393601685517853,
        "recall": 0.6094477711244178
      },
      {
        "accuracy": 0.5548902195608783,
        "f1": 0.49459493710990715,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.49459493710990715,
        "precision": 0.47130527305178005,
        "recall": 0.5548902195608783
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6414927240276541,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6414927240276541,
        "precision": 0.6212804549630897,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.6733200266134398,
        "f1": 0.6233654864393388,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6233654864393388,
        "precision": 0.604429460167983,
        "recall": 0.6733200266134398
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.639743264793165,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.639743264793165,
        "precision": 0.6210754589280147,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006653340947459384,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006653340947459384,
        "precision": 0.005454196820661775,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.6420699246048547,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6420699246048547,
        "precision": 0.6235626630337209,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6293399972541689,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6293399972541689,
        "precision": 0.6083161718890262,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.6966067864271457,
        "f1": 0.6429558539338978,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6429558539338978,
        "precision": 0.6230435547301815,
        "recall": 0.6966067864271457
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5247858779794907,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.5247858779794907,
        "precision": 0.5038415066858181,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.003178428541041605,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003178428541041605,
        "precision": 0.002189185055382368,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5610317579064297,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5610317579064297,
        "precision": 0.5416576899111829,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.6513639387890885,
        "f1": 0.5998468671123361,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5998468671123361,
        "precision": 0.5802445373802659,
        "recall": 0.6513639387890885
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.6575324727021333,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6575324727021333,
        "precision": 0.6365858230628689,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.781360079264271,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.781360079264271,
        "precision": 0.7660409340050061,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8566031957249521,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8566031957249521,
        "precision": 0.8456365047682414,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.2654690618762475,
        "f1": 0.21627624728265551,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.21627624728265551,
        "precision": 0.19939326032140403,
        "recall": 0.2654690618762475
      },
      {
        "accuracy": 0.7225548902195609,
        "f1": 0.6743048294944503,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.6743048294944503,
        "precision": 0.6549592154852223,
        "recall": 0.7225548902195609
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8708044229002312,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8708044229002312,
        "precision": 0.8607525689362016,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.6320691949434465,
        "f1": 0.5844496672839986,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5844496672839986,
        "precision": 0.565360020699342,
        "recall": 0.6320691949434465
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.821278654811589,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.821278654811589,
        "precision": 0.8110334885783987,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.8862275449101796,
        "f1": 0.8612542591584507,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8612542591584507,
        "precision": 0.8501837594651966,
        "recall": 0.8862275449101796
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7906124259417672,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.7906124259417672,
        "precision": 0.7769511482086332,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5611306487553993,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5611306487553993,
        "precision": 0.5385079048252701,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.806017114400348,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.806017114400348,
        "precision": 0.7925883276182676,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.8410987548712101,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8410987548712101,
        "precision": 0.830028831226436,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.839400563951462,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.839400563951462,
        "precision": 0.8276114437791086,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005484929428299056,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.005484929428299056,
        "precision": 0.004063097443110576,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.8235565905226585,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8235565905226585,
        "precision": 0.810568545448785,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8368485251718785,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8368485251718785,
        "precision": 0.8240804106073567,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.8013232793671916,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8013232793671916,
        "precision": 0.7873050195904486,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7133300498569959,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.7133300498569959,
        "precision": 0.693634952317587,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006261244054052079,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.006261244054052079,
        "precision": 0.004794701905205625,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5761725226795087,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.5761725226795087,
        "precision": 0.557802384648692,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8488134841428253,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8488134841428253,
        "precision": 0.8370148591705477,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8443362433382394,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.8443362433382394,
        "precision": 0.8329729430028833,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8585980663824975,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8585980663824975,
        "precision": 0.8486138833444223,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9135506764249279,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9135506764249279,
        "precision": 0.9069305832778888,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.27944111776447106,
        "f1": 0.2282188388974816,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.2282188388974816,
        "precision": 0.2115834302461049,
        "recall": 0.27944111776447106
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7191163128288877,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.7191163128288877,
        "precision": 0.7012486232017757,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9303076386908722,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9303076386908722,
        "precision": 0.9246174318030606,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6419246163757142,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.6419246163757142,
        "precision": 0.6236484942572768,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.9001996007984032,
        "f1": 0.8831596067125009,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8831596067125009,
        "precision": 0.8762974051896207,
        "recall": 0.9001996007984032
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9155276748091119,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9155276748091119,
        "precision": 0.90909292526059,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8454899724360802,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.8454899724360802,
        "precision": 0.8365491239742737,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6408231156734151,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6408231156734151,
        "precision": 0.6217913379590027,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8695529575769096,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8695529575769096,
        "precision": 0.8601352849855843,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8895542248835662,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8895542248835662,
        "precision": 0.8811709913506321,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9121756487025948,
        "f1": 0.8969320618023213,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8969320618023213,
        "precision": 0.8906021290751829,
        "recall": 0.9121756487025948
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.009318734699494917,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.009318734699494917,
        "precision": 0.006806150470033738,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8894021480847828,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8894021480847828,
        "precision": 0.8806719893546241,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9109130944460285,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9109130944460285,
        "precision": 0.9033884611728922,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8597598453885879,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8597598453885879,
        "precision": 0.8502344517314577,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7893245255520706,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7893245255520706,
        "precision": 0.7758522877285353,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.005806253229899507,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.005806253229899507,
        "precision": 0.004214192162665317,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.6340652029274784,
        "f1": 0.5847500765664438,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.5847500765664438,
        "precision": 0.5649528984359323,
        "recall": 0.6340652029274784
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8567753382124638,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8567753382124638,
        "precision": 0.8470281658904414,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9217248043595349,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9217248043595349,
        "precision": 0.915801729873586,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8915644900674841,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8915644900674841,
        "precision": 0.8842046066596965,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9400754047460634,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9400754047460634,
        "precision": 0.935129740518962,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.24095390821937726,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.24095390821937726,
        "precision": 0.22260475718559553,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8102319171181447,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.8102319171181447,
        "precision": 0.7962360992301113,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.9733865602129075,
        "f1": 0.9668662674650699,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9668662674650699,
        "precision": 0.9641273009536484,
        "recall": 0.9733865602129075
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.67482285586078,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.67482285586078,
        "precision": 0.6575903748059437,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9300953648259038,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9300953648259038,
        "precision": 0.9245287203371035,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.9634065202927479,
        "f1": 0.9544466622310933,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9544466622310933,
        "precision": 0.9505988023952096,
        "recall": 0.9634065202927479
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.8239573762527854,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8239573762527854,
        "precision": 0.8123491113012072,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.7138342362893261,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.7138342362893261,
        "precision": 0.6954598739029877,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9260811709913507,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9260811709913507,
        "precision": 0.9203260146373918,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9170547793302285,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9170547793302285,
        "precision": 0.9107119095143048,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9377689066311821,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9377689066311821,
        "precision": 0.9324683965402528,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.010496134246290078,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.010496134246290078,
        "precision": 0.008072079501885425,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9322022621423819,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9322022621423819,
        "precision": 0.9261698824573076,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9365713018407629,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9365713018407629,
        "precision": 0.9310711909514304,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9208028387669106,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9208028387669106,
        "precision": 0.9146152140164117,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8201169090390648,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.8201169090390648,
        "precision": 0.8061052498178245,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.009321674436270298,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.009321674436270298,
        "precision": 0.00732870072049769,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.7039254823685961,
        "f1": 0.6598923845430831,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.6598923845430831,
        "precision": 0.6423784945741033,
        "recall": 0.7039254823685961
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8529623293096347,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8529623293096347,
        "precision": 0.8430979311218831,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9104362703165098,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9104362703165098,
        "precision": 0.9039033045021069,
        "recall": 0.9261477045908184
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}