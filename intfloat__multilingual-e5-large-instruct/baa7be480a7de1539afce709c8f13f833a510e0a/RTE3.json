{
  "dataset_revision": "d94f96ca5a6798e20f5a77e566f7a288dc6138d7",
  "evaluation_time": 267.8006691932678,
  "kg_co2_emissions": 0.00548817740263617,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.8482328482328483,
          "accuracy_threshold": 0.7790635824203491,
          "ap": 0.8792726340650434,
          "f1": 0.9178852643419573,
          "f1_threshold": 0.7790635824203491,
          "precision": 0.85,
          "recall": 0.9975550122249389
        },
        "dot": {
          "accuracy": 0.8503118503118503,
          "accuracy_threshold": 290.701416015625,
          "ap": 0.8772925805926227,
          "f1": 0.9189189189189189,
          "f1_threshold": 290.701416015625,
          "precision": 0.8517745302713987,
          "recall": 0.9975550122249389
        },
        "euclidean": {
          "accuracy": 0.8503118503118503,
          "accuracy_threshold": 13.207374572753906,
          "ap": 0.8736832557625291,
          "f1": 0.9189189189189189,
          "f1_threshold": 13.207374572753906,
          "precision": 0.8517745302713987,
          "recall": 0.9975550122249389
        },
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ],
        "main_score": 0.8792726340650434,
        "manhattan": {
          "accuracy": 0.8503118503118503,
          "accuracy_threshold": 332.3099670410156,
          "ap": 0.8745399398285698,
          "f1": 0.9189189189189189,
          "f1_threshold": 332.3099670410156,
          "precision": 0.8517745302713987,
          "recall": 0.9975550122249389
        },
        "max": {
          "accuracy": 0.8503118503118503,
          "ap": 0.8792726340650434,
          "f1": 0.9189189189189189
        },
        "similarity": {
          "accuracy": 0.8482328482328483,
          "accuracy_threshold": 0.7790635824203491,
          "ap": 0.8792726340650434,
          "f1": 0.9178852643419573,
          "f1_threshold": 0.7790635824203491,
          "precision": 0.85,
          "recall": 0.9975550122249389
        }
      },
      {
        "cosine": {
          "accuracy": 0.8485477178423236,
          "accuracy_threshold": 0.7802770733833313,
          "ap": 0.8826133267588567,
          "f1": 0.9180695847362514,
          "f1_threshold": 0.7802770733833313,
          "precision": 0.8503118503118503,
          "recall": 0.9975609756097561
        },
        "dot": {
          "accuracy": 0.8485477178423236,
          "accuracy_threshold": 312.8623046875,
          "ap": 0.898032872694107,
          "f1": 0.9180695847362514,
          "f1_threshold": 312.8623046875,
          "precision": 0.8503118503118503,
          "recall": 0.9975609756097561
        },
        "euclidean": {
          "accuracy": 0.8506224066390041,
          "accuracy_threshold": 13.76715087890625,
          "ap": 0.8760845490801102,
          "f1": 0.9191011235955056,
          "f1_threshold": 13.76715087890625,
          "precision": 0.8520833333333333,
          "recall": 0.9975609756097561
        },
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.898032872694107,
        "manhattan": {
          "accuracy": 0.8506224066390041,
          "accuracy_threshold": 351.5661926269531,
          "ap": 0.8775950193364007,
          "f1": 0.9191011235955056,
          "f1_threshold": 351.5661926269531,
          "precision": 0.8520833333333333,
          "recall": 0.9975609756097561
        },
        "max": {
          "accuracy": 0.8506224066390041,
          "ap": 0.898032872694107,
          "f1": 0.9191011235955056
        },
        "similarity": {
          "accuracy": 0.8485477178423236,
          "accuracy_threshold": 0.7802770733833313,
          "ap": 0.8826133267588567,
          "f1": 0.9180695847362514,
          "f1_threshold": 0.7802770733833313,
          "precision": 0.8503118503118503,
          "recall": 0.9975609756097561
        }
      },
      {
        "cosine": {
          "accuracy": 0.8464730290456431,
          "accuracy_threshold": 0.7833991646766663,
          "ap": 0.880995960447317,
          "f1": 0.9168539325842697,
          "f1_threshold": 0.7833991646766663,
          "precision": 0.8482328482328483,
          "recall": 0.9975550122249389
        },
        "dot": {
          "accuracy": 0.8464730290456431,
          "accuracy_threshold": 285.5291442871094,
          "ap": 0.8782269620147907,
          "f1": 0.9168539325842697,
          "f1_threshold": 285.5291442871094,
          "precision": 0.8482328482328483,
          "recall": 0.9975550122249389
        },
        "euclidean": {
          "accuracy": 0.8464730290456431,
          "accuracy_threshold": 13.443885803222656,
          "ap": 0.8757594373911646,
          "f1": 0.9168539325842697,
          "f1_threshold": 13.443885803222656,
          "precision": 0.8482328482328483,
          "recall": 0.9975550122249389
        },
        "hf_subset": "fr",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.880995960447317,
        "manhattan": {
          "accuracy": 0.8464730290456431,
          "accuracy_threshold": 349.6922912597656,
          "ap": 0.8759683208097426,
          "f1": 0.9168539325842697,
          "f1_threshold": 349.6922912597656,
          "precision": 0.8482328482328483,
          "recall": 0.9975550122249389
        },
        "max": {
          "accuracy": 0.8464730290456431,
          "ap": 0.880995960447317,
          "f1": 0.9168539325842697
        },
        "similarity": {
          "accuracy": 0.8464730290456431,
          "accuracy_threshold": 0.7833991646766663,
          "ap": 0.880995960447317,
          "f1": 0.9168539325842697,
          "f1_threshold": 0.7833991646766663,
          "precision": 0.8482328482328483,
          "recall": 0.9975550122249389
        }
      },
      {
        "cosine": {
          "accuracy": 0.8472803347280334,
          "accuracy_threshold": 0.7825020551681519,
          "ap": 0.8738291938386578,
          "f1": 0.9173272933182333,
          "f1_threshold": 0.7825020551681519,
          "precision": 0.8490566037735849,
          "recall": 0.9975369458128078
        },
        "dot": {
          "accuracy": 0.8472803347280334,
          "accuracy_threshold": 276.0644836425781,
          "ap": 0.8823640763028886,
          "f1": 0.9173272933182333,
          "f1_threshold": 276.0644836425781,
          "precision": 0.8490566037735849,
          "recall": 0.9975369458128078
        },
        "euclidean": {
          "accuracy": 0.8472803347280334,
          "accuracy_threshold": 13.041512489318848,
          "ap": 0.868528134924475,
          "f1": 0.9173272933182333,
          "f1_threshold": 13.041512489318848,
          "precision": 0.8490566037735849,
          "recall": 0.9975369458128078
        },
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ],
        "main_score": 0.8823640763028886,
        "manhattan": {
          "accuracy": 0.8472803347280334,
          "accuracy_threshold": 332.589111328125,
          "ap": 0.8689976583506163,
          "f1": 0.9173272933182333,
          "f1_threshold": 332.589111328125,
          "precision": 0.8490566037735849,
          "recall": 0.9975369458128078
        },
        "max": {
          "accuracy": 0.8472803347280334,
          "ap": 0.8823640763028886,
          "f1": 0.9173272933182333
        },
        "similarity": {
          "accuracy": 0.8472803347280334,
          "accuracy_threshold": 0.7825020551681519,
          "ap": 0.8738291938386578,
          "f1": 0.9173272933182333,
          "f1_threshold": 0.7825020551681519,
          "precision": 0.8490566037735849,
          "recall": 0.9975369458128078
        }
      }
    ]
  },
  "task_name": "RTE3"
}