{
  "dataset_revision": "f43b4f32987048043a8b31e5e26be4d360c2438f",
  "evaluation_time": 166.2760133743286,
  "kg_co2_emissions": 0.003491465451144288,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.9102040816326531,
          "accuracy_threshold": 0.9528570771217346,
          "ap": 0.9592297877528375,
          "f1": 0.9383177570093458,
          "f1_threshold": 0.9528570771217346,
          "precision": 0.8972296693476318,
          "recall": 0.9833496571988247
        },
        "dot": {
          "accuracy": 0.8163265306122449,
          "accuracy_threshold": 348.6514892578125,
          "ap": 0.8399694495963643,
          "f1": 0.8772088808337108,
          "f1_threshold": 342.72052001953125,
          "precision": 0.8161888701517707,
          "recall": 0.9480901077375122
        },
        "euclidean": {
          "accuracy": 0.9095238095238095,
          "accuracy_threshold": 6.1734819412231445,
          "ap": 0.960938412271357,
          "f1": 0.9376465072667605,
          "f1_threshold": 6.183585166931152,
          "precision": 0.8992805755395683,
          "recall": 0.9794319294809011
        },
        "hf_subset": "default",
        "languages": [
          "hye-Armn"
        ],
        "main_score": 0.9609716050900641,
        "manhattan": {
          "accuracy": 0.9081632653061225,
          "accuracy_threshold": 160.87074279785156,
          "ap": 0.9609716050900641,
          "f1": 0.9369453526389538,
          "f1_threshold": 160.87074279785156,
          "precision": 0.8955357142857143,
          "recall": 0.9823702252693438
        },
        "max": {
          "accuracy": 0.9102040816326531,
          "ap": 0.9609716050900641,
          "f1": 0.9383177570093458
        },
        "similarity": {
          "accuracy": 0.9102040816326531,
          "accuracy_threshold": 0.9528570771217346,
          "ap": 0.9592297877528375,
          "f1": 0.9383177570093458,
          "f1_threshold": 0.9528570771217346,
          "precision": 0.8972296693476318,
          "recall": 0.9833496571988247
        }
      }
    ]
  },
  "task_name": "ArmenianParaphrasePC"
}