{
  "dataset_revision": "218ce687943a0da435d6d62751a4ab216be6cd40",
  "evaluation_time": 178.99806189537048,
  "kg_co2_emissions": 0.003744883659600284,
  "mteb_version": "1.12.41",
  "scores": {
    "train": [
      {
        "accuracy": 0.36513671875,
        "f1": 0.38935762775345595,
        "f1_weighted": 0.39843942394918275,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.36513671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.40087890625,
            "f1": 0.4071106237651021,
            "f1_weighted": 0.4280410760785887
          },
          {
            "accuracy": 0.3349609375,
            "f1": 0.3680138155354402,
            "f1_weighted": 0.3683533987895195
          },
          {
            "accuracy": 0.3857421875,
            "f1": 0.4059771497517142,
            "f1_weighted": 0.4219740023840046
          },
          {
            "accuracy": 0.333984375,
            "f1": 0.36420800130615655,
            "f1_weighted": 0.3729398309215842
          },
          {
            "accuracy": 0.4111328125,
            "f1": 0.42363786415760457,
            "f1_weighted": 0.4463352693252095
          },
          {
            "accuracy": 0.34814453125,
            "f1": 0.3860650772453654,
            "f1_weighted": 0.37846575582494757
          },
          {
            "accuracy": 0.3447265625,
            "f1": 0.38209079857562317,
            "f1_weighted": 0.3737149013327927
          },
          {
            "accuracy": 0.39794921875,
            "f1": 0.4057692512687779,
            "f1_weighted": 0.42524211198611395
          },
          {
            "accuracy": 0.3310546875,
            "f1": 0.3716587567871293,
            "f1_weighted": 0.3819378426315514
          },
          {
            "accuracy": 0.36279296875,
            "f1": 0.379044939141646,
            "f1_weighted": 0.3873900502175148
          }
        ]
      }
    ]
  },
  "task_name": "HindiDiscourseClassification"
}