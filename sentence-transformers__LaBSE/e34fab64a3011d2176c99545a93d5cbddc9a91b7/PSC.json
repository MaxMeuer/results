{
  "dataset_revision": "d05a294af9e1d3ff2bfb6b714e08a24a6cabc669",
  "evaluation_time": 1.452333688735962,
  "kg_co2_emissions": 7.632604759676136e-05,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.9517625231910947,
          "accuracy_threshold": 0.5763879418373108,
          "ap": 0.9741937601499664,
          "f1": 0.9202453987730062,
          "f1_threshold": 0.5763879418373108,
          "precision": 0.9259259259259259,
          "recall": 0.9146341463414634
        },
        "dot": {
          "accuracy": 0.9517625231910947,
          "accuracy_threshold": 0.5763880610466003,
          "ap": 0.9741937601499664,
          "f1": 0.9202453987730062,
          "f1_threshold": 0.5763880610466003,
          "precision": 0.9259259259259259,
          "recall": 0.9146341463414634
        },
        "euclidean": {
          "accuracy": 0.9517625231910947,
          "accuracy_threshold": 0.9204477071762085,
          "ap": 0.9741937601499664,
          "f1": 0.9202453987730062,
          "f1_threshold": 0.9204477071762085,
          "precision": 0.9259259259259259,
          "recall": 0.9146341463414634
        },
        "hf_subset": "default",
        "languages": [
          "pol-Latn"
        ],
        "main_score": 0.9741937601499664,
        "manhattan": {
          "accuracy": 0.9489795918367347,
          "accuracy_threshold": 20.380126953125,
          "ap": 0.9716285011420647,
          "f1": 0.9165402124430957,
          "f1_threshold": 20.380126953125,
          "precision": 0.9123867069486404,
          "recall": 0.9207317073170732
        },
        "max": {
          "accuracy": 0.9517625231910947,
          "ap": 0.9741937601499664,
          "f1": 0.9202453987730062
        },
        "similarity": {
          "accuracy": 0.9517625231910947,
          "accuracy_threshold": 0.5763880610466003,
          "ap": 0.9741937601499664,
          "f1": 0.9202453987730062,
          "f1_threshold": 0.5763880610466003,
          "precision": 0.9259259259259259,
          "recall": 0.9146341463414634
        }
      }
    ]
  },
  "task_name": "PSC"
}