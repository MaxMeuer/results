{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 17.04964852333069,
  "kg_co2_emissions": 0.000680984826147899,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.15568862275449102,
        "f1": 0.10628799241050439,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.10628799241050439,
        "precision": 0.09359994498589906,
        "recall": 0.15568862275449102
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8676662547920032,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8676662547920032,
        "precision": 0.8578240344707411,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8593828216582708,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8593828216582708,
        "precision": 0.8488689288090485,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7980927034819251,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7980927034819251,
        "precision": 0.7817365269461076,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00031506188402921246,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.00031506188402921246,
        "precision": 0.00016905693552400142,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8742847638057218,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8742847638057218,
        "precision": 0.8638342362893261,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8418844849982574,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8418844849982574,
        "precision": 0.8291417165668662,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8843899502582137,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8843899502582137,
        "precision": 0.8754380128631626,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.34530938123752497,
        "f1": 0.2734785507240597,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.2734785507240597,
        "precision": 0.2519779220818319,
        "recall": 0.34530938123752497
      },
      {
        "accuracy": 0.8589487691284099,
        "f1": 0.8325845663171012,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.8325845663171012,
        "precision": 0.8210966954978931,
        "recall": 0.8589487691284099
      },
      {
        "accuracy": 0.5262807717897539,
        "f1": 0.45736573990067003,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.45736573990067003,
        "precision": 0.432322392252532,
        "recall": 0.5262807717897539
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8149383772138262,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.8149383772138262,
        "precision": 0.8009536482590375,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.6307385229540918,
        "f1": 0.5720693533567786,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.5720693533567786,
        "precision": 0.5487448383655968,
        "recall": 0.6307385229540918
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8619332763045338,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8619332763045338,
        "precision": 0.8510645375914836,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8272011532490574,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8272011532490574,
        "precision": 0.8144552165510249,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.6393878908848969,
        "f1": 0.5837372873301018,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.5837372873301018,
        "precision": 0.5612996229762696,
        "recall": 0.6393878908848969
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0015193342491332715,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0015193342491332715,
        "precision": 0.0010286685967092553,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7312042581503659,
        "f1": 0.6884374108925007,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.6884374108925007,
        "precision": 0.6711455396086135,
        "recall": 0.7312042581503659
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.871168773563983,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.871168773563983,
        "precision": 0.8602683521845199,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.48655814873379744,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.48655814873379744,
        "precision": 0.46267837101170434,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8688527706491779,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8688527706491779,
        "precision": 0.8593036149922377,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8507334537274658,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8507334537274658,
        "precision": 0.8400310490130849,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.20292747837658018,
        "f1": 0.1575864070782902,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1575864070782902,
        "precision": 0.1462959484367434,
        "recall": 0.20292747837658018
      },
      {
        "accuracy": 0.17964071856287425,
        "f1": 0.13760866235694202,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.13760866235694202,
        "precision": 0.1272322202681767,
        "recall": 0.17964071856287425
      },
      {
        "accuracy": 0.1703260146373919,
        "f1": 0.12955467432108161,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12955467432108161,
        "precision": 0.12011994444487895,
        "recall": 0.1703260146373919
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.00515266472320107,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00515266472320107,
        "precision": 0.004014306249561465,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.13365414022187078,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.13365414022187078,
        "precision": 0.12392650305586338,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.12414218430332653,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.12414218430332653,
        "precision": 0.11337003338510233,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.15600100547118248,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.15600100547118248,
        "precision": 0.14417529274706772,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.13506320691949433,
        "f1": 0.1063678250745293,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1063678250745293,
        "precision": 0.09878940049688924,
        "recall": 0.13506320691949433
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.14307978155834167,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.14307978155834167,
        "precision": 0.13241372971289328,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.1397312095599731,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1397312095599731,
        "precision": 0.1306601333179684,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.1656686626746507,
        "f1": 0.12272898340714354,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.12272898340714354,
        "precision": 0.11183264720585874,
        "recall": 0.1656686626746507
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.14441849887589986,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14441849887589986,
        "precision": 0.13483334214158932,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1322838761860615,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1322838761860615,
        "precision": 0.11983852031137508,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.1656686626746507,
        "f1": 0.12187069022211672,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12187069022211672,
        "precision": 0.11138210158926591,
        "recall": 0.1656686626746507
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.14697373333585897,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.14697373333585897,
        "precision": 0.1359909356419533,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0026555089750537933,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0026555089750537933,
        "precision": 0.001955271128988586,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.1330000462609889,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1330000462609889,
        "precision": 0.123341674342157,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.13105906604722523,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.13105906604722523,
        "precision": 0.11914995691557317,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.1236003264387672,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.1236003264387672,
        "precision": 0.11529086738618656,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.12414578596686641,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.12414578596686641,
        "precision": 0.11303206712724159,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.13299685330563674,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.13299685330563674,
        "precision": 0.12068979654015465,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9405189620758483,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9405189620758483,
        "precision": 0.9357950765136394,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8372144599689509,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8372144599689509,
        "precision": 0.8234752716788646,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0010734346983054183,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010734346983054183,
        "precision": 0.0006981973394856947,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9087951081963058,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9087951081963058,
        "precision": 0.9009758261255266,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9183632734530938,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9183632734530938,
        "precision": 0.9115324905744068,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9634065202927479,
        "f1": 0.9535595475715235,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9535595475715235,
        "precision": 0.949268130405855,
        "recall": 0.9634065202927479
      },
      {
        "accuracy": 0.3147039254823686,
        "f1": 0.2553381323926416,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2553381323926416,
        "precision": 0.2402816529276303,
        "recall": 0.3147039254823686
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9191173209137281,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9191173209137281,
        "precision": 0.9120647593701487,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.490352628077179,
        "f1": 0.4297410227108141,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4297410227108141,
        "precision": 0.41126661956712385,
        "recall": 0.490352628077179
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8907740075404748,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8907740075404748,
        "precision": 0.8808050565535595,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.569208539025427,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.569208539025427,
        "precision": 0.5494002922978305,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.935041029053005,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.935041029053005,
        "precision": 0.9299955644267022,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8847638057218897,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8847638057218897,
        "precision": 0.874517631403859,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6010097169777808,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6010097169777808,
        "precision": 0.5806382018956869,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0008931594709423458,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008931594709423458,
        "precision": 0.0005718110838543168,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7344094879025018,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7344094879025018,
        "precision": 0.7165074612679403,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9477489465513418,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9477489465513418,
        "precision": 0.9427811044577512,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.5096473719228211,
        "f1": 0.44392133820119956,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.44392133820119956,
        "precision": 0.42314754434024665,
        "recall": 0.5096473719228211
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9388777999556441,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9388777999556441,
        "precision": 0.9342869815923707,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9388112663561765,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9388112663561765,
        "precision": 0.9337436238633843,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8507572157272756,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8507572157272756,
        "precision": 0.840026296613123,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012835120403946387,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012835120403946387,
        "precision": 0.0010896266069008206,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9173763583943224,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9173763583943224,
        "precision": 0.9101305325856224,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9260811709913507,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9260811709913507,
        "precision": 0.9190396983810157,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.9753825681969395,
        "f1": 0.9688179197161234,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9688179197161234,
        "precision": 0.9659569749390108,
        "recall": 0.9753825681969395
      },
      {
        "accuracy": 0.3685961410512309,
        "f1": 0.3008615809699546,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.3008615809699546,
        "precision": 0.28215510211739475,
        "recall": 0.3685961410512309
      },
      {
        "accuracy": 0.9507651363938789,
        "f1": 0.9395874916832999,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9395874916832999,
        "precision": 0.934519849190508,
        "recall": 0.9507651363938789
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.43722260430251336,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.43722260430251336,
        "precision": 0.4164180143554727,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8996895098691506,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8996895098691506,
        "precision": 0.8916278554003105,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5834030487390435,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5834030487390435,
        "precision": 0.5614466343760951,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9489687292082502,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9489687292082502,
        "precision": 0.9450210689731647,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8876912840984698,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8876912840984698,
        "precision": 0.8777888667110224,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6162948901471855,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6162948901471855,
        "precision": 0.593663490719379,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0015527071774166627,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0015527071774166627,
        "precision": 0.0012351923869810986,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7623615203455522,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7623615203455522,
        "precision": 0.7457774926337801,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.957418496340652,
        "f1": 0.9461299622976269,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9461299622976269,
        "precision": 0.9409514304723886,
        "recall": 0.957418496340652
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.4656639586559932,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.4656639586559932,
        "precision": 0.44309815914107337,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.959414504324684,
        "f1": 0.9500332667997339,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9500332667997339,
        "precision": 0.9458305611000222,
        "recall": 0.959414504324684
      },
      {
        "accuracy": 0.957418496340652,
        "f1": 0.9465735196274119,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9465735196274119,
        "precision": 0.9416389443335551,
        "recall": 0.957418496340652
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001142715048726555,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.001142715048726555,
        "precision": 0.0009435502408946466,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8495802046700249,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8495802046700249,
        "precision": 0.8379906852960746,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8233152742134777,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8233152742134777,
        "precision": 0.8108370154278338,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8680987231885435,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8680987231885435,
        "precision": 0.8584682486878096,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.29141716566866266,
        "f1": 0.22624348605870553,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.22624348605870553,
        "precision": 0.20771319306748448,
        "recall": 0.29141716566866266
      },
      {
        "accuracy": 0.846307385229541,
        "f1": 0.8144488800177424,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8144488800177424,
        "precision": 0.7999065361340809,
        "recall": 0.846307385229541
      },
      {
        "accuracy": 0.4431137724550898,
        "f1": 0.37227590298291,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.37227590298291,
        "precision": 0.3497052277568644,
        "recall": 0.4431137724550898
      },
      {
        "accuracy": 0.8143712574850299,
        "f1": 0.7755261962846792,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7755261962846792,
        "precision": 0.7592481703260145,
        "recall": 0.8143712574850299
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.48531640043679897,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.48531640043679897,
        "precision": 0.46136979161850467,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.8380128631625637,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8380128631625637,
        "precision": 0.8253603903304502,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8145613534835091,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8145613534835091,
        "precision": 0.8006320691949433,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.5741849634065203,
        "f1": 0.5087561436862834,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5087561436862834,
        "precision": 0.486403671733013,
        "recall": 0.5741849634065203
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012269936891282434,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0012269936891282434,
        "precision": 0.0010585913222830056,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.688622754491018,
        "f1": 0.6382301774517343,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.6382301774517343,
        "precision": 0.6180094836781463,
        "recall": 0.688622754491018
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8544910179640718,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8544910179640718,
        "precision": 0.8425223626820433,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.47837658017298734,
        "f1": 0.40781675262713185,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.40781675262713185,
        "precision": 0.38467193822942597,
        "recall": 0.47837658017298734
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.843366177697515,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.843366177697515,
        "precision": 0.831775338212464,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.8729208250166334,
        "f1": 0.8478598358837881,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.8478598358837881,
        "precision": 0.8368226509943077,
        "recall": 0.8729208250166334
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016462458063466572,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0016462458063466572,
        "precision": 0.0012701037981931482,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0030362955346321945,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0030362955346321945,
        "precision": 0.002677747820441157,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0037871787289618297,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0037871787289618297,
        "precision": 0.003262969980119072,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0022461250338828517,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0022461250338828517,
        "precision": 0.002010379451319408,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0037008673972035383,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0037008673972035383,
        "precision": 0.0033074168236081774,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0017690391696048588,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0017690391696048588,
        "precision": 0.0014012782436747676,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003133282832207497,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003133282832207497,
        "precision": 0.00292539513671553,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017852329476814865,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0017852329476814865,
        "precision": 0.0016008129867355041,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0029846658131307473,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0029846658131307473,
        "precision": 0.0024739541901168615,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002305776454146381,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.002305776454146381,
        "precision": 0.001974891823917178,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017629458432063747,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0017629458432063747,
        "precision": 0.0014452782826649621,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.02983426940065387,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.02983426940065387,
        "precision": 0.027436685071415612,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002490888246174792,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.002490888246174792,
        "precision": 0.00214964786494162,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003291863264594495,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.003291863264594495,
        "precision": 0.0029023266781395387,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024901468000746827,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0024901468000746827,
        "precision": 0.0023027565077483,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003192530210562104,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.003192530210562104,
        "precision": 0.0026958896787465303,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004426606405526008,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.004426606405526008,
        "precision": 0.003861162923202332,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8957862053670438,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8957862053670438,
        "precision": 0.8867487247726769,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9297183410955865,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9297183410955865,
        "precision": 0.9235861610113107,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.3439787092481703,
        "f1": 0.27454309299705193,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.27454309299705193,
        "precision": 0.2550992899586713,
        "recall": 0.3439787092481703
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8889902734214112,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8889902734214112,
        "precision": 0.8804502106897316,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.42968700545768024,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.42968700545768024,
        "precision": 0.40804460841885987,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.863606121091151,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.863606121091151,
        "precision": 0.8514637391882901,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.6487025948103793,
        "f1": 0.5917892209808377,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5917892209808377,
        "precision": 0.5707654337365503,
        "recall": 0.6487025948103793
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9177201153249058,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9177201153249058,
        "precision": 0.9103681525837214,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.8738427906092576,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8738427906092576,
        "precision": 0.8641605677533821,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.5810809597735745,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.5810809597735745,
        "precision": 0.5569876120774325,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011156425754059755,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0011156425754059755,
        "precision": 0.0007365176132293061,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.720252136419801,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.720252136419801,
        "precision": 0.7029016041990095,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9187751481164653,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9187751481164653,
        "precision": 0.9121756487025948,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.47517918051914,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.47517918051914,
        "precision": 0.4541060689513783,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9063872255489023,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9063872255489023,
        "precision": 0.8992237746728764,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9064981148813485,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9064981148813485,
        "precision": 0.8991350632069196,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9550232867598137,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9550232867598137,
        "precision": 0.9504879130627633,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.35994677312042583,
        "f1": 0.28913107320958287,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.28913107320958287,
        "precision": 0.2688946953721326,
        "recall": 0.35994677312042583
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9203371035706365,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9203371035706365,
        "precision": 0.9130627633621645,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4561982698893089,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.4561982698893089,
        "precision": 0.43362054889001,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9113328897760036,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9113328897760036,
        "precision": 0.9032490574406742,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.669328010645376,
        "f1": 0.6081730386121603,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.6081730386121603,
        "precision": 0.5847918542000965,
        "recall": 0.669328010645376
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9398758039476601,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9398758039476601,
        "precision": 0.9343535151918385,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8849855843867819,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8849855843867819,
        "precision": 0.8744954535373698,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6327297785381618,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6327297785381618,
        "precision": 0.6093223605698656,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.00048439517950012596,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00048439517950012596,
        "precision": 0.00025685031243089467,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7637814318453041,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.7637814318453041,
        "precision": 0.7466622310933687,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9426702151253049,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9426702151253049,
        "precision": 0.9372366378354403,
        "recall": 0.9540918163672655
      },
      {
        "accuracy": 0.5688622754491018,
        "f1": 0.49964990653613406,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.49964990653613406,
        "precision": 0.4747296867526995,
        "recall": 0.5688622754491018
      },
      {
        "accuracy": 0.9447771124417831,
        "f1": 0.9315591040141937,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9315591040141937,
        "precision": 0.9254823685961411,
        "recall": 0.9447771124417831
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9387669106231981,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9387669106231981,
        "precision": 0.9337990685296075,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.4597471723220226,
        "f1": 0.37932055682207555,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.37932055682207555,
        "precision": 0.3526900743966612,
        "recall": 0.4597471723220226
      },
      {
        "accuracy": 0.9607451763140386,
        "f1": 0.9506986027944112,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9506986027944112,
        "precision": 0.946274118429807,
        "recall": 0.9607451763140386
      },
      {
        "accuracy": 0.6593479707252162,
        "f1": 0.5947501821753318,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5947501821753318,
        "precision": 0.5697266841977421,
        "recall": 0.6593479707252162
      },
      {
        "accuracy": 0.9534264803725881,
        "f1": 0.9420935905965846,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9420935905965846,
        "precision": 0.9370148591705477,
        "recall": 0.9534264803725881
      },
      {
        "accuracy": 0.7671324018629407,
        "f1": 0.7178895843566502,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.7178895843566502,
        "precision": 0.6974289516205685,
        "recall": 0.7671324018629407
      },
      {
        "accuracy": 0.9747172322022621,
        "f1": 0.9676424927921935,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9676424927921935,
        "precision": 0.9645708582834331,
        "recall": 0.9747172322022621
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9322244400088712,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9322244400088712,
        "precision": 0.9261698824573076,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7720833465344443,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7720833465344443,
        "precision": 0.7525005544466622,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0023166538980254146,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0023166538980254146,
        "precision": 0.0016929716279187464,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8562705277276135,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8562705277276135,
        "precision": 0.8458028387669108,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.9687292082501663,
        "f1": 0.9605899312486139,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9605899312486139,
        "precision": 0.9570858283433133,
        "recall": 0.9687292082501663
      },
      {
        "accuracy": 0.6952761144377911,
        "f1": 0.6307438514025341,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.6307438514025341,
        "precision": 0.6057097445320998,
        "recall": 0.6952761144377911
      },
      {
        "accuracy": 0.9727212242182302,
        "f1": 0.9658239077400753,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9658239077400753,
        "precision": 0.9629629629629629,
        "recall": 0.9727212242182302
      },
      {
        "accuracy": 0.9707252162341983,
        "f1": 0.9630516744289199,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9630516744289199,
        "precision": 0.9596362829895765,
        "recall": 0.9707252162341983
      },
      {
        "accuracy": 0.4138389886892881,
        "f1": 0.3590794268937982,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.3590794268937982,
        "precision": 0.341855171661951,
        "recall": 0.4138389886892881
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.29922686170191154,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.29922686170191154,
        "precision": 0.28336993542600125,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.331374727051794,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.331374727051794,
        "precision": 0.3146816295082642,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.3366600133067199,
        "f1": 0.298431953655445,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.298431953655445,
        "precision": 0.2852918095433065,
        "recall": 0.3366600133067199
      },
      {
        "accuracy": 0.42980705256154356,
        "f1": 0.3775159587882529,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3775159587882529,
        "precision": 0.36036937642230077,
        "recall": 0.42980705256154356
      },
      {
        "accuracy": 0.37192282102461743,
        "f1": 0.32490588007886745,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.32490588007886745,
        "precision": 0.3086586520586045,
        "recall": 0.37192282102461743
      },
      {
        "accuracy": 0.38323353293413176,
        "f1": 0.33919622429269797,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.33919622429269797,
        "precision": 0.3231998029245639,
        "recall": 0.38323353293413176
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002473356106499028,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.002473356106499028,
        "precision": 0.0017865602277839497,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.39654025282767796,
        "f1": 0.352148747227707,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.352148747227707,
        "precision": 0.33659680383217183,
        "recall": 0.39654025282767796
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.35979134997549783,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.35979134997549783,
        "precision": 0.3453173841405575,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.32667997338656024,
        "f1": 0.2777194205413239,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.2777194205413239,
        "precision": 0.2607191193518539,
        "recall": 0.32667997338656024
      },
      {
        "accuracy": 0.4151696606786427,
        "f1": 0.36491297504922426,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.36491297504922426,
        "precision": 0.34820847260967025,
        "recall": 0.4151696606786427
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.3680477416347781,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.3680477416347781,
        "precision": 0.3522917487987348,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.4605061682847288,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4605061682847288,
        "precision": 0.4387524881786359,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8758609764597788,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8758609764597788,
        "precision": 0.8646263029496563,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5821840446091943,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5821840446091943,
        "precision": 0.5605044354379018,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9414060767354181,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9414060767354181,
        "precision": 0.9367043690396984,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.8982035928143712,
        "f1": 0.873985362608117,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.873985362608117,
        "precision": 0.8631847416278555,
        "recall": 0.8982035928143712
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6339454328476284,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6339454328476284,
        "precision": 0.6118057775742406,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.002365496985000956,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002365496985000956,
        "precision": 0.001904827147173337,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7541858082776246,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.7541858082776246,
        "precision": 0.7374877229667648,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9347083610556663,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9347083610556663,
        "precision": 0.9287757817697938,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.49323234058763,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.49323234058763,
        "precision": 0.47080681830182824,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9338212463960966,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9338212463960966,
        "precision": 0.9285540031049014,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9371479263694832,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9371479263694832,
        "precision": 0.9316367265469062,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.5874916833000665,
        "f1": 0.5262326865121275,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5262326865121275,
        "precision": 0.503226927578225,
        "recall": 0.5874916833000665
      },
      {
        "accuracy": 0.4930139720558882,
        "f1": 0.4368964959783323,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4368964959783323,
        "precision": 0.41482332564873364,
        "recall": 0.4930139720558882
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5835838134182622,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5835838134182622,
        "precision": 0.562612737487987,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5114057599087539,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5114057599087539,
        "precision": 0.4902818349737206,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.5961410512308716,
        "f1": 0.5427864329061934,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5427864329061934,
        "precision": 0.5218417902050636,
        "recall": 0.5961410512308716
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015239241271387503,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015239241271387503,
        "precision": 0.0010470467816645027,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.5209300614739736,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5209300614739736,
        "precision": 0.4999068768079134,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.6187624750499002,
        "f1": 0.5586784103750171,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5586784103750171,
        "precision": 0.5355896506096106,
        "recall": 0.6187624750499002
      },
      {
        "accuracy": 0.44644045242847635,
        "f1": 0.3833722461466972,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.3833722461466972,
        "precision": 0.3599053696359085,
        "recall": 0.44644045242847635
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.58850768880709,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.58850768880709,
        "precision": 0.5677449814176362,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.6327345309381237,
        "f1": 0.578109661093693,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.578109661093693,
        "precision": 0.5572584460708213,
        "recall": 0.6327345309381237
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6022666307596448,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6022666307596448,
        "precision": 0.5792452372791693,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.919107816113804,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.919107816113804,
        "precision": 0.9129740518962076,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.854424484364604,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.854424484364604,
        "precision": 0.8432801064537591,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6187545543832969,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6187545543832969,
        "precision": 0.5945247071993579,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.001880877561528643,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.001880877561528643,
        "precision": 0.0012074714731330897,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.7744510978043913,
        "f1": 0.7339590659949939,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7339590659949939,
        "precision": 0.7173605170611158,
        "recall": 0.7744510978043913
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.912656169143195,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.912656169143195,
        "precision": 0.9047183410955867,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.5881570192947438,
        "f1": 0.5201089883724614,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.5201089883724614,
        "precision": 0.49550929406218824,
        "recall": 0.5881570192947438
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053448658239076,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9053448658239076,
        "precision": 0.8975049900199601,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9204036371701043,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9204036371701043,
        "precision": 0.9133399866932801,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7158529501842874,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7158529501842874,
        "precision": 0.6977659060963042,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6596077685898045,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6596077685898045,
        "precision": 0.6389295483107859,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5490135317480628,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5490135317480628,
        "precision": 0.525422171529956,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0018199504217261046,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018199504217261046,
        "precision": 0.0011792219425120713,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.6069501209221768,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6069501209221768,
        "precision": 0.587461848789194,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.7544910179640718,
        "f1": 0.7101057144969319,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7101057144969319,
        "precision": 0.6922506838175501,
        "recall": 0.7544910179640718
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.44908011335157044,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44908011335157044,
        "precision": 0.42408624309821913,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.7744510978043913,
        "f1": 0.7287477954144621,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7287477954144621,
        "precision": 0.7104914103417098,
        "recall": 0.7744510978043913
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7198539429078351,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7198539429078351,
        "precision": 0.7015366093210404,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8890124512879004,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8890124512879004,
        "precision": 0.8794632956309604,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6156807264591696,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6156807264591696,
        "precision": 0.5924384276180683,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0015703241739809587,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015703241739809587,
        "precision": 0.0012434758029498552,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7876696822804606,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7876696822804606,
        "precision": 0.7741184298070526,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9451541361721002,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9451541361721002,
        "precision": 0.9401973830117544,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.5681969394544245,
        "f1": 0.5043211716430497,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.5043211716430497,
        "precision": 0.48364761452008015,
        "recall": 0.5681969394544245
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9410512308715903,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9410512308715903,
        "precision": 0.9362053670436903,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9489465513417608,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9489465513417608,
        "precision": 0.945131958305611,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5713566761470953,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5713566761470953,
        "precision": 0.5457838291670627,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0013419193359313119,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0013419193359313119,
        "precision": 0.0008150669125467496,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.701993367761831,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.701993367761831,
        "precision": 0.6849531096537085,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9174983366600133,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9174983366600133,
        "precision": 0.9110889332446219,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.4766292478867329,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.4766292478867329,
        "precision": 0.4505948014431049,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9106010201818584,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9106010201818584,
        "precision": 0.9027944111776448,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9131514748281215,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9131514748281215,
        "precision": 0.9060989132845421,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0011751729896773623,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011751729896773623,
        "precision": 0.0006546301202405124,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.6644298704178944,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6644298704178944,
        "precision": 0.644992842597633,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.7850964737192282,
        "f1": 0.7391676963533251,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7391676963533251,
        "precision": 0.7201844987274129,
        "recall": 0.7850964737192282
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4455866045686405,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4455866045686405,
        "precision": 0.4212429638078341,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7462387394523122,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7462387394523122,
        "precision": 0.7281326236416056,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.7924151696606786,
        "f1": 0.7495591308964561,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7495591308964561,
        "precision": 0.7314933624813864,
        "recall": 0.7924151696606786
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001387690416354842,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.001387690416354842,
        "precision": 0.0011506787597704926,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0031089488887529673,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0031089488887529673,
        "precision": 0.002733379906535218,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002238090075462593,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.002238090075462593,
        "precision": 0.0019289428370544716,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003251556453426095,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.003251556453426095,
        "precision": 0.002673183778421313,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028795107465448442,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0028795107465448442,
        "precision": 0.0024481940944616628,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8072109748756455,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8072109748756455,
        "precision": 0.7933577289864715,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5336623530236304,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.5336623530236304,
        "precision": 0.5074620600069703,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8170785413300384,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8170785413300384,
        "precision": 0.803953996768368,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8422298260621615,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8422298260621615,
        "precision": 0.8303060545575516,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4719765615474198,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.4719765615474198,
        "precision": 0.45106993403227025,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9387890884896873,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9387890884896873,
        "precision": 0.933932135728543,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9337103570636506,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9337103570636506,
        "precision": 0.9289753825681969,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6574010708741248,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6574010708741248,
        "precision": 0.637178288924796,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6225801551150852,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6225801551150852,
        "precision": 0.6031051727159512,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9434242625859393,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9434242625859393,
        "precision": 0.9386781991572412,
        "recall": 0.9540918163672655
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}