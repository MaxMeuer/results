{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 15.67300534248352,
  "kg_co2_emissions": 0.0008638933736073868,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.349609375,
        "f1": 0.2740902651132143,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.2740902651132143,
        "precision": 0.2537044531406142,
        "recall": 0.349609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0022027297703577234,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0022027297703577234,
        "precision": 0.0013066141515086153,
        "recall": 0.015625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6065139789138813,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.6065139789138813,
        "precision": 0.5851775783412985,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7580550905257937,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.7580550905257937,
        "precision": 0.7409865606398809,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.93701171875,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.93701171875,
        "precision": 0.9298502604166666,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9090006510416666,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.9090006510416666,
        "precision": 0.8995047433035714,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0038943213246461403,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0038943213246461403,
        "precision": 0.0035194252334187002,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.896684337797619,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.896684337797619,
        "precision": 0.88720703125,
        "recall": 0.9189453125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.42333828114921657,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.42333828114921657,
        "precision": 0.40976051671852454,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.4101430341875227,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4101430341875227,
        "precision": 0.3946128274179673,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.39647569614098943,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.39647569614098943,
        "precision": 0.38233085924982,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014620465342649061,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.014620465342649061,
        "precision": 0.0116308170995671,
        "recall": 0.03125
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.41746611400761996,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.41746611400761996,
        "precision": 0.4016076565664908,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.33514209984950566,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.33514209984950566,
        "precision": 0.31807168164083266,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.44275036002894974,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.44275036002894974,
        "precision": 0.42980522071145066,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.41716307489628585,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.41716307489628585,
        "precision": 0.403655006958804,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.447265625,
        "f1": 0.4009719232210037,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4009719232210037,
        "precision": 0.3872264762277417,
        "recall": 0.447265625
      },
      {
        "accuracy": 0.525390625,
        "f1": 0.484612150245948,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.484612150245948,
        "precision": 0.4732555311788177,
        "recall": 0.525390625
      },
      {
        "accuracy": 0.392578125,
        "f1": 0.3266528815647787,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3266528815647787,
        "precision": 0.3064967142331388,
        "recall": 0.392578125
      },
      {
        "accuracy": 0.49609375,
        "f1": 0.4432551768988996,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4432551768988996,
        "precision": 0.42796652398831675,
        "recall": 0.49609375
      },
      {
        "accuracy": 0.439453125,
        "f1": 0.38197550118546303,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38197550118546303,
        "precision": 0.3637678367847006,
        "recall": 0.439453125
      },
      {
        "accuracy": 0.447265625,
        "f1": 0.404636706696781,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.404636706696781,
        "precision": 0.39168966833836794,
        "recall": 0.447265625
      },
      {
        "accuracy": 0.5078125,
        "f1": 0.46006592230434395,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.46006592230434395,
        "precision": 0.44688857011692906,
        "recall": 0.5078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011701602543179375,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.011701602543179375,
        "precision": 0.009607680166747342,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.455078125,
        "f1": 0.4036486548088696,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4036486548088696,
        "precision": 0.38682852150573643,
        "recall": 0.455078125
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.33972172431156805,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.33972172431156805,
        "precision": 0.3188771909184809,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.40974019067394163,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.40974019067394163,
        "precision": 0.3947287300610982,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.362041898753545,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.362041898753545,
        "precision": 0.3435442330636236,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.35749170696924604,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.35749170696924604,
        "precision": 0.33807820546692324,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666667,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9977213541666667,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0027483142895413076,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0027483142895413076,
        "precision": 0.0019001166695855859,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5585324286844935,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5585324286844935,
        "precision": 0.5404201225406766,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7281783808639277,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7281783808639277,
        "precision": 0.7129073237959956,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9089192708333333,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9089192708333333,
        "precision": 0.898681640625,
        "recall": 0.9306640625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8965549749729437,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8965549749729437,
        "precision": 0.8883626302083334,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006529947916666666,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0006529947916666666,
        "precision": 0.00048925879004004,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.875,
        "f1": 0.8444986979166667,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8444986979166667,
        "precision": 0.8323071676587301,
        "recall": 0.875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0037522992766908306,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0037522992766908306,
        "precision": 0.0030441423512636927,
        "recall": 0.0166015625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.7080078125,
        "f1": 0.6544194602930112,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.6544194602930112,
        "precision": 0.6357782588696537,
        "recall": 0.7080078125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7751674107142856,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7751674107142856,
        "precision": 0.7606518942212301,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.93388671875,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.93388671875,
        "precision": 0.9269205729166667,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9200520833333333,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9200520833333333,
        "precision": 0.9117838541666667,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006530165149983148,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0006530165149983148,
        "precision": 0.000489269673582996,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9923502604166667,
        "precision": 0.9915364583333333,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8837642609126983,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.8837642609126983,
        "precision": 0.8735595703125,
        "recall": 0.908203125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0020734006432845528,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0020734006432845528,
        "precision": 0.0013399388235324017,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.671875,
        "f1": 0.6091854868222055,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.6091854868222055,
        "precision": 0.5870550814390052,
        "recall": 0.671875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7542015438988094,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7542015438988094,
        "precision": 0.7353717137896825,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9232421875,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.9232421875,
        "precision": 0.914794921875,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8944521949404762,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.8944521949404762,
        "precision": 0.8841471354166667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010483557168953176,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0010483557168953176,
        "precision": 0.000720783172965285,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8694878472222223,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.8694878472222223,
        "precision": 0.8577718098958333,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003993948241278345,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.003993948241278345,
        "precision": 0.003950791817272257,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031352730377658808,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0031352730377658808,
        "precision": 0.0027604541755452097,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0043264311928678705,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0043264311928678705,
        "precision": 0.004149729487109612,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0026664779821770662,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0026664779821770662,
        "precision": 0.0023520902076863354,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0027654109540580967,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0027654109540580967,
        "precision": 0.00244245700172309,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003990217786837577,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003990217786837577,
        "precision": 0.0036328824995153592,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003906863792585465,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003906863792585465,
        "precision": 0.0035911326303206125,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005527215786344739,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.005527215786344739,
        "precision": 0.004917669313722983,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004289752525260706,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004289752525260706,
        "precision": 0.0037749975154520174,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011596651927750859,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0011596651927750859,
        "precision": 0.0007930708310687029,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0053361650884888295,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0053361650884888295,
        "precision": 0.004774609071484071,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08176063845009157,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.08176063845009157,
        "precision": 0.0723330543154762,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004314640880154829,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.004314640880154829,
        "precision": 0.004143613713081037,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010048252257389197,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0010048252257389197,
        "precision": 0.0009907822539967533,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006981176817721113,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0006981176817721113,
        "precision": 0.0005121284567506393,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032939098492707755,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0032939098492707755,
        "precision": 0.0028583927513946474,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004898050333002399,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.004898050333002399,
        "precision": 0.00489047497508922,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6406636078536777,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6406636078536777,
        "precision": 0.6171119678932179,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.7707101004464285,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.7707101004464285,
        "precision": 0.7528576078869047,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9456380208333333,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.9456380208333333,
        "precision": 0.9391276041666666,
        "recall": 0.958984375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9147135416666666,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.9147135416666666,
        "precision": 0.9056315104166668,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0036176601580103647,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0036176601580103647,
        "precision": 0.0030702243890977443,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8925316220238095,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.8925316220238095,
        "precision": 0.8824055989583333,
        "recall": 0.916015625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6310872395833333,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.6310872395833333,
        "precision": 0.6078603506839013,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.837890625,
        "f1": 0.7965332031250001,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.7965332031250001,
        "precision": 0.7801688058035715,
        "recall": 0.837890625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9469401041666667,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.9469401041666667,
        "precision": 0.9405924479166666,
        "recall": 0.9599609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9320312500000001,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.9320312500000001,
        "precision": 0.9243977864583333,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0037699005248322767,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0037699005248322767,
        "precision": 0.0029565000393836642,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9091471354166667,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.9091471354166667,
        "precision": 0.8999674479166666,
        "recall": 0.9296875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.7839680989583333,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7839680989583333,
        "precision": 0.7626232328869047,
        "recall": 0.83203125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9104817708333333,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.9104817708333333,
        "precision": 0.900390625,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97265625,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.97265625,
        "precision": 0.96923828125,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007126506457240242,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007126506457240242,
        "precision": 0.005246127778805062,
        "recall": 0.01953125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9625651041666667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9625651041666667,
        "precision": 0.9581705729166667,
        "recall": 0.9716796875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.777340720260642,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.777340720260642,
        "precision": 0.7618989490327381,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.7802734375,
        "f1": 0.7441080729166667,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7441080729166667,
        "precision": 0.7303819444444444,
        "recall": 0.7802734375
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7539605034722223,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.7539605034722223,
        "precision": 0.736379665798611,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7620326450892857,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.7620326450892857,
        "precision": 0.7453706287202381,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8038643973214286,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8038643973214286,
        "precision": 0.7881370907738094,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7758393787202381,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.7758393787202381,
        "precision": 0.7602135440514347,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7811058407738095,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7811058407738095,
        "precision": 0.7664388020833334,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.0135683868885576,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0135683868885576,
        "precision": 0.011419589407805984,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.810009765625,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.810009765625,
        "precision": 0.7965750558035715,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.80859375,
        "f1": 0.7664776250225469,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7664776250225469,
        "precision": 0.7499434566084957,
        "recall": 0.80859375
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7495599127435064,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7495599127435064,
        "precision": 0.7326822916666667,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7898934236336579,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7898934236336579,
        "precision": 0.7745318700396826,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8021003844246031,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8021003844246031,
        "precision": 0.7870209949555653,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8134765625,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.8134765625,
        "precision": 0.7964029947916667,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.943359375,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.943359375,
        "precision": 0.9366861979166666,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.93154296875,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.93154296875,
        "precision": 0.9234212239583333,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0030947349482825914,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0030947349482825914,
        "precision": 0.0023882976341669925,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8940755208333333,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.8940755208333333,
        "precision": 0.8834147135416666,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.86484375,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.86484375,
        "precision": 0.8524685329861112,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8548502604166666,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8548502604166666,
        "precision": 0.8407389322916667,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.92373046875,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.92373046875,
        "precision": 0.915283203125,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8854027157738096,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8854027157738096,
        "precision": 0.8751139322916667,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9057291666666667,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9057291666666667,
        "precision": 0.896484375,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012680059985078736,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.012680059985078736,
        "precision": 0.010278204241499478,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9007649739583333,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9007649739583333,
        "precision": 0.8919038318452381,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9042643229166667,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9042643229166667,
        "precision": 0.8942382812499999,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8190941220238095,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8190941220238095,
        "precision": 0.8026041666666666,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9134114583333333,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9134114583333333,
        "precision": 0.9036783854166667,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9101097470238095,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9101097470238095,
        "precision": 0.901611328125,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97265625,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.97265625,
        "precision": 0.96923828125,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9435221354166666,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9435221354166666,
        "precision": 0.9371744791666666,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.011075745146287425,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.011075745146287425,
        "precision": 0.008823536748085455,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9348958333333334,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9348958333333334,
        "precision": 0.9274088541666667,
        "recall": 0.9501953125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.99365234375,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.99365234375,
        "precision": 0.9930013020833333,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333334,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9314778645833333,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9314778645833333,
        "precision": 0.923828125,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.008058855413824614,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008058855413824614,
        "precision": 0.006634549843190842,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9783528645833334,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9783528645833334,
        "precision": 0.97607421875,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8973632812500001,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8973632812500001,
        "precision": 0.8866373697916666,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9884440104166667,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9884440104166667,
        "precision": 0.9871419270833333,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92646484375,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.92646484375,
        "precision": 0.9192491319444445,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0029947409813661442,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0029947409813661442,
        "precision": 0.002637744550945378,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9046595982142858,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9046595982142858,
        "precision": 0.8953450520833333,
        "recall": 0.92578125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.93115234375,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.93115234375,
        "precision": 0.9236653645833333,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003758143116315153,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.003758143116315153,
        "precision": 0.003162988117627247,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.91484375,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.91484375,
        "precision": 0.9059244791666667,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.011372980175663152,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.011372980175663152,
        "precision": 0.008512208227187939,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.903125,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.903125,
        "precision": 0.8922526041666666,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035029458736187844,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0035029458736187844,
        "precision": 0.003260348784377267,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0032833346912492668,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0032833346912492668,
        "precision": 0.002853082554401835,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004100209034734587,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004100209034734587,
        "precision": 0.0036450834704511176,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027187860595531714,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0027187860595531714,
        "precision": 0.0024020122216051494,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035664094460182176,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0035664094460182176,
        "precision": 0.0033106271546009015,
        "recall": 0.0068359375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.947265625,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.947265625,
        "precision": 0.9412434895833334,
        "recall": 0.9599609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8910528273809524,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.8910528273809524,
        "precision": 0.880615234375,
        "recall": 0.9150390625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9708658854166666,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9708658854166666,
        "precision": 0.9677734375,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9593098958333333,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9593098958333333,
        "precision": 0.9556315104166666,
        "recall": 0.9677734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}