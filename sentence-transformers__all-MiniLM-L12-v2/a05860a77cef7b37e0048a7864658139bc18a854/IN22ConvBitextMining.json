{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 16.357499837875366,
  "kg_co2_emissions": 0.0005187805622365309,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008042768978501623,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0008042768978501623,
        "precision": 0.0007370675573943563,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007773572415911604,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0007773572415911604,
        "precision": 0.0007239324556460513,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006821785859646932,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0006821785859646932,
        "precision": 0.0006738530970188136,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0029018873336395692,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0029018873336395692,
        "precision": 0.00202060359245988,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.028469277029299835,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.028469277029299835,
        "precision": 0.02415741695141172,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.04012480319448091,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.04012480319448091,
        "precision": 0.03561160230321907,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.017132714816130355,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.017132714816130355,
        "precision": 0.014910669085843011,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00020446828070539225,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.00020446828070539225,
        "precision": 0.00011187761319470785,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006829972895165136,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0006829972895165136,
        "precision": 0.0006742698894110357,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.010334437370142823,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.010334437370142823,
        "precision": 0.00892761169958232,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007642077640012804,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0007642077640012804,
        "precision": 0.0007184330813729077,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00026300140392618635,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.00026300140392618635,
        "precision": 0.00014539657708271416,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0011098782778221827,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0011098782778221827,
        "precision": 0.0009984968334935068,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008043223303762906,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0008043223303762906,
        "precision": 0.0007372883852854556,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.025468913749495444,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.025468913749495444,
        "precision": 0.02182762223007819,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012631990538863362,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0012631990538863362,
        "precision": 0.001081485444403689,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.010835471913316224,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.010835471913316224,
        "precision": 0.008795372218525912,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001359113769604562,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.001359113769604562,
        "precision": 0.00113944263125574,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008289634423026068,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0008289634423026068,
        "precision": 0.0007564407499329593,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013961988376300807,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0013961988376300807,
        "precision": 0.001364364267800942,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00135791869420201,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.00135791869420201,
        "precision": 0.0013445567596345102,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.02567242335515636,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.02567242335515636,
        "precision": 0.0224527376223983,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.09381237524950099,
        "f1": 0.07785381856651082,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.07785381856651082,
        "precision": 0.07343738364444093,
        "recall": 0.09381237524950099
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.024950704651303453,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.024950704651303453,
        "precision": 0.023444659372803087,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.02245236943960938,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.02245236943960938,
        "precision": 0.020877073014464897,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003581554897344371,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003581554897344371,
        "precision": 0.0029842668684745013,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02483850626189801,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02483850626189801,
        "precision": 0.022588334690479547,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0037636578593069118,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0037636578593069118,
        "precision": 0.003413418268542144,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0032896418743542347,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0032896418743542347,
        "precision": 0.0030543868905139053,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.014192592913015844,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.014192592913015844,
        "precision": 0.012903988067580249,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.019376183685920374,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.019376183685920374,
        "precision": 0.018219946916917067,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.05154312546077004,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05154312546077004,
        "precision": 0.047313101255217024,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0017908627190064315,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017908627190064315,
        "precision": 0.0014304723885562207,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.06187624750499002,
        "f1": 0.05378644420560588,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.05378644420560588,
        "precision": 0.05132034781012688,
        "recall": 0.06187624750499002
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.024242243686114565,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.024242243686114565,
        "precision": 0.021805874145930878,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.021163091210133822,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021163091210133822,
        "precision": 0.019365270996505556,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.0650566591684356,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0650566591684356,
        "precision": 0.06131711056567225,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012662624324950396,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0012662624324950396,
        "precision": 0.0010085656673811051,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.018859224666032102,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.018859224666032102,
        "precision": 0.01733569897242552,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008565732212777744,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0008565732212777744,
        "precision": 0.0007767964309816227,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.014570249001386724,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.014570249001386724,
        "precision": 0.012134436752131064,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01622131826722645,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.01622131826722645,
        "precision": 0.014535246055538803,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.011076443635043842,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011076443635043842,
        "precision": 0.009306732157804205,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.028293782943902997,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.028293782943902997,
        "precision": 0.026152249163443712,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022319246663661283,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.022319246663661283,
        "precision": 0.020601118025387135,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013481357780556812,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0013481357780556812,
        "precision": 0.0010660703749135983,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.02236571638713622,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02236571638713622,
        "precision": 0.02053754653222384,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001967719513722036,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.001967719513722036,
        "precision": 0.001703336117810954,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003363652412272765,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003363652412272765,
        "precision": 0.002913613015183766,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01591735039850314,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.01591735039850314,
        "precision": 0.014156594752347693,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.015620274741778515,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.015620274741778515,
        "precision": 0.014803364116958158,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.1282348962488683,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1282348962488683,
        "precision": 0.11471343028229256,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011815432014863337,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0011815432014863337,
        "precision": 0.0008259918746284943,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.1164337990685296,
        "f1": 0.08855294738528272,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08855294738528272,
        "precision": 0.08041111739964035,
        "recall": 0.1164337990685296
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.09938391115448764,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09938391115448764,
        "precision": 0.08880532585622407,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.02223689991431483,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02223689991431483,
        "precision": 0.020554535508653642,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.25615435795076513,
        "f1": 0.20752254680651755,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20752254680651755,
        "precision": 0.19024873533356568,
        "recall": 0.25615435795076513
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010388483866321473,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0010388483866321473,
        "precision": 0.0008760543035102421,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.16699933466400532,
        "f1": 0.12608570737313252,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12608570737313252,
        "precision": 0.11302712036244969,
        "recall": 0.16699933466400532
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013081511081487443,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0013081511081487443,
        "precision": 0.0010269665591414344,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.03421958618071181,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.03421958618071181,
        "precision": 0.030335337624021127,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.08316699933466401,
        "f1": 0.05826029019054732,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05826029019054732,
        "precision": 0.05095906071454974,
        "recall": 0.08316699933466401
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.010816051629062831,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010816051629062831,
        "precision": 0.00899838376114598,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.02301776033260433,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.02301776033260433,
        "precision": 0.022044205240313024,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 7.918228823999436e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 7.918228823999436e-05,
        "precision": 4.03701062961843e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.0234627584789646,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.0234627584789646,
        "precision": 0.021719828396239354,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006165314548548081,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006165314548548081,
        "precision": 0.0004237373470143125,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0046857179892213,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0046857179892213,
        "precision": 0.004011865450116976,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.08449767132401863,
        "f1": 0.06186844524064393,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.06186844524064393,
        "precision": 0.05610232309954942,
        "recall": 0.08449767132401863
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.02596349446700469,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02596349446700469,
        "precision": 0.024425600175499447,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02518200251733186,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.02518200251733186,
        "precision": 0.024191836755745485,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010957937604644192,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010957937604644192,
        "precision": 0.0009184360324185935,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.03470630596379099,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.03470630596379099,
        "precision": 0.03318438418238817,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003360610213570959,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.003360610213570959,
        "precision": 0.0031016599280072332,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.018361244338503304,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.018361244338503304,
        "precision": 0.016489306384093082,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.03106599136435687,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.03106599136435687,
        "precision": 0.029737956910011652,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0002060832137135373,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0002060832137135373,
        "precision": 0.00011098335445656739,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001452491147349413,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.001452491147349413,
        "precision": 0.0011902997242116268,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011393878908848968,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0011393878908848968,
        "precision": 0.0009481804440274596,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002251053448658239,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002251053448658239,
        "precision": 0.0019140463035282093,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018881567154883535,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0018881567154883535,
        "precision": 0.0015335461799513101,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.00968486307807665,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.00968486307807665,
        "precision": 0.007987759308646945,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00267171749690583,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.00267171749690583,
        "precision": 0.0020912874496512635,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.0294500945199548,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.0294500945199548,
        "precision": 0.027167886449323574,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005811365774198729,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.005811365774198729,
        "precision": 0.004635757724317447,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004927427472127822,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.004927427472127822,
        "precision": 0.004401770071376619,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013349635505324127,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.013349635505324127,
        "precision": 0.012379633497862155,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.027377568096130966,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.027377568096130966,
        "precision": 0.025571080062098028,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01656846423990388,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.01656846423990388,
        "precision": 0.015177110021691958,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012996733805117036,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0012996733805117036,
        "precision": 0.0008990723110869913,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.023875997630375668,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.023875997630375668,
        "precision": 0.022707987548900046,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013473644986738203,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0013473644986738203,
        "precision": 0.0010967963063771447,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.024665872326817245,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.024665872326817245,
        "precision": 0.022626833588268277,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.024975181911309655,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.024975181911309655,
        "precision": 0.02387699438597642,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0035325479909755104,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0035325479909755104,
        "precision": 0.002709198359075076,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0019136170153069125,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0019136170153069125,
        "precision": 0.001684332002832052,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0014413480730846,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0014413480730846,
        "precision": 0.0013903011586889114,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012915176123851288,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0012915176123851288,
        "precision": 0.0010247412056994805,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0025815060634765755,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0025815060634765755,
        "precision": 0.0023149116916764516,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.015663020936684133,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.015663020936684133,
        "precision": 0.013476980144593684,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.016209402265135404,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.016209402265135404,
        "precision": 0.013331977219202767,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.021494106099062788,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.021494106099062788,
        "precision": 0.01870223509789157,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001973363001307113,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.001973363001307113,
        "precision": 0.0017690630569338502,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006903489374136769,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006903489374136769,
        "precision": 0.0006780021375829759,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02138978598454014,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.02138978598454014,
        "precision": 0.018901510379020475,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006703573984107257,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006703573984107257,
        "precision": 0.0006678562067783625,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0002790626058929831,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0002790626058929831,
        "precision": 0.00016282149385111818,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662543328342166,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0006662543328342166,
        "precision": 0.0006657954808614814,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007367107361205151,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007367107361205151,
        "precision": 0.0007018375013258828,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.015641338835451154,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.015641338835451154,
        "precision": 0.013822126484173055,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006748026737459636,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006748026737459636,
        "precision": 0.0006700816709757729,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.03246734414399085,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.03246734414399085,
        "precision": 0.02942841328107409,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00020054898434299453,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00020054898434299453,
        "precision": 0.00011613140620163765,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008821833531876711,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008821833531876711,
        "precision": 0.0007897353268702075,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009121850187493382,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009121850187493382,
        "precision": 0.0008016628525610561,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006849419741283073,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0006849419741283073,
        "precision": 0.0006752601716950719,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03111635352154314,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.03111635352154314,
        "precision": 0.027696244594800423,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.017161665316999437,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.017161665316999437,
        "precision": 0.01517551034967878,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0076568178736723,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0076568178736723,
        "precision": 0.006365641321162495,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.007486004147332653,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.007486004147332653,
        "precision": 0.00683553552445258,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.04007769076076679,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04007769076076679,
        "precision": 0.03759560095460747,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.012741490370826997,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.012741490370826997,
        "precision": 0.011662547090643776,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.688929352089571e-05,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 8.688929352089571e-05,
        "precision": 4.508201373653437e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.016836387595084334,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.016836387595084334,
        "precision": 0.016033571953836687,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 4.482102235673233e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 4.482102235673233e-05,
        "precision": 2.2713267340328593e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.06320691949434465,
        "f1": 0.046895684763357835,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.046895684763357835,
        "precision": 0.04238585126603247,
        "recall": 0.06320691949434465
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.01686129772813548,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.01686129772813548,
        "precision": 0.015588058283508505,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.01464110019499241,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.01464110019499241,
        "precision": 0.012798672793985994,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011270935773762425,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0011270935773762425,
        "precision": 0.0009415150732981364,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.3259251317401327e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.3259251317401327e-05,
        "precision": 6.673183566348456e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.6458659590870204e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 1.6458659590870204e-05,
        "precision": 8.2708407631435e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00019118137530578554,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.00019118137530578554,
        "precision": 0.00011143246387044505,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.03549356006109166,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.03549356006109166,
        "precision": 0.031555218814817265,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0015918273142983038,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0015918273142983038,
        "precision": 0.0014726465056607188,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007011783146126639,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0007011783146126639,
        "precision": 0.0006834253209922924,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.02014469114181396,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.02014469114181396,
        "precision": 0.01712814516019176,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007130853650035922,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0007130853650035922,
        "precision": 0.0006894924471782932,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00032464643578659436,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.00032464643578659436,
        "precision": 0.00019639294790533228,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011924184516186919,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0011924184516186919,
        "precision": 0.0010411846742597213,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007493870885406268,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007493870885406268,
        "precision": 0.0007087965158620077,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.014847242747963046,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.014847242747963046,
        "precision": 0.013071235423589539,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001641055026513153,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.001641055026513153,
        "precision": 0.00150156974194545,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.022892627646573013,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.022892627646573013,
        "precision": 0.019185262249134503,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 7.985408520744796e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 7.985408520744796e-05,
        "precision": 4.0846622330257885e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011287476390286276,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0011287476390286276,
        "precision": 0.0009228540834202287,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000883097090681921,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.000883097090681921,
        "precision": 0.0007805268669734459,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014880635728879697,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0014880635728879697,
        "precision": 0.001414732332165758,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.03268930607936806,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.03268930607936806,
        "precision": 0.02817504321163669,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004872566298291977,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.004872566298291977,
        "precision": 0.0040638252115298016,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.007145025857818237,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.007145025857818237,
        "precision": 0.005503333053593825,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009495695407282371,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.009495695407282371,
        "precision": 0.008105258263593484,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011312170979678072,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0011312170979678072,
        "precision": 0.0010092665376237133,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007639373797761301,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.007639373797761301,
        "precision": 0.005767978836050677,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012897696854628025,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0012897696854628025,
        "precision": 0.00084247165545096,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.006478437370768505,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.006478437370768505,
        "precision": 0.004842513728109637,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.008000707745357993,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.008000707745357993,
        "precision": 0.00645514375019383,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00044304509046015357,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00044304509046015357,
        "precision": 0.0002420120699690592,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002114690913563756,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0002114690913563756,
        "precision": 0.0001181937802056199,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002638389576278504,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0002638389576278504,
        "precision": 0.0001431034881375579,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00025301461507173326,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.00025301461507173326,
        "precision": 0.00013308237366450054,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006103333348842331,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0006103333348842331,
        "precision": 0.00042092593488328667,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005558760286780907,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.005558760286780907,
        "precision": 0.0038196938477373394,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.02148073634998738,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02148073634998738,
        "precision": 0.020555431730149135,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022069857399198718,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.022069857399198718,
        "precision": 0.02125785642961817,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009986562822068281,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0009986562822068281,
        "precision": 0.0008494914932040682,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.022171262051061277,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.022171262051061277,
        "precision": 0.021709587078848555,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0030872598237867703,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0030872598237867703,
        "precision": 0.0025504546462630294,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.015528286860622189,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.015528286860622189,
        "precision": 0.014439686628642048,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022811519817507845,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.022811519817507845,
        "precision": 0.021946583024427334,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 4.1936672154267994e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 4.1936672154267994e-05,
        "precision": 2.1227870799839655e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000728423273333453,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.000728423273333453,
        "precision": 0.0004438811262729481,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009160563241318607,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0009160563241318607,
        "precision": 0.0008131291388306769,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0018050835895642304,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0018050835895642304,
        "precision": 0.0016010222150069093,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027343232679330506,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0027343232679330506,
        "precision": 0.002439058740643215,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.009466675593245981,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.009466675593245981,
        "precision": 0.008461861104913367,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.014576289597675398,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.014576289597675398,
        "precision": 0.013438817568263595,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00026070429243218145,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.00026070429243218145,
        "precision": 0.0001530061022896077,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.021049538936743925,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.021049538936743925,
        "precision": 0.019790577156258166,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011784059323772986,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0011784059323772986,
        "precision": 0.0010336259168706946,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.03293368731903427,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.03293368731903427,
        "precision": 0.03028107565532715,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.019538849376072046,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.019538849376072046,
        "precision": 0.01802435599656696,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.03879928187020403,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03879928187020403,
        "precision": 0.034202521906016595,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000852319466703202,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.000852319466703202,
        "precision": 0.000593335583597417,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007939933895403694,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0007939933895403694,
        "precision": 0.0007357300427395193,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013490579025203116,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0013490579025203116,
        "precision": 0.0011268802170706544,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00101682599712855,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.00101682599712855,
        "precision": 0.0008966327396137223,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.06453759148369927,
        "f1": 0.04273552568666085,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04273552568666085,
        "precision": 0.03686591769462027,
        "recall": 0.06453759148369927
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00063681955218032,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00063681955218032,
        "precision": 0.00039753577642194374,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.09115103127079174,
        "f1": 0.07479435557984342,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07479435557984342,
        "precision": 0.07008825062717278,
        "recall": 0.09115103127079174
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.036319779677182515,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.036319779677182515,
        "precision": 0.031946292599985215,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.021328833767323124,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021328833767323124,
        "precision": 0.01946823883359734,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.10521852342622567,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10521852342622567,
        "precision": 0.0954489169808531,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002419594200212069,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002419594200212069,
        "precision": 0.0018862238608792015,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.044542900730525484,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.044542900730525484,
        "precision": 0.04022304008394545,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011885259759259659,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011885259759259659,
        "precision": 0.0010402670994408868,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.018445960412028277,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.018445960412028277,
        "precision": 0.01626039581376048,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.0499001996007984,
        "f1": 0.03746686521137619,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.03746686521137619,
        "precision": 0.03361814003950783,
        "recall": 0.0499001996007984
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.010454918722720814,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010454918722720814,
        "precision": 0.008698894395157928,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012874374191533535,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0012874374191533535,
        "precision": 0.0010146476697788646,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0005950511264187318,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0005950511264187318,
        "precision": 0.0003608959388233603,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0026613439787092482,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0026613439787092482,
        "precision": 0.002239964515413617,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010702926074714143,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0010702926074714143,
        "precision": 0.0009245722601619503,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002574603723183756,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0002574603723183756,
        "precision": 0.0001377276477929063,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012498067154457263,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0012498067154457263,
        "precision": 0.0010245378038249743,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.08449767132401863,
        "f1": 0.06520032349451942,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.06520032349451942,
        "precision": 0.05980668902325589,
        "recall": 0.08449767132401863
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007746654676083785,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0007746654676083785,
        "precision": 0.0007218317272552402,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001162365676655034,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.001162365676655034,
        "precision": 0.001025051148563357,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00467149910704906,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.00467149910704906,
        "precision": 0.004422457355301345,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.04485986495930097,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04485986495930097,
        "precision": 0.038875123114976734,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.019839129119913153,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.019839129119913153,
        "precision": 0.018068074827140745,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.08782435129740519,
        "f1": 0.0693925280751628,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0693925280751628,
        "precision": 0.06412754835908528,
        "recall": 0.08782435129740519
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0007576064599933987,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007576064599933987,
        "precision": 0.0004414896039256015,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.040109928941942326,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.040109928941942326,
        "precision": 0.03471368700616088,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008790590531350532,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0008790590531350532,
        "precision": 0.0007780378722528334,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.024741255626941884,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.024741255626941884,
        "precision": 0.02128155613743422,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.2322022621423819,
        "f1": 0.18136852797531436,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18136852797531436,
        "precision": 0.1638831284040865,
        "recall": 0.2322022621423819
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.015377035355805615,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015377035355805615,
        "precision": 0.01337199182341512,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0026861932441690673,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0026861932441690673,
        "precision": 0.0024130941878531867,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.11709913506320692,
        "f1": 0.08444944626992296,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.08444944626992296,
        "precision": 0.07474470442137057,
        "recall": 0.11709913506320692
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001962403892753719,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001962403892753719,
        "precision": 0.0017624281033318222,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.13293356307328363,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13293356307328363,
        "precision": 0.12020609574501791,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010845192731420276,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0010845192731420276,
        "precision": 0.0008992390619628505,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04092134670976986,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.04092134670976986,
        "precision": 0.0353323815732332,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.09248170326014638,
        "f1": 0.06897106737426098,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06897106737426098,
        "precision": 0.06210597083850577,
        "recall": 0.09248170326014638
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.00224866655739059,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.00224866655739059,
        "precision": 0.0019339155999572543,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.016972361503187802,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.016972361503187802,
        "precision": 0.01630388619485733,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.0068879549553797674,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0068879549553797674,
        "precision": 0.005408245321462413,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00017974457279864043,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.00017974457279864043,
        "precision": 9.930455253512469e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008341712564845247,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0008341712564845247,
        "precision": 0.0007616369807242299,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007060794236442939,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007060794236442939,
        "precision": 0.000686241138669615,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009990136065754177,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0009990136065754177,
        "precision": 0.0008593934746186051,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.024755107389837928,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.024755107389837928,
        "precision": 0.021804828798245614,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002143969359538222,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002143969359538222,
        "precision": 0.0018001127967473694,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.14038589487691283,
        "f1": 0.10288403895601264,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10288403895601264,
        "precision": 0.09150728863802716,
        "recall": 0.14038589487691283
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001495918372923005,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001495918372923005,
        "precision": 0.0012230358429772467,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.022770846829251762,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.022770846829251762,
        "precision": 0.019529599821647304,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.06986027944111776,
        "f1": 0.05215106103329656,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05215106103329656,
        "precision": 0.04694235866890558,
        "recall": 0.06986027944111776
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.011614832993312688,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011614832993312688,
        "precision": 0.010103228631960642,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000856469257372831,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.000856469257372831,
        "precision": 0.0005955501906197017,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00010120479770723222,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.00010120479770723222,
        "precision": 5.3820933539956875e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008209604061704617,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0008209604061704617,
        "precision": 0.0007475082023122949,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006838409444589488,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0006838409444589488,
        "precision": 0.0006746950622437304,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.025148405651109915,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.025148405651109915,
        "precision": 0.021223717725552763,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00023664703825984414,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00023664703825984414,
        "precision": 0.00014057333238175706,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.04707720625297236,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.04707720625297236,
        "precision": 0.04254624007618019,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05371622745254987,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05371622745254987,
        "precision": 0.04870325486592952,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0031224524630186425,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0031224524630186425,
        "precision": 0.002793039907549867,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003389299623453605,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.003389299623453605,
        "precision": 0.002932569560907089,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001678776752730999,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.001678776752730999,
        "precision": 0.0015602403280655023,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006447422615087285,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0006447422615087285,
        "precision": 0.0003740222145516819,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.02668853857946502,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.02668853857946502,
        "precision": 0.023705442382252848,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002720484956013898,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.002720484956013898,
        "precision": 0.0020643897390404376,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0034029274181180376,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0034029274181180376,
        "precision": 0.003125515191273525,
        "recall": 0.00665335994677312
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}