{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 11.296792030334473,
  "kg_co2_emissions": 0.0007564873110677588,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8224801918133525,
        "cosine_spearman": 0.8097434761569621,
        "euclidean_pearson": 0.8041788453818768,
        "euclidean_spearman": 0.8097434761569621,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8097434761569621,
        "manhattan_pearson": 0.8033579288057746,
        "manhattan_spearman": 0.8083310323133623,
        "pearson": 0.8224801918133525,
        "spearman": 0.8097434761569621
      },
      {
        "cosine_pearson": 0.7598139390004854,
        "cosine_spearman": 0.7392471671303881,
        "euclidean_pearson": 0.7627470081573071,
        "euclidean_spearman": 0.7392471671303881,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7392471671303881,
        "manhattan_pearson": 0.7617477970362344,
        "manhattan_spearman": 0.734373685354654,
        "pearson": 0.7598139390004854,
        "spearman": 0.7392471671303881
      },
      {
        "cosine_pearson": 0.5443306617677465,
        "cosine_spearman": 0.55237907563976,
        "euclidean_pearson": 0.559851026887379,
        "euclidean_spearman": 0.55237907563976,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.55237907563976,
        "manhattan_pearson": 0.5550640609962779,
        "manhattan_spearman": 0.5465780168398393,
        "pearson": 0.5443306617677465,
        "spearman": 0.55237907563976
      },
      {
        "cosine_pearson": 0.5026214423296764,
        "cosine_spearman": 0.474820008075818,
        "euclidean_pearson": 0.5121129112865921,
        "euclidean_spearman": 0.474820008075818,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.474820008075818,
        "manhattan_pearson": 0.5082895335403688,
        "manhattan_spearman": 0.47144401740854186,
        "pearson": 0.5026214423296764,
        "spearman": 0.474820008075818
      },
      {
        "cosine_pearson": 0.4724312458034976,
        "cosine_spearman": 0.46964946642967637,
        "euclidean_pearson": 0.4761211864624856,
        "euclidean_spearman": 0.46964946642967637,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.46964946642967637,
        "manhattan_pearson": 0.4750882690832227,
        "manhattan_spearman": 0.4683300756402552,
        "pearson": 0.4724312458034976,
        "spearman": 0.46964946642967637
      },
      {
        "cosine_pearson": 0.8144809419522542,
        "cosine_spearman": 0.8009170521315604,
        "euclidean_pearson": 0.8150317370998753,
        "euclidean_spearman": 0.8009174849810488,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8009170521315604,
        "manhattan_pearson": 0.8145702608953891,
        "manhattan_spearman": 0.8006367060531441,
        "pearson": 0.8144809419522542,
        "spearman": 0.8009170521315604
      },
      {
        "cosine_pearson": 0.4745183290916011,
        "cosine_spearman": 0.46054342578353613,
        "euclidean_pearson": 0.4785693249363305,
        "euclidean_spearman": 0.46054342578353613,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.46054342578353613,
        "manhattan_pearson": 0.4799892083116788,
        "manhattan_spearman": 0.46221610196268037,
        "pearson": 0.4745183290916011,
        "spearman": 0.46054342578353613
      },
      {
        "cosine_pearson": 0.746740836390827,
        "cosine_spearman": 0.7501287468018092,
        "euclidean_pearson": 0.7271081981392584,
        "euclidean_spearman": 0.7501287468018092,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7501287468018092,
        "manhattan_pearson": 0.7259850274938134,
        "manhattan_spearman": 0.748112510064956,
        "pearson": 0.746740836390827,
        "spearman": 0.7501287468018092
      },
      {
        "cosine_pearson": 0.3280427734853142,
        "cosine_spearman": 0.41612976270621405,
        "euclidean_pearson": 0.40553962937489463,
        "euclidean_spearman": 0.41612976270621405,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.41612976270621405,
        "manhattan_pearson": 0.40608451844694293,
        "manhattan_spearman": 0.4171929260720007,
        "pearson": 0.3280427734853142,
        "spearman": 0.41612976270621405
      },
      {
        "cosine_pearson": 0.49645802318686927,
        "cosine_spearman": 0.5130567560911481,
        "euclidean_pearson": 0.5000856523465922,
        "euclidean_spearman": 0.5130567560911481,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5130567560911481,
        "manhattan_pearson": 0.4971929159149684,
        "manhattan_spearman": 0.5076236408428384,
        "pearson": 0.49645802318686927,
        "spearman": 0.5130567560911481
      },
      {
        "cosine_pearson": 0.7941576152768621,
        "cosine_spearman": 0.7686272756786886,
        "euclidean_pearson": 0.7862601127829459,
        "euclidean_spearman": 0.7686272756786886,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7686272756786886,
        "manhattan_pearson": 0.7861137869175162,
        "manhattan_spearman": 0.7700339557531798,
        "pearson": 0.7941576152768621,
        "spearman": 0.7686272756786886
      },
      {
        "cosine_pearson": 0.7911745213527912,
        "cosine_spearman": 0.7639408616952107,
        "euclidean_pearson": 0.775192865246257,
        "euclidean_spearman": 0.7639408616952107,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7639408616952107,
        "manhattan_pearson": 0.7741299014470844,
        "manhattan_spearman": 0.761086059636311,
        "pearson": 0.7911745213527912,
        "spearman": 0.7639408616952107
      }
    ]
  },
  "task_name": "SemRel24STS"
}