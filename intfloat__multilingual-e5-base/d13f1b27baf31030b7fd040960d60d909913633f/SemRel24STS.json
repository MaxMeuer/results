{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 4.5575597286224365,
  "kg_co2_emissions": 0.00024747470231028124,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8063431972350791,
        "cosine_spearman": 0.7943047577565244,
        "euclidean_pearson": 0.7907675911239929,
        "euclidean_spearman": 0.7943047577565244,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7943047577565244,
        "manhattan_pearson": 0.7903527203448522,
        "manhattan_spearman": 0.7930022073507282,
        "pearson": 0.8063431972350791,
        "spearman": 0.7943047577565244
      },
      {
        "cosine_pearson": 0.7543787096287549,
        "cosine_spearman": 0.7256326276475369,
        "euclidean_pearson": 0.7530692255093374,
        "euclidean_spearman": 0.7256326276475369,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7256326276475369,
        "manhattan_pearson": 0.7524188419715686,
        "manhattan_spearman": 0.7273275429843192,
        "pearson": 0.7543787096287549,
        "spearman": 0.7256326276475369
      },
      {
        "cosine_pearson": 0.504155106952456,
        "cosine_spearman": 0.5019991067552446,
        "euclidean_pearson": 0.5138169412282821,
        "euclidean_spearman": 0.5019991067552446,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.5019991067552446,
        "manhattan_pearson": 0.5133993280857295,
        "manhattan_spearman": 0.5025567025097297,
        "pearson": 0.504155106952456,
        "spearman": 0.5019991067552446
      },
      {
        "cosine_pearson": 0.4827095927418801,
        "cosine_spearman": 0.45324679732323686,
        "euclidean_pearson": 0.4903882776604509,
        "euclidean_spearman": 0.45324679732323686,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.45324679732323686,
        "manhattan_pearson": 0.48835581421917357,
        "manhattan_spearman": 0.4517925066938626,
        "pearson": 0.4827095927418801,
        "spearman": 0.45324679732323686
      },
      {
        "cosine_pearson": 0.4080470966046469,
        "cosine_spearman": 0.40143450894729094,
        "euclidean_pearson": 0.4086982070354375,
        "euclidean_spearman": 0.40143450894729094,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.40143450894729094,
        "manhattan_pearson": 0.41584966003618706,
        "manhattan_spearman": 0.40957106273977345,
        "pearson": 0.4080470966046469,
        "spearman": 0.40143450894729094
      },
      {
        "cosine_pearson": 0.8166646262218509,
        "cosine_spearman": 0.8039019258893243,
        "euclidean_pearson": 0.8159936583265732,
        "euclidean_spearman": 0.8039019258893243,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8039019258893243,
        "manhattan_pearson": 0.8176879886175535,
        "manhattan_spearman": 0.8075392159412234,
        "pearson": 0.8166646262218509,
        "spearman": 0.8039019258893243
      },
      {
        "cosine_pearson": 0.5360676523512852,
        "cosine_spearman": 0.5123414179162021,
        "euclidean_pearson": 0.533454859763763,
        "euclidean_spearman": 0.5123414179162021,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5123414179162021,
        "manhattan_pearson": 0.5259948112713042,
        "manhattan_spearman": 0.5036140564653215,
        "pearson": 0.5360676523512852,
        "spearman": 0.5123414179162021
      },
      {
        "cosine_pearson": 0.7283090905977956,
        "cosine_spearman": 0.7257176943362972,
        "euclidean_pearson": 0.7105961157027397,
        "euclidean_spearman": 0.7257176943362972,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7257176943362972,
        "manhattan_pearson": 0.7093576106492813,
        "manhattan_spearman": 0.7245075624548345,
        "pearson": 0.7283090905977956,
        "spearman": 0.7257176943362972
      },
      {
        "cosine_pearson": 0.28948702672252635,
        "cosine_spearman": 0.39799651795987606,
        "euclidean_pearson": 0.3726374945757329,
        "euclidean_spearman": 0.39799651795987606,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.39799651795987606,
        "manhattan_pearson": 0.37609782499906985,
        "manhattan_spearman": 0.40763658662819646,
        "pearson": 0.28948702672252635,
        "spearman": 0.39799651795987606
      },
      {
        "cosine_pearson": 0.5072765003490803,
        "cosine_spearman": 0.5138349538105524,
        "euclidean_pearson": 0.5105852921916256,
        "euclidean_spearman": 0.5138349538105524,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5138349538105524,
        "manhattan_pearson": 0.501826437748424,
        "manhattan_spearman": 0.5058186392214556,
        "pearson": 0.5072765003490803,
        "spearman": 0.5138349538105524
      },
      {
        "cosine_pearson": 0.7949406500568319,
        "cosine_spearman": 0.7736960416097961,
        "euclidean_pearson": 0.7868994556408411,
        "euclidean_spearman": 0.7736960416097961,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7736960416097961,
        "manhattan_pearson": 0.7879074653930243,
        "manhattan_spearman": 0.7760698425868396,
        "pearson": 0.7949406500568319,
        "spearman": 0.7736960416097961
      },
      {
        "cosine_pearson": 0.801037379042443,
        "cosine_spearman": 0.7742685010164576,
        "euclidean_pearson": 0.7806232707864268,
        "euclidean_spearman": 0.7742685010164576,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7742685010164576,
        "manhattan_pearson": 0.7800590054556594,
        "manhattan_spearman": 0.7736428819807606,
        "pearson": 0.801037379042443,
        "spearman": 0.7742685010164576
      }
    ]
  },
  "task_name": "SemRel24STS"
}