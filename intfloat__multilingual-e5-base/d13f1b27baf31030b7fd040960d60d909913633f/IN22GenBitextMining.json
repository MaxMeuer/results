{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 17.369563579559326,
  "kg_co2_emissions": 0.0009325341401548249,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.4267578125,
        "f1": 0.3707198788797349,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.3707198788797349,
        "precision": 0.3520537788683181,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00928798973824602,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.00928798973824602,
        "precision": 0.007078632093474362,
        "recall": 0.0234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9169921875,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.9169921875,
        "precision": 0.90869140625,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8505882626488095,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.8505882626488095,
        "precision": 0.8370535714285714,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.92578125,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.92578125,
        "precision": 0.9173177083333333,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9373372395833333,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.9373372395833333,
        "precision": 0.93017578125,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.005314418002300135,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.005314418002300135,
        "precision": 0.003817735174904187,
        "recall": 0.0185546875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833334,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9793294270833334,
        "precision": 0.9768880208333333,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.3155962491630224,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3155962491630224,
        "precision": 0.3086535014361226,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.2672917392338843,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2672917392338843,
        "precision": 0.26227534727825985,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.28807736013095064,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.28807736013095064,
        "precision": 0.283128513307376,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.013914786241828788,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.013914786241828788,
        "precision": 0.012497173685651144,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.31059211114362634,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.31059211114362634,
        "precision": 0.3047931140313306,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.3212890625,
        "f1": 0.28764256061332116,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.28764256061332116,
        "precision": 0.2794206717055605,
        "recall": 0.3212890625
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.26992317846608543,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.26992317846608543,
        "precision": 0.2609886956227101,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.26284511598508614,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.26284511598508614,
        "precision": 0.25764827590906497,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.27594084590896134,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.27594084590896134,
        "precision": 0.2703151124903055,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.33542836003108706,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.33542836003108706,
        "precision": 0.3279694867175966,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.25772032022148017,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.25772032022148017,
        "precision": 0.25301922959813217,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.31640625,
        "f1": 0.29861328883698174,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.29861328883698174,
        "precision": 0.2953359734082456,
        "recall": 0.31640625
      },
      {
        "accuracy": 0.328125,
        "f1": 0.30442929629378807,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.30442929629378807,
        "precision": 0.2971875918913326,
        "recall": 0.328125
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.2981081180002932,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2981081180002932,
        "precision": 0.2905812694423998,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.31700317177971127,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.31700317177971127,
        "precision": 0.3106451587557567,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.012114842008103529,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.012114842008103529,
        "precision": 0.01003602309300438,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.359375,
        "f1": 0.3274104982485343,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3274104982485343,
        "precision": 0.3202385592275808,
        "recall": 0.359375
      },
      {
        "accuracy": 0.3203125,
        "f1": 0.29594019439055896,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.29594019439055896,
        "precision": 0.2891750710956159,
        "recall": 0.3203125
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.2942219445330632,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.2942219445330632,
        "precision": 0.28585469925135193,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.2803800451739054,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2803800451739054,
        "precision": 0.2752976012324375,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.2652277981020545,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2652277981020545,
        "precision": 0.2609827832492397,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00883867745125449,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00883867745125449,
        "precision": 0.007637166876796833,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.91240234375,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.91240234375,
        "precision": 0.9033203125,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9106119791666667,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9106119791666667,
        "precision": 0.9023763020833333,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9451497395833333,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9451497395833333,
        "precision": 0.93896484375,
        "recall": 0.9580078125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9713541666666667,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9713541666666667,
        "precision": 0.9677734375,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.0058535668869970576,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0058535668869970576,
        "precision": 0.004681733104529478,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.98193359375,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.98193359375,
        "precision": 0.9798177083333334,
        "recall": 0.986328125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01034418462396978,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.01034418462396978,
        "precision": 0.008382540882677182,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9615885416666667,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9615885416666667,
        "precision": 0.95703125,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.90458984375,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.90458984375,
        "precision": 0.8955078125,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9436848958333333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.9436848958333333,
        "precision": 0.9375,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9617513020833334,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9617513020833334,
        "precision": 0.95751953125,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007644058919149348,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007644058919149348,
        "precision": 0.0061930033313197675,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.99755859375,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.99755859375,
        "precision": 0.9973958333333334,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.01003791715020106,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.01003791715020106,
        "precision": 0.00853279838413662,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8873263888888889,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.8873263888888889,
        "precision": 0.8768636067708333,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8355003720238094,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.8355003720238094,
        "precision": 0.8208333333333334,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9264322916666667,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.9264322916666667,
        "precision": 0.9189453125,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9365234375,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.9365234375,
        "precision": 0.9296875,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007233958755323475,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.007233958755323475,
        "precision": 0.006017398274824522,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9690755208333334,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9690755208333334,
        "precision": 0.96533203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0029272121745413087,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0029272121745413087,
        "precision": 0.002572703281772575,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027413370068802645,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0027413370068802645,
        "precision": 0.002410474397785669,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016300094930213464,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0016300094930213464,
        "precision": 0.0014660478961159064,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002670265287224891,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002670265287224891,
        "precision": 0.002376138336489899,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017134471780315592,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0017134471780315592,
        "precision": 0.0011837651021073706,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009871546302754946,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0009871546302754946,
        "precision": 0.00098187506910659,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012007280156114356,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0012007280156114356,
        "precision": 0.001099682879704301,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032504041409128987,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0032504041409128987,
        "precision": 0.0027879671032974796,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013250861424115102,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0013250861424115102,
        "precision": 0.0009155788502109704,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0033299243455258186,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0033299243455258186,
        "precision": 0.0031786476870628647,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012253095518867925,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0012253095518867925,
        "precision": 0.0011183800869638634,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07053751720858797,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.07053751720858797,
        "precision": 0.06131451291407709,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028472949180177553,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0028472949180177553,
        "precision": 0.0025304598196513877,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005692558725855264,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.005692558725855264,
        "precision": 0.005385454007791467,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001001160632624105,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.001001160632624105,
        "precision": 0.000988926627270016,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022407588923552056,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0022407588923552056,
        "precision": 0.002120203901294926,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001229461533071749,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.001229461533071749,
        "precision": 0.0011204703587516086,
        "recall": 0.0029296875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.90771484375,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.90771484375,
        "precision": 0.8986002604166666,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8507812499999999,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.8507812499999999,
        "precision": 0.8388943142361112,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9389322916666666,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.9389322916666666,
        "precision": 0.93310546875,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.94140625,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.94140625,
        "precision": 0.9353841145833334,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00857533978284035,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.00857533978284035,
        "precision": 0.006559365695103251,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166666,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9806315104166666,
        "precision": 0.9783528645833334,
        "recall": 0.9853515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9280598958333333,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.9280598958333333,
        "precision": 0.919921875,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.85087890625,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.85087890625,
        "precision": 0.83544921875,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.923046875,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.923046875,
        "precision": 0.915771484375,
        "recall": 0.939453125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9449869791666667,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.9449869791666667,
        "precision": 0.9386393229166667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.006806215561910795,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.006806215561910795,
        "precision": 0.005664708771895618,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9814453125,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.9814453125,
        "precision": 0.9794921875,
        "recall": 0.9853515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8751627604166666,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.8751627604166666,
        "precision": 0.8626953125,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8153831845238095,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8153831845238095,
        "precision": 0.7994628906250001,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8920138888888889,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8920138888888889,
        "precision": 0.8823649088541666,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9401692708333333,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9401692708333333,
        "precision": 0.933837890625,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0032860682324102777,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0032860682324102777,
        "precision": 0.0023311372731950318,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9720052083333334,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9720052083333334,
        "precision": 0.9689127604166667,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8444049873737374,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8444049873737374,
        "precision": 0.8347275047971491,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.7392578125,
        "f1": 0.7032845409798535,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7032845409798535,
        "precision": 0.6897536363058943,
        "recall": 0.7392578125
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8641476321530033,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8641476321530033,
        "precision": 0.85741456491677,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6976907414747089,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6976907414747089,
        "precision": 0.6857325915187242,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8842685326597745,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8842685326597745,
        "precision": 0.8780211433531746,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.862598501758658,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.862598501758658,
        "precision": 0.8537569101790935,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.7838316902281746,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7838316902281746,
        "precision": 0.7711111886160715,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.0153719033296251,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0153719033296251,
        "precision": 0.012603468939386457,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8901064918154762,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8901064918154762,
        "precision": 0.8822629898313492,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8821212469362745,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8821212469362745,
        "precision": 0.8749067826704546,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7959424101671919,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7959424101671919,
        "precision": 0.7838322715153769,
        "recall": 0.828125
      },
      {
        "accuracy": 0.875,
        "f1": 0.8576021634615385,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8576021634615385,
        "precision": 0.8514001067120927,
        "recall": 0.875
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8395244136650387,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8395244136650387,
        "precision": 0.8346613266291001,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8508324032738095,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.8508324032738095,
        "precision": 0.837890625,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8948428199404762,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.8948428199404762,
        "precision": 0.8858235677083334,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333334,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9886067708333334,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9065290178571429,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.9065290178571429,
        "precision": 0.89794921875,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.005541559291581639,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.005541559291581639,
        "precision": 0.004144897927434421,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9637044270833333,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.9637044270833333,
        "precision": 0.9599609375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7551614646350071,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7551614646350071,
        "precision": 0.7462773851659633,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7199704807066214,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7199704807066214,
        "precision": 0.7099874585592358,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.8369140625,
        "f1": 0.814668771154295,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.814668771154295,
        "precision": 0.8071890235843515,
        "recall": 0.8369140625
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7929186672492494,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7929186672492494,
        "precision": 0.7829037873641305,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8090355282738095,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8090355282738095,
        "precision": 0.7980492001488095,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009412269131635908,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009412269131635908,
        "precision": 0.00761747328435603,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.8321782943390673,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8321782943390673,
        "precision": 0.8231825086805555,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.828125,
        "f1": 0.8043735773397798,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8043735773397798,
        "precision": 0.7957111202485381,
        "recall": 0.828125
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7592448774429073,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.7592448774429073,
        "precision": 0.7489671054856601,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7908074112752086,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7908074112752086,
        "precision": 0.7840842919203641,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7884715116982797,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7884715116982797,
        "precision": 0.7822441758141931,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9259440104166667,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.9259440104166667,
        "precision": 0.9186197916666667,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9490559895833333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9490559895833333,
        "precision": 0.943359375,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.008317993675415358,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008317993675415358,
        "precision": 0.006614133266058541,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166666,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9728190104166666,
        "precision": 0.9695638020833334,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9045166015625,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9045166015625,
        "precision": 0.8980143229166666,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8874883742559524,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8874883742559524,
        "precision": 0.880176204004329,
        "recall": 0.90625
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8620265151515152,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8620265151515152,
        "precision": 0.851513671875,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.008411524490398186,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008411524490398186,
        "precision": 0.006864553319060987,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9166387648809524,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9166387648809524,
        "precision": 0.909423828125,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8978159102182539,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8978159102182539,
        "precision": 0.8913899739583334,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8610863095238095,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8610863095238095,
        "precision": 0.85029296875,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9142664085046897,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9142664085046897,
        "precision": 0.9100578539299242,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8978895399305555,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8978895399305555,
        "precision": 0.8907617962549603,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9625651041666666,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9625651041666666,
        "precision": 0.9580078125,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.0066692109479766,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0066692109479766,
        "precision": 0.0049069861595219255,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9388020833333334,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.9388020833333334,
        "precision": 0.9322916666666666,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004726033487620534,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004726033487620534,
        "precision": 0.0032747993091873906,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9811197916666667,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.9811197916666667,
        "precision": 0.97900390625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011862169900641921,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.011862169900641921,
        "precision": 0.009666811595522533,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9411280776515152,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9411280776515152,
        "precision": 0.9367350260416667,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8816460503472222,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8816460503472222,
        "precision": 0.8763635859583125,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8541130690056471,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8541130690056471,
        "precision": 0.844946711816829,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.876367739230226,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.876367739230226,
        "precision": 0.872652583699526,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8618096452909829,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8618096452909829,
        "precision": 0.8589310877408822,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032682854811322158,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0032682854811322158,
        "precision": 0.0031315679870088575,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0033590044294084824,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0033590044294084824,
        "precision": 0.003193494888031489,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002452331399566665,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.002452331399566665,
        "precision": 0.002284123812620612,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002283318381180223,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.002283318381180223,
        "precision": 0.002150779376498801,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032714771657684927,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0032714771657684927,
        "precision": 0.003133178408033499,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.992578125,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.992578125,
        "precision": 0.991943359375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9417574179292929,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9417574179292929,
        "precision": 0.9384440104166667,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9321625016693376,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9321625016693376,
        "precision": 0.9289252387152778,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}