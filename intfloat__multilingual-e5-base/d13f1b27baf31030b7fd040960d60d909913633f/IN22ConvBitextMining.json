{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 24.469868421554565,
  "kg_co2_emissions": 0.0009255649533011164,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.1596806387225549,
        "f1": 0.11495474659147314,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.11495474659147314,
        "precision": 0.10203647289182101,
        "recall": 0.1596806387225549
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8140956182872351,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8140956182872351,
        "precision": 0.8002196664871315,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8116766467065869,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8116766467065869,
        "precision": 0.7965798561606944,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7611348731109212,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7611348731109212,
        "precision": 0.744954535373697,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003102541893123952,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.003102541893123952,
        "precision": 0.0020334475896201043,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8279330228432024,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8279330228432024,
        "precision": 0.8144773944175141,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8172876469283655,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8172876469283655,
        "precision": 0.8025900579792796,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8090485695276114,
        "f1": 0.7795502198695811,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.7795502198695811,
        "precision": 0.7684857658673185,
        "recall": 0.8090485695276114
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.4348805515472182,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.4348805515472182,
        "precision": 0.410712701580965,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.8143712574850299,
        "f1": 0.7800684345594525,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7800684345594525,
        "precision": 0.7655688622754492,
        "recall": 0.8143712574850299
      },
      {
        "accuracy": 0.4763805721889554,
        "f1": 0.4241553116802617,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.4241553116802617,
        "precision": 0.40378900688281927,
        "recall": 0.4763805721889554
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7565757374140608,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7565757374140608,
        "precision": 0.7415724107340873,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.4943779108449767,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4943779108449767,
        "precision": 0.47242848569900353,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8187529702499763,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8187529702499763,
        "precision": 0.8061654468840098,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.803371035706365,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.803371035706365,
        "precision": 0.7894876912840986,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.5848303393213573,
        "f1": 0.5272873205008933,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.5272873205008933,
        "precision": 0.5043928016981908,
        "recall": 0.5848303393213573
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0033062782246887634,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0033062782246887634,
        "precision": 0.0023522507257925994,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.759297278458955,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.759297278458955,
        "precision": 0.7427272439248487,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.8582834331337326,
        "f1": 0.8287662769698697,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8287662769698697,
        "precision": 0.8158191553401134,
        "recall": 0.8582834331337326
      },
      {
        "accuracy": 0.6959414504324684,
        "f1": 0.6426976734361964,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.6426976734361964,
        "precision": 0.6210856065646485,
        "recall": 0.6959414504324684
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8289452840351044,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8289452840351044,
        "precision": 0.8164448880017743,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7931681610324324,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.7931681610324324,
        "precision": 0.781972258169863,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.14637391882900866,
        "f1": 0.11686238693759185,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11686238693759185,
        "precision": 0.10992093463418776,
        "recall": 0.14637391882900866
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.09402783341238852,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.09402783341238852,
        "precision": 0.0893847451972878,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.10246174318030606,
        "f1": 0.08051705134867773,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08051705134867773,
        "precision": 0.07600702316955014,
        "recall": 0.10246174318030606
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.009232971383966714,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009232971383966714,
        "precision": 0.007615362598872014,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.08908205899180888,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.08908205899180888,
        "precision": 0.08550876489312093,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.12574850299401197,
        "f1": 0.09858272118750358,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09858272118750358,
        "precision": 0.09256971898100597,
        "recall": 0.12574850299401197
      },
      {
        "accuracy": 0.06320691949434465,
        "f1": 0.05309530056004848,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05309530056004848,
        "precision": 0.05077736634622861,
        "recall": 0.06320691949434465
      },
      {
        "accuracy": 0.09115103127079174,
        "f1": 0.07383029149843175,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.07383029149843175,
        "precision": 0.070703503381834,
        "recall": 0.09115103127079174
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.0959671818810078,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0959671818810078,
        "precision": 0.09099793934432686,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.1217564870259481,
        "f1": 0.10360698241547554,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10360698241547554,
        "precision": 0.0989086832888513,
        "recall": 0.1217564870259481
      },
      {
        "accuracy": 0.10978043912175649,
        "f1": 0.09183292886955728,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.09183292886955728,
        "precision": 0.08789833060207757,
        "recall": 0.10978043912175649
      },
      {
        "accuracy": 0.10844976713240187,
        "f1": 0.0920835678430413,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.0920835678430413,
        "precision": 0.08845676808798884,
        "recall": 0.10844976713240187
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.1088160977061644,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1088160977061644,
        "precision": 0.10350210216548968,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.08651575757714629,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08651575757714629,
        "precision": 0.07968486580094476,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.11147759644361507,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11147759644361507,
        "precision": 0.10652660597974244,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.008282758314346942,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008282758314346942,
        "precision": 0.006222764367999947,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.12508316699933467,
        "f1": 0.10091226388786066,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10091226388786066,
        "precision": 0.09474868621803836,
        "recall": 0.12508316699933467
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.08974964896369424,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08974964896369424,
        "precision": 0.08336648899475535,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.10445775116433799,
        "f1": 0.07906013239543362,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.07906013239543362,
        "precision": 0.07353239986362152,
        "recall": 0.10445775116433799
      },
      {
        "accuracy": 0.11909514304723885,
        "f1": 0.09277524106312274,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09277524106312274,
        "precision": 0.08728351648262475,
        "recall": 0.11909514304723885
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.09343046020584377,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.09343046020584377,
        "precision": 0.08889748519860766,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9373475271678864,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9373475271678864,
        "precision": 0.9321579064094034,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8266815575198808,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8266815575198808,
        "precision": 0.8147176546378143,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005760768033805382,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005760768033805382,
        "precision": 0.004386869411618037,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8877483128980135,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8877483128980135,
        "precision": 0.8795630960301618,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.906000697018661,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.906000697018661,
        "precision": 0.8980927034819249,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9166159744004055,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9166159744004055,
        "precision": 0.9109289357792352,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5529409435098058,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5529409435098058,
        "precision": 0.531339132886039,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.9188290086493679,
        "f1": 0.8993584260051324,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8993584260051324,
        "precision": 0.8907027215410448,
        "recall": 0.9188290086493679
      },
      {
        "accuracy": 0.6187624750499002,
        "f1": 0.5676089287366732,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5676089287366732,
        "precision": 0.5486812090105504,
        "recall": 0.6187624750499002
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8513766118556538,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8513766118556538,
        "precision": 0.8400896619459494,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5965175469167485,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5965175469167485,
        "precision": 0.5782843391468248,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8977505306846624,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8977505306846624,
        "precision": 0.8895431359503216,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8905870798086368,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8905870798086368,
        "precision": 0.8822703798751704,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.7345309381237525,
        "f1": 0.6880053893027945,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6880053893027945,
        "precision": 0.6700678009061243,
        "recall": 0.7345309381237525
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.002939757326846615,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002939757326846615,
        "precision": 0.002131171760495164,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8716255800088135,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8716255800088135,
        "precision": 0.8640919219761534,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9269809587174856,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9269809587174856,
        "precision": 0.9209580838323354,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7570185026771854,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7570185026771854,
        "precision": 0.740249659411336,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9163910274688717,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9163910274688717,
        "precision": 0.9103855780502488,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8992021728548675,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8992021728548675,
        "precision": 0.8915613218008428,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.8072595549641458,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8072595549641458,
        "precision": 0.7954165742588896,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007176874009423063,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.007176874009423063,
        "precision": 0.006007236771714009,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8853900664279907,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8853900664279907,
        "precision": 0.8770181858505212,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8974606342869815,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.8974606342869815,
        "precision": 0.8885625574248328,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8993584260051326,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8993584260051326,
        "precision": 0.8934310123713924,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.6180971390552229,
        "f1": 0.5655929086068806,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.5655929086068806,
        "precision": 0.5468152827434264,
        "recall": 0.6180971390552229
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8774134271140259,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8774134271140259,
        "precision": 0.867476158793524,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.4731540818167565,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.4731540818167565,
        "precision": 0.45406575017353457,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8705235032580342,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8705235032580342,
        "precision": 0.8620980261698825,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.5568862275449101,
        "f1": 0.5061198818184846,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5061198818184846,
        "precision": 0.4882874661363511,
        "recall": 0.5568862275449101
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9153486677438775,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9153486677438775,
        "precision": 0.909376485124988,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8859297278458954,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8859297278458954,
        "precision": 0.8763583943224662,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6220596325386745,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6220596325386745,
        "precision": 0.6013407669565941,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0033247303254566405,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0033247303254566405,
        "precision": 0.002556461513973435,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8879162310300034,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8879162310300034,
        "precision": 0.8799955644267021,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9232571893250536,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9232571893250536,
        "precision": 0.9176036815258372,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7382652351714227,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7382652351714227,
        "precision": 0.7216939137597822,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9080727434020848,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9080727434020848,
        "precision": 0.9017409625194056,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.9018835345182651,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9018835345182651,
        "precision": 0.8957703640338371,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004270382510717697,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.004270382510717697,
        "precision": 0.003265779038861853,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8142381902860945,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8142381902860945,
        "precision": 0.7995675316034597,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.7948695202188216,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.7948695202188216,
        "precision": 0.7786223848599098,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.8023952095808383,
        "f1": 0.7711202414795228,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.7711202414795228,
        "precision": 0.7591105981325541,
        "recall": 0.8023952095808383
      },
      {
        "accuracy": 0.4750499001996008,
        "f1": 0.41192165932684893,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.41192165932684893,
        "precision": 0.38908320924288986,
        "recall": 0.4750499001996008
      },
      {
        "accuracy": 0.7970725216234198,
        "f1": 0.758526861620674,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.758526861620674,
        "precision": 0.74157874726737,
        "recall": 0.7970725216234198
      },
      {
        "accuracy": 0.44644045242847635,
        "f1": 0.3888105087271971,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.3888105087271971,
        "precision": 0.36814367521081026,
        "recall": 0.44644045242847635
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7176842563070107,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7176842563070107,
        "precision": 0.6992369351650789,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.45707708227732124,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.45707708227732124,
        "precision": 0.4381097522036233,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7774862972467763,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.7774862972467763,
        "precision": 0.7610624904038078,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.8066327662136046,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8066327662136046,
        "precision": 0.7930092196559262,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.5442448436460412,
        "f1": 0.481315162253286,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.481315162253286,
        "precision": 0.45850395381039977,
        "recall": 0.5442448436460412
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.003215593534140212,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003215593534140212,
        "precision": 0.0023381472266311284,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.780439121756487,
        "f1": 0.738486437787835,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.738486437787835,
        "precision": 0.7212434918522743,
        "recall": 0.780439121756487
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8302506098913285,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8302506098913285,
        "precision": 0.8162748576920233,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6215790640940342,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.6215790640940342,
        "precision": 0.5976911496871575,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.8033192873512235,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8033192873512235,
        "precision": 0.7903544762327198,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7917735956658112,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7917735956658112,
        "precision": 0.7784605392389824,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0024272086115263124,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0024272086115263124,
        "precision": 0.0019876461636395013,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00262476858456629,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.00262476858456629,
        "precision": 0.0022401740980196,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013770456888148334,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0013770456888148334,
        "precision": 0.00135446279158854,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.002828980016007452,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002828980016007452,
        "precision": 0.0024734863481497946,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001633368651047169,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.001633368651047169,
        "precision": 0.0014960690046261875,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0017190821119660688,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0017190821119660688,
        "precision": 0.0013527712365105015,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0021406117635794347,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0021406117635794347,
        "precision": 0.001616690467122595,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015478930942122205,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0015478930942122205,
        "precision": 0.0014466341468050683,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001405864516297633,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.001405864516297633,
        "precision": 0.0011475771318155514,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011371748796898497,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0011371748796898497,
        "precision": 0.0009407484221706688,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015885869082684573,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0015885869082684573,
        "precision": 0.0014722331742462284,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.026005791141718443,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.026005791141718443,
        "precision": 0.023478831363062898,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0017521093147345324,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0017521093147345324,
        "precision": 0.0013775316261974751,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013737773628961908,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0013737773628961908,
        "precision": 0.0010910007742099743,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0013753278734620286,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0013753278734620286,
        "precision": 0.001067908205725286,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001699530790985353,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.001699530790985353,
        "precision": 0.0015493501005983557,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017873297580901538,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0017873297580901538,
        "precision": 0.0015997548807695384,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.864318981085448,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.864318981085448,
        "precision": 0.8533710357063651,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8625967641436701,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8625967641436701,
        "precision": 0.8552310722470402,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.5369261477045908,
        "f1": 0.47432595127205907,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.47432595127205907,
        "precision": 0.4502019769983842,
        "recall": 0.5369261477045908
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8144409593511389,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8144409593511389,
        "precision": 0.7996118873364382,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.4657351962741184,
        "f1": 0.4157091885200885,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.4157091885200885,
        "precision": 0.39733248750214817,
        "recall": 0.4657351962741184
      },
      {
        "accuracy": 0.8416500332667998,
        "f1": 0.8069950046995954,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8069950046995954,
        "precision": 0.7919446820644425,
        "recall": 0.8416500332667998
      },
      {
        "accuracy": 0.5662009314703925,
        "f1": 0.5159878323051976,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5159878323051976,
        "precision": 0.49829942821491696,
        "recall": 0.5662009314703925
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8765136393878908,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8765136393878908,
        "precision": 0.867276557995121,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8669882457307608,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8669882457307608,
        "precision": 0.8566486075468112,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.5948103792415169,
        "f1": 0.5369135706461056,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.5369135706461056,
        "precision": 0.5152612763890209,
        "recall": 0.5948103792415169
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0032310134605543785,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0032310134605543785,
        "precision": 0.002723876626072235,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8228226087507524,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8228226087507524,
        "precision": 0.8115129529301185,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8896872920825017,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8896872920825017,
        "precision": 0.8810711909514305,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.7485029940119761,
        "f1": 0.7004022886258416,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7004022886258416,
        "precision": 0.6803369045385014,
        "recall": 0.7485029940119761
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8711814466305483,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8711814466305483,
        "precision": 0.86187624750499,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8474912608645144,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8474912608645144,
        "precision": 0.8387737992029409,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8791232350114585,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8791232350114585,
        "precision": 0.8710095681652568,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5094202210410969,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.5094202210410969,
        "precision": 0.4850686193750066,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8567975160789532,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8567975160789532,
        "precision": 0.8453759148369926,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.49833666001330673,
        "f1": 0.444931186947155,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.444931186947155,
        "precision": 0.4257046753054736,
        "recall": 0.49833666001330673
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.8769476919177518,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8769476919177518,
        "precision": 0.8676424927921933,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.5244569476760267,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.5244569476760267,
        "precision": 0.5055497710687331,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9080632386021606,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9080632386021606,
        "precision": 0.9005877134619649,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8819250388112664,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8819250388112664,
        "precision": 0.8722222222222222,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5815641899159075,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.5815641899159075,
        "precision": 0.5583356929165313,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.00324204832790111,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00324204832790111,
        "precision": 0.0024762280855824556,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8711370908975699,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.8711370908975699,
        "precision": 0.8612885340430251,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.9227323131514749,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9227323131514749,
        "precision": 0.9157795520070969,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.7777777777777778,
        "f1": 0.7336353747531392,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7336353747531392,
        "precision": 0.7161521113616921,
        "recall": 0.7777777777777778
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.904280328232424,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.904280328232424,
        "precision": 0.8968174761587934,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8963533250958401,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.8963533250958401,
        "precision": 0.8897477771729269,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.445268817823708,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.445268817823708,
        "precision": 0.4178510918501525,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8899344168805245,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8899344168805245,
        "precision": 0.8800251349153546,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.42328500766624516,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.42328500766624516,
        "precision": 0.3959424307540768,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.8629407850964738,
        "f1": 0.8349887526534233,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8349887526534233,
        "precision": 0.8236942953292862,
        "recall": 0.8629407850964738
      },
      {
        "accuracy": 0.5395874916833001,
        "f1": 0.46457665717146757,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.46457665717146757,
        "precision": 0.43872913882893927,
        "recall": 0.5395874916833001
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9107800272470932,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9107800272470932,
        "precision": 0.9030336153090643,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8957535908575005,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8957535908575005,
        "precision": 0.8878770237303171,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6275259485838328,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6275259485838328,
        "precision": 0.601933698740086,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0016562932571639569,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0016562932571639569,
        "precision": 0.0012386079111276651,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8919151595798303,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8919151595798303,
        "precision": 0.8837895637296835,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9314925704147261,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9314925704147261,
        "precision": 0.926713240186294,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.729791211228337,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.729791211228337,
        "precision": 0.7112230805344578,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9055571396888763,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9055571396888763,
        "precision": 0.897989206771642,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9179915301671788,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9179915301671788,
        "precision": 0.9115232497967029,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.5229540918163673,
        "f1": 0.46988577936094666,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.46988577936094666,
        "precision": 0.45295652444900464,
        "recall": 0.5229540918163673
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2326262526741778,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.2326262526741778,
        "precision": 0.22174475290252282,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.458416500332668,
        "f1": 0.41410978184924574,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.41410978184924574,
        "precision": 0.39973755800337935,
        "recall": 0.458416500332668
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.22608186198756255,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.22608186198756255,
        "precision": 0.21688018483429541,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4580919927122112,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.4580919927122112,
        "precision": 0.44378344945835624,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.5149700598802395,
        "f1": 0.46190012921575113,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.46190012921575113,
        "precision": 0.4439501788146603,
        "recall": 0.5149700598802395
      },
      {
        "accuracy": 0.35994677312042583,
        "f1": 0.31163306219158005,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.31163306219158005,
        "precision": 0.2957562741830736,
        "recall": 0.35994677312042583
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.006924778112402864,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006924778112402864,
        "precision": 0.00489813673653874,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.5050138146375779,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5050138146375779,
        "precision": 0.4892364626804072,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.4873064596370224,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.4873064596370224,
        "precision": 0.47408502532268715,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.426480372588157,
        "f1": 0.3754737401128829,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.3754737401128829,
        "precision": 0.35881469384463394,
        "recall": 0.426480372588157
      },
      {
        "accuracy": 0.52228875582169,
        "f1": 0.4803403829867296,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.4803403829867296,
        "precision": 0.46724409520875415,
        "recall": 0.52228875582169
      },
      {
        "accuracy": 0.5089820359281437,
        "f1": 0.4668230511703386,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.4668230511703386,
        "precision": 0.453021890821701,
        "recall": 0.5089820359281437
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.49449303300424585,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.49449303300424585,
        "precision": 0.47465058282834494,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8345013676351003,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8345013676351003,
        "precision": 0.8226565387743032,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.5888223552894212,
        "f1": 0.5397779237100594,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5397779237100594,
        "precision": 0.5214532756291345,
        "recall": 0.5888223552894212
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8881823654278744,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8881823654278744,
        "precision": 0.8802727877578178,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.8351313246522828,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8351313246522828,
        "precision": 0.822195291955771,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.6345478835498795,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6345478835498795,
        "precision": 0.6127762992533452,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0029877945264309104,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0029877945264309104,
        "precision": 0.001842004617969381,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8546430947628553,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8546430947628553,
        "precision": 0.8460163921241766,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8887241390235402,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.8887241390235402,
        "precision": 0.8797516078953205,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.7651363938789089,
        "f1": 0.7190703249585485,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7190703249585485,
        "precision": 0.7001388996897978,
        "recall": 0.7651363938789089
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8834150989839612,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.8834150989839612,
        "precision": 0.8753825681969395,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8860791644224777,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8860791644224777,
        "precision": 0.8779670817095966,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.4530938123752495,
        "f1": 0.40060218673958936,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.40060218673958936,
        "precision": 0.3828437789016631,
        "recall": 0.4530938123752495
      },
      {
        "accuracy": 0.3992015968063872,
        "f1": 0.3509143937688355,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3509143937688355,
        "precision": 0.33644053421997533,
        "recall": 0.3992015968063872
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.46869257008977566,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.46869257008977566,
        "precision": 0.4488306461320702,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.48835662009314706,
        "f1": 0.4280624215093227,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4280624215093227,
        "precision": 0.40842085669929984,
        "recall": 0.48835662009314706
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.4423610295748372,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4423610295748372,
        "precision": 0.4226505142672808,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0058028604036551405,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0058028604036551405,
        "precision": 0.004327619185361937,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.5528942115768463,
        "f1": 0.49851754353131106,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.49851754353131106,
        "precision": 0.4798375065091633,
        "recall": 0.5528942115768463
      },
      {
        "accuracy": 0.5089820359281437,
        "f1": 0.4523215720102505,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4523215720102505,
        "precision": 0.4337809832008842,
        "recall": 0.5089820359281437
      },
      {
        "accuracy": 0.4204923486360612,
        "f1": 0.36069819944875425,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.36069819944875425,
        "precision": 0.34044063886878256,
        "recall": 0.4204923486360612
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.477533095610666,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.477533095610666,
        "precision": 0.459070343052379,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.5515635395874917,
        "f1": 0.5008395158147869,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5008395158147869,
        "precision": 0.4834896926463793,
        "recall": 0.5515635395874917
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.48642496453716116,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.48642496453716116,
        "precision": 0.4675728149281043,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8667807242657543,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8667807242657543,
        "precision": 0.8574961188733643,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.8429807052561543,
        "f1": 0.8125083166999334,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8125083166999334,
        "precision": 0.7989243734752717,
        "recall": 0.8429807052561543
      },
      {
        "accuracy": 0.6161011310711909,
        "f1": 0.5629507034696656,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5629507034696656,
        "precision": 0.5429812813046346,
        "recall": 0.6161011310711909
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.004048302593546203,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.004048302593546203,
        "precision": 0.0027708021883451482,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8348192503881127,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8348192503881127,
        "precision": 0.823486360612109,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8809618857523048,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8809618857523048,
        "precision": 0.8710800620980261,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7164511432974507,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7164511432974507,
        "precision": 0.6983485410132118,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8624813864334823,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8624813864334823,
        "precision": 0.8527568794035859,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8457693079449566,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8457693079449566,
        "precision": 0.835551912048918,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.5504261318632576,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5504261318632576,
        "precision": 0.5303893947888567,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5109110194406269,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5109110194406269,
        "precision": 0.4910910853026622,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.479707252162342,
        "f1": 0.4297595285619238,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4297595285619238,
        "precision": 0.4110027081055613,
        "recall": 0.479707252162342
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007566781646780261,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007566781646780261,
        "precision": 0.006192323512309183,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5439749316994826,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5439749316994826,
        "precision": 0.52500735200336,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5284763141050566,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5284763141050566,
        "precision": 0.5099917500821575,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.44508657048577205,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44508657048577205,
        "precision": 0.4237950025874178,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.6017503860817234,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6017503860817234,
        "precision": 0.5840604317433268,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.5981370592149036,
        "f1": 0.5538536277059231,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5538536277059231,
        "precision": 0.5374051979583022,
        "recall": 0.5981370592149036
      },
      {
        "accuracy": 0.8968729208250167,
        "f1": 0.8712923359629946,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8712923359629946,
        "precision": 0.8601685517853184,
        "recall": 0.8968729208250167
      },
      {
        "accuracy": 0.6932801064537591,
        "f1": 0.642379790683184,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.642379790683184,
        "precision": 0.6233155622377179,
        "recall": 0.6932801064537591
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0028282362822679786,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0028282362822679786,
        "precision": 0.002242263732706856,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8911415264708676,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8911415264708676,
        "precision": 0.8832557108006209,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9193834553115989,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9193834553115989,
        "precision": 0.9135506764249279,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7781367667595211,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7781367667595211,
        "precision": 0.7614105123087159,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9124196052339765,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9124196052339765,
        "precision": 0.9055999112885341,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8925498209929348,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8925498209929348,
        "precision": 0.8849475651870862,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.612109115103127,
        "f1": 0.5499559766026832,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5499559766026832,
        "precision": 0.5261696664391274,
        "recall": 0.612109115103127
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004328324084463979,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004328324084463979,
        "precision": 0.0036003713582019557,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8313816810822798,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.8313816810822798,
        "precision": 0.8199001707983743,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9119760479041915,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9119760479041915,
        "precision": 0.905045464626303,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7081603175415552,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7081603175415552,
        "precision": 0.6883246974065338,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8946551341760923,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.8946551341760923,
        "precision": 0.8863051674428919,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8715806482273548,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8715806482273548,
        "precision": 0.8627818437199674,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0036280790779379306,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0036280790779379306,
        "precision": 0.0025313827469966303,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6519029665536652,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6519029665536652,
        "precision": 0.6339538941617394,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5748646708335902,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5748646708335902,
        "precision": 0.5556033419254346,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.4639111910011287,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4639111910011287,
        "precision": 0.44416073595215305,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.6053944236472693,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6053944236472693,
        "precision": 0.590012658218352,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.6493679308050565,
        "f1": 0.6063859338220255,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6063859338220255,
        "precision": 0.5912086655273165,
        "recall": 0.6493679308050565
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008216777056353502,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0008216777056353502,
        "precision": 0.0007465206067337811,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009647515477959851,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009647515477959851,
        "precision": 0.0006554013689102268,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0006579573378839297,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0006579573378839297,
        "precision": 0.00037455330698476814,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00011262177963865648,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.00011262177963865648,
        "precision": 5.7325813352982314e-05,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016901146496641865,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0016901146496641865,
        "precision": 0.001530054378455936,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8650476824129519,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8650476824129519,
        "precision": 0.8540363717010424,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.7697937458416501,
        "f1": 0.7232243693321537,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7232243693321537,
        "precision": 0.7039254823685961,
        "recall": 0.7697937458416501
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8744400088711466,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8744400088711466,
        "precision": 0.8648544181478313,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8603538141462292,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8603538141462292,
        "precision": 0.8511651300573456,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.7811044577511643,
        "f1": 0.7376897479691891,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7376897479691891,
        "precision": 0.7196240035561392,
        "recall": 0.7811044577511643
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9157019294743847,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9157019294743847,
        "precision": 0.9086493679308051,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8999419151115757,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8999419151115757,
        "precision": 0.8936404967842093,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7352755287885028,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7352755287885028,
        "precision": 0.7216913615449876,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6851789152928052,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6851789152928052,
        "precision": 0.6730228289859028,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9029718341095587,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9029718341095587,
        "precision": 0.8955311599024174,
        "recall": 0.9201596806387226
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}