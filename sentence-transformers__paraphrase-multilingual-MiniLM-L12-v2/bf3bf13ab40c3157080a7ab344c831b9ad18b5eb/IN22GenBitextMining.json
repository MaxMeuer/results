{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 11.360186338424683,
  "kg_co2_emissions": 0.0004259240490213342,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.01171875,
        "f1": 0.006078381794388039,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.006078381794388039,
        "precision": 0.005680850437947518,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.04000875797132719,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.04000875797132719,
        "precision": 0.039458900369623656,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.03537531980994152,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.03537531980994152,
        "precision": 0.03527934935623024,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05035726981096925,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.05035726981096925,
        "precision": 0.04489754223640942,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002276543913465913,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.002276543913465913,
        "precision": 0.0021264585211246633,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06339119449367121,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.06339119449367121,
        "precision": 0.058030517017280354,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.058215751262626264,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.058215751262626264,
        "precision": 0.053835956525408436,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.057670230653416796,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.057670230653416796,
        "precision": 0.056773037695191715,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.007874131892946131,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.007874131892946131,
        "precision": 0.007843969565278244,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.035244913354175046,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.035244913354175046,
        "precision": 0.034312084860438186,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.011871122617148136,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.011871122617148136,
        "precision": 0.011801197489754098,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.0435915773609511,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0435915773609511,
        "precision": 0.041533290226591024,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.009444776714513556,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.009444776714513556,
        "precision": 0.0092796856264988,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.02091373735900428,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.02091373735900428,
        "precision": 0.020744955948208722,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.041656160240515466,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.041656160240515466,
        "precision": 0.037340564871677556,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.021558207947530862,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.021558207947530862,
        "precision": 0.02124460864798905,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024843472960992905,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0024843472960992905,
        "precision": 0.0020668542038027333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.028021634916166167,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.028021634916166167,
        "precision": 0.027845526578481727,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.0253574469150641,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0253574469150641,
        "precision": 0.02421577492817248,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01432499667199148,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.01432499667199148,
        "precision": 0.01416119736140725,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.024101587942357793,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.024101587942357793,
        "precision": 0.023444052725979544,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023179842503911335,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.023179842503911335,
        "precision": 0.02193912231092201,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.08127809848780093,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08127809848780093,
        "precision": 0.07852927021162093,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06780009906369025,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.06780009906369025,
        "precision": 0.06493464905267149,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.05511335363018945,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05511335363018945,
        "precision": 0.04933469310876476,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011755351624800638,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011755351624800638,
        "precision": 0.0007796999007936508,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05349054441520409,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.05349054441520409,
        "precision": 0.04883852952731312,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015481850410618794,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.015481850410618794,
        "precision": 0.011790597098214286,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06911394421423725,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06911394421423725,
        "precision": 0.0660779551917113,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.0605222773731203,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0605222773731203,
        "precision": 0.05703512524801588,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.0407431232040099,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0407431232040099,
        "precision": 0.03530581918327248,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.10544537927350428,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10544537927350428,
        "precision": 0.10133114769345239,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.014304260144037323,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.014304260144037323,
        "precision": 0.012126848845598845,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.08095552465160141,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08095552465160141,
        "precision": 0.07783018924899505,
        "recall": 0.09375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07244058056511612,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07244058056511612,
        "precision": 0.06885826727553669,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05053794798882613,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.05053794798882613,
        "precision": 0.04539420059293996,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0907442477670416,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0907442477670416,
        "precision": 0.08813500497855392,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008489209976105137,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008489209976105137,
        "precision": 0.0005227161788586452,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.08097733376887341,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08097733376887341,
        "precision": 0.07871178760170613,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02796721049937546,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.02796721049937546,
        "precision": 0.023830599196810135,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06489442335106066,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.06489442335106066,
        "precision": 0.0606358904917086,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06776443563651288,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06776443563651288,
        "precision": 0.06346878173887338,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.050033117242154,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.050033117242154,
        "precision": 0.04713820683131338,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9449869791666667,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9449869791666667,
        "precision": 0.9388020833333333,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.12164119507889123,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12164119507889123,
        "precision": 0.10385420099638693,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00010848370457628329,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00010848370457628329,
        "precision": 5.5312486234866215e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.14530008508265632,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.14530008508265632,
        "precision": 0.12287691131777595,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.09647197259932835,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09647197259932835,
        "precision": 0.07863778653851534,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97314453125,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.97314453125,
        "precision": 0.9700520833333333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.30859375,
        "f1": 0.22214820498511903,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.22214820498511903,
        "precision": 0.19606676051557714,
        "recall": 0.30859375
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.17209467955052193,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.17209467955052193,
        "precision": 0.1464408580079734,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5347693810096154,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5347693810096154,
        "precision": 0.5070967769209956,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.06921422641289793,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06921422641289793,
        "precision": 0.05629087467953899,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5498767671130953,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5498767671130953,
        "precision": 0.5207395523313492,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7532374526515151,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7532374526515151,
        "precision": 0.7315755208333332,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.11611358379550676,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11611358379550676,
        "precision": 0.09762994366266545,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6746171254960318,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6746171254960318,
        "precision": 0.6480875651041667,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003307093677246901,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003307093677246901,
        "precision": 0.0001737246782253576,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.869140625,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.869140625,
        "precision": 0.85595703125,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.15473224948416264,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.15473224948416264,
        "precision": 0.12826931775906386,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.5517578125,
        "f1": 0.47541239684794373,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.47541239684794373,
        "precision": 0.4452241443452381,
        "recall": 0.5517578125
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.7997907366071428,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7997907366071428,
        "precision": 0.7788899739583334,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.7060546875,
        "f1": 0.628862072172619,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.628862072172619,
        "precision": 0.5965425037202381,
        "recall": 0.7060546875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.11035676497426905,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.11035676497426905,
        "precision": 0.09351245640947575,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019155388503158672,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0019155388503158672,
        "precision": 0.0015302770673864424,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.14156911487322368,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14156911487322368,
        "precision": 0.11831146780714541,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.09052760413347737,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.09052760413347737,
        "precision": 0.07232073762008258,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9557291666666667,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9557291666666667,
        "precision": 0.9501953125,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.341796875,
        "f1": 0.25592617018398267,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.25592617018398267,
        "precision": 0.22945854330131674,
        "recall": 0.341796875
      },
      {
        "accuracy": 0.2626953125,
        "f1": 0.16452276022588522,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.16452276022588522,
        "precision": 0.13868725489947736,
        "recall": 0.2626953125
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.459295169890873,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.459295169890873,
        "precision": 0.42919683398199016,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.06972774860290082,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.06972774860290082,
        "precision": 0.05595580627365739,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.509060400320166,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.509060400320166,
        "precision": 0.47907017299107146,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.6981608072916667,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.6981608072916667,
        "precision": 0.6737885974702381,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.10619621377831615,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.10619621377831615,
        "precision": 0.08764027168265842,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6093501984126984,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6093501984126984,
        "precision": 0.5803955078125,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00033349096016566473,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00033349096016566473,
        "precision": 0.000176570752228647,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7943033854166667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7943033854166667,
        "precision": 0.7762858072916666,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.14013086331560595,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.14013086331560595,
        "precision": 0.11522350302437045,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4394245186237373,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.4394245186237373,
        "precision": 0.4085205078125,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7434895833333334,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7434895833333334,
        "precision": 0.719677734375,
        "recall": 0.796875
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.59921875,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.59921875,
        "precision": 0.5644694010416667,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000556485615079365,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.000556485615079365,
        "precision": 0.0003603120432538595,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.2126788576007326,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.2126788576007326,
        "precision": 0.20196842924870267,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07429503367003366,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.07429503367003366,
        "precision": 0.06726134465520772,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.14832787070667844,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.14832787070667844,
        "precision": 0.14507395267715037,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07609827662773234,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.07609827662773234,
        "precision": 0.07349847359700831,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.14750472678309917,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.14750472678309917,
        "precision": 0.14235771159123567,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.05762927032458282,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.05762927032458282,
        "precision": 0.05633736398589621,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06769016336803244,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.06769016336803244,
        "precision": 0.06122200491546708,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.062008766657151215,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.062008766657151215,
        "precision": 0.061026456823449496,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.08353193557418376,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.08353193557418376,
        "precision": 0.0826247888017531,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.21523260248241502,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.21523260248241502,
        "precision": 0.205194576202877,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.08227045475277185,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.08227045475277185,
        "precision": 0.08036050640788997,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003011067708333333,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003011067708333333,
        "precision": 0.002613467261904762,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.09232455021641109,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.09232455021641109,
        "precision": 0.09067741806557342,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.10424777208468614,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.10424777208468614,
        "precision": 0.09826632088855308,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.059736573140680996,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.059736573140680996,
        "precision": 0.057944461587372834,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.08974102362875787,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.08974102362875787,
        "precision": 0.08849500230815574,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.06765731383318385,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.06765731383318385,
        "precision": 0.0646401721982934,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003984617902143675,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0003984617902143675,
        "precision": 0.00021856070941608433,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002664697443000765,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0002664697443000765,
        "precision": 0.00014069435457563856,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.019777662874871e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.019777662874871e-06,
        "precision": 1.010934265010352e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.632649194039855e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 7.632649194039855e-06,
        "precision": 3.823813948508521e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.2674459586466166e-05,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 3.2674459586466166e-05,
        "precision": 1.6521057347670253e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1653270509977827e-06,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 2.1653270509977827e-06,
        "precision": 1.0838651498335183e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009011130136986302,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0009011130136986302,
        "precision": 0.0006200456841097109,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5012071883711668e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 1.5012071883711668e-05,
        "precision": 7.548437926412277e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00017980696219103477,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00017980696219103477,
        "precision": 9.878261966551327e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00014586305973280598,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.00014586305973280598,
        "precision": 7.70580535854675e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.513122441577284e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 9.513122441577284e-05,
        "precision": 4.989191857298475e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.047017065392494714,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.047017065392494714,
        "precision": 0.04065923632574023,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009791459986772486,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0009791459986772486,
        "precision": 0.0009778559602649007,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.289717348927874e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 9.289717348927874e-05,
        "precision": 4.7949058919803604e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000978482976892822,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.000978482976892822,
        "precision": 0.0009775236835629921,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.1268941208405187e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 2.1268941208405187e-05,
        "precision": 1.0730416621825227e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.953122623431025e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 4.953122623431025e-05,
        "precision": 2.4985837729978356e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08043114700219192,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.08043114700219192,
        "precision": 0.0726413085357249,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.2158253732540902,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.2158253732540902,
        "precision": 0.21314501883611703,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.08737471347847789,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.08737471347847789,
        "precision": 0.08493382085417907,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.1543886208192849,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.1543886208192849,
        "precision": 0.14849994962177576,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.09944466196419322,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.09944466196419322,
        "precision": 0.09787736966164409,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08179098462301587,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.08179098462301587,
        "precision": 0.0739841448337542,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.08832980703141682,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.08832980703141682,
        "precision": 0.08667041618984439,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.10890784289313335,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.10890784289313335,
        "precision": 0.10730582292446358,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.271117259837963,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.271117259837963,
        "precision": 0.26151033382735683,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.10613335615022251,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.10613335615022251,
        "precision": 0.10433623872179587,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003956221515008644,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.003956221515008644,
        "precision": 0.0033156652644733267,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.13433737291466122,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.13433737291466122,
        "precision": 0.13268002998426504,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12984442752056496,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.12984442752056496,
        "precision": 0.12304309509212619,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.09180043260473589,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.09180043260473589,
        "precision": 0.09020360496502432,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.11648763020833333,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.11648763020833333,
        "precision": 0.11516229538690476,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0908615048718033,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.0908615048718033,
        "precision": 0.08747527661634863,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.1054954664681969,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.1054954664681969,
        "precision": 0.10241054410472741,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.025034373329924073,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.025034373329924073,
        "precision": 0.023770945600873485,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.07565472315228175,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.07565472315228175,
        "precision": 0.07066697961005752,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03476896367521368,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.03476896367521368,
        "precision": 0.03306916351550609,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10625,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.10625,
        "precision": 0.09921612850869513,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03115198538109181,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.03115198538109181,
        "precision": 0.02921642941030579,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.07119479121533795,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.07119479121533795,
        "precision": 0.06941901312934028,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06489168994414969,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.06489168994414969,
        "precision": 0.06002415783002488,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.04780046988224637,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.04780046988224637,
        "precision": 0.0465371378629795,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003898652030892448,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.003898652030892448,
        "precision": 0.003024102633477633,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.0668986619572557,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0668986619572557,
        "precision": 0.065129852379917,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.09354225974810214,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.09354225974810214,
        "precision": 0.08933026957231756,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.04508730727029184,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.04508730727029184,
        "precision": 0.043254178665940224,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07389343499825421,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.07389343499825421,
        "precision": 0.07229984199905576,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07262199414658055,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.07262199414658055,
        "precision": 0.06853310184691369,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.2145723306795651,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.2145723306795651,
        "precision": 0.18931345753855522,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.1731641512467566,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.1731641512467566,
        "precision": 0.1490008439751374,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.4943607390873016,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.4943607390873016,
        "precision": 0.46634854403409093,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.06770665457633206,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.06770665457633206,
        "precision": 0.054511202257776725,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.60546875,
        "f1": 0.5278715587797619,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5278715587797619,
        "precision": 0.4970741877480158,
        "recall": 0.60546875
      },
      {
        "accuracy": 0.7744140625,
        "f1": 0.7186275421626984,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.7186275421626984,
        "precision": 0.6943277994791667,
        "recall": 0.7744140625
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.11642216416643329,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.11642216416643329,
        "precision": 0.09936856045287923,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6479104662698412,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6479104662698412,
        "precision": 0.6218343098958333,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00019049422648076463,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00019049422648076463,
        "precision": 9.877767931197094e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8273949032738095,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8273949032738095,
        "precision": 0.8128580729166667,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.1545569962806291,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.1545569962806291,
        "precision": 0.12968665263715634,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.4384517609126984,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.4384517609126984,
        "precision": 0.4088883040787338,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.810546875,
        "f1": 0.7598361545138889,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.7598361545138889,
        "precision": 0.7372407459077381,
        "recall": 0.810546875
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6005945335046898,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.6005945335046898,
        "precision": 0.5657633463541667,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.08812375439443454,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.08812375439443454,
        "precision": 0.07913113366975352,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.1734434006797583,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1734434006797583,
        "precision": 0.1668145006035631,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.031309890196608944,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.031309890196608944,
        "precision": 0.025949083468614714,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.16256166630678348,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.16256166630678348,
        "precision": 0.15520798271565572,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.16889783100280045,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.16889783100280045,
        "precision": 0.16262258991630488,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.07375330917781152,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07375330917781152,
        "precision": 0.06428279743152333,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.17388477971959587,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.17388477971959587,
        "precision": 0.16706486039972868,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011033579448850319,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0011033579448850319,
        "precision": 0.0007384347646061465,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.234375,
        "f1": 0.20738265933818573,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.20738265933818573,
        "precision": 0.1980269399562302,
        "recall": 0.234375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06986960872817949,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.06986960872817949,
        "precision": 0.0607951904869477,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.11015861037833694,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.11015861037833694,
        "precision": 0.10450758774517965,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.16906254372074686,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.16906254372074686,
        "precision": 0.16160590819770507,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.14016826819415323,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.14016826819415323,
        "precision": 0.1314593926768125,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0910915798611111,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.0910915798611111,
        "precision": 0.08892463235294118,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08064371744791665,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.08064371744791665,
        "precision": 0.07142984651017666,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.09027212620117882,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.09027212620117882,
        "precision": 0.08666082777437634,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.140625,
        "f1": 0.13145256159185892,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.13145256159185892,
        "precision": 0.1288625321740255,
        "recall": 0.140625
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.1271785869295962,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.1271785869295962,
        "precision": 0.11600556697615669,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.133872043115019,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.133872043115019,
        "precision": 0.13046442438077663,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018704530423280423,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0018704530423280423,
        "precision": 0.0012989533253205125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.14760460070830936,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.14760460070830936,
        "precision": 0.1440242587999055,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12652631467850328,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.12652631467850328,
        "precision": 0.11811331472928747,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.1013596415855894,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.1013596415855894,
        "precision": 0.09724286612817795,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.15625,
        "f1": 0.14436642278439152,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.14436642278439152,
        "precision": 0.14089782288024474,
        "recall": 0.15625
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12921164049093736,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.12921164049093736,
        "precision": 0.12302138895330861,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.04626716408081298,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.04626716408081298,
        "precision": 0.03810930677083414,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.34618989903891395,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.34618989903891395,
        "precision": 0.3316069455717893,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.38173506181318684,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38173506181318684,
        "precision": 0.3660884796626984,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.09549726561614261,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09549726561614261,
        "precision": 0.08175278332214342,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4338573373241342,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4338573373241342,
        "precision": 0.41635784462932895,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001054707412423219,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001054707412423219,
        "precision": 0.0006188481798237895,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.43330531230921854,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.43330531230921854,
        "precision": 0.421609873416514,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.0907722323249667,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0907722323249667,
        "precision": 0.07708235726819136,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.24635106646825394,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.24635106646825394,
        "precision": 0.22986230891504328,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.3730172939401455,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3730172939401455,
        "precision": 0.35664005925184444,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.2895245000225469,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2895245000225469,
        "precision": 0.2720470309233378,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.015976082616707618,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.015976082616707618,
        "precision": 0.014940347519742724,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02830952920117322,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.02830952920117322,
        "precision": 0.027103559261845146,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.051890686879628736,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.051890686879628736,
        "precision": 0.046023577204403546,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.029830216711773237,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.029830216711773237,
        "precision": 0.027912778881083684,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003938802083333333,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.003938802083333333,
        "precision": 0.0032660590277777775,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.0231593119524154,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0231593119524154,
        "precision": 0.022117996618567063,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.1307616860290767,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.1307616860290767,
        "precision": 0.12243671719990079,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.02100034892429194,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.02100034892429194,
        "precision": 0.019975160506342272,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.028010405544749973,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.028010405544749973,
        "precision": 0.02696568850190477,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02964609558679467,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.02964609558679467,
        "precision": 0.027183314732142857,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4439221314709596,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4439221314709596,
        "precision": 0.4259556361607143,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.0953984637914074,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0953984637914074,
        "precision": 0.08143454106764197,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.45386207217261904,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.45386207217261904,
        "precision": 0.4335216703869047,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000621964271931596,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000621964271931596,
        "precision": 0.0003579954117063492,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.5171685112847222,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5171685112847222,
        "precision": 0.5030289290787338,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.09850953083374958,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09850953083374958,
        "precision": 0.08258192274305556,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.2830101376488095,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.2830101376488095,
        "precision": 0.26307896205357145,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.576171875,
        "f1": 0.5259944590999278,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5259944590999278,
        "precision": 0.5068863509537338,
        "recall": 0.576171875
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.349136475503663,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.349136475503663,
        "precision": 0.32508567821067824,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.11335685904448331,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11335685904448331,
        "precision": 0.09781357780655911,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.48939460875496027,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.48939460875496027,
        "precision": 0.46997186569940474,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004744264793200416,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004744264793200416,
        "precision": 0.0002644751238019074,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.630248964721621,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.630248964721621,
        "precision": 0.6155532781021062,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.15964555543771997,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.15964555543771997,
        "precision": 0.1352185497528156,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.39971682135025055,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.39971682135025055,
        "precision": 0.37477213541666665,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.6728515625,
        "f1": 0.6207278073489011,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6207278073489011,
        "precision": 0.6001069568452382,
        "recall": 0.6728515625
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.4667417151817851,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4667417151817851,
        "precision": 0.4428075396825397,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07626045105771581,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.07626045105771581,
        "precision": 0.07463750055694172,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002747158611673414,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.002747158611673414,
        "precision": 0.0024425177552448627,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.08451388104201576,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.08451388104201576,
        "precision": 0.08384261214339339,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09497965603443478,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.09497965603443478,
        "precision": 0.09001518669763806,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.07177304150097184,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.07177304150097184,
        "precision": 0.07026308320096122,
        "recall": 0.078125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07510610433641823,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.07510610433641823,
        "precision": 0.07305027494990168,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05949671183425081,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.05949671183425081,
        "precision": 0.05689908846036776,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.6779857127997226e-05,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 5.6779857127997226e-05,
        "precision": 2.877012365616383e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.6119849795386905,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6119849795386905,
        "precision": 0.5985912045739348,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.11322837047934703,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.11322837047934703,
        "precision": 0.09537633924789012,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.3142027839781746,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.3142027839781746,
        "precision": 0.29459751674107143,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.560546875,
        "f1": 0.5141935050626456,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5141935050626456,
        "precision": 0.496812996031746,
        "recall": 0.560546875
      },
      {
        "accuracy": 0.453125,
        "f1": 0.39132397550366305,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.39132397550366305,
        "precision": 0.36859538844402123,
        "recall": 0.453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009788602941176471,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0009788602941176471,
        "precision": 0.000977712750294464,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011359133751122517,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0011359133751122517,
        "precision": 0.0010589725741002678,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785001240079365,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0009785001240079365,
        "precision": 0.00097753227408143,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006530889675052411,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0006530889675052411,
        "precision": 0.0004893059745540399,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.786271141649049e-05,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 9.786271141649049e-05,
        "precision": 5.088636784239172e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.12375860178594553,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.12375860178594553,
        "precision": 0.10188986902854091,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.4216238839285714,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.4216238839285714,
        "precision": 0.3955729166666666,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.720703125,
        "f1": 0.6644391741071429,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6644391741071429,
        "precision": 0.6400173611111112,
        "recall": 0.720703125
      },
      {
        "accuracy": 0.603515625,
        "f1": 0.523686290922619,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.523686290922619,
        "precision": 0.492454117063492,
        "recall": 0.603515625
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.052189391825622294,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.052189391825622294,
        "precision": 0.04973946521982342,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.08894170133415533,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.08894170133415533,
        "precision": 0.08444652606906786,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.08004478748119406,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.08004478748119406,
        "precision": 0.07517082846366518,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.4033203125,
        "f1": 0.3617227385244963,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3617227385244963,
        "precision": 0.3474155970982143,
        "recall": 0.4033203125
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.2742714045936702,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2742714045936702,
        "precision": 0.25618049028822054,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.5947265625,
        "f1": 0.528515625,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.528515625,
        "precision": 0.5010765438988095,
        "recall": 0.5947265625
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}