{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 12.170466184616089,
  "kg_co2_emissions": 0.00039866380526540877,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030556528557901604,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0030556528557901604,
        "precision": 0.0024561117217471173,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.04008691950824926,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.04008691950824926,
        "precision": 0.03817991489154018,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.028902029868517948,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.028902029868517948,
        "precision": 0.02685509391352364,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.09846972721224219,
        "f1": 0.07284068233137836,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.07284068233137836,
        "precision": 0.06544045020513137,
        "recall": 0.09846972721224219
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011831937063774276,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0011831937063774276,
        "precision": 0.0009643294621762495,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09394029923350786,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.09394029923350786,
        "precision": 0.08492749886672567,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.07363585066687633,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.07363585066687633,
        "precision": 0.06549828182337158,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.04462774979585369,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.04462774979585369,
        "precision": 0.04211650739585287,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.010805872991501734,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.010805872991501734,
        "precision": 0.009856251772419437,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06906190379150656,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.06906190379150656,
        "precision": 0.06229660009925566,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.010477504825861952,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.010477504825861952,
        "precision": 0.009862861437193362,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.0658682634730539,
        "f1": 0.04601384715901446,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.04601384715901446,
        "precision": 0.04107927096088704,
        "recall": 0.0658682634730539
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.009694413398174041,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.009694413398174041,
        "precision": 0.008819742462389665,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.03063024340180493,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.03063024340180493,
        "precision": 0.02875816130357772,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.10911510312707917,
        "f1": 0.08380824588012452,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.08380824588012452,
        "precision": 0.07741967174619593,
        "recall": 0.10911510312707917
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01792448954313404,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.01792448954313404,
        "precision": 0.01613941650839632,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008555656421215625,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0008555656421215625,
        "precision": 0.0007666464774592644,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.013092459407502085,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.013092459407502085,
        "precision": 0.012474283147796953,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.06852960745176315,
        "f1": 0.050517552159241,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.050517552159241,
        "precision": 0.0458957583957584,
        "recall": 0.06852960745176315
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01545301339913956,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.01545301339913956,
        "precision": 0.014935986153551023,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.021734824111888165,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.021734824111888165,
        "precision": 0.02023758557818098,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.02598638990889654,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.02598638990889654,
        "precision": 0.02415188862294651,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.025750296436095825,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.025750296436095825,
        "precision": 0.023061484263642202,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01897870780863669,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.01897870780863669,
        "precision": 0.017666297177459732,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.010674073000060411,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.010674073000060411,
        "precision": 0.0090000014401212,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001527388822578165,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001527388822578165,
        "precision": 0.0011816618894597767,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.01304716574177652,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.01304716574177652,
        "precision": 0.01229280477440504,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.009389872614434589,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.009389872614434589,
        "precision": 0.008254804554952738,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.02016127874702292,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02016127874702292,
        "precision": 0.018918004295800293,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.018200107721065804,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.018200107721065804,
        "precision": 0.016511709625482082,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.011494585690008526,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.011494585690008526,
        "precision": 0.010425075721939788,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.029073459057608404,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.029073459057608404,
        "precision": 0.0266937168214401,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006992993699580526,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.006992993699580526,
        "precision": 0.005817729620124828,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.019838148455681732,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.019838148455681732,
        "precision": 0.018645024882108237,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.020096147206505866,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.020096147206505866,
        "precision": 0.017656907434479483,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008298218378058697,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.008298218378058697,
        "precision": 0.006855510177127811,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.028202641007951435,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.028202641007951435,
        "precision": 0.026463401896745738,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00047053166998892263,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00047053166998892263,
        "precision": 0.00029338769789437997,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02772989618965781,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.02772989618965781,
        "precision": 0.02540802266185047,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.011129904692778943,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.011129904692778943,
        "precision": 0.009764181753536378,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.017612922303541067,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.017612922303541067,
        "precision": 0.016114577720579202,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.027671142439835143,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.027671142439835143,
        "precision": 0.02560242791772486,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01872361618108528,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01872361618108528,
        "precision": 0.01733537689823723,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7584941228653803,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7584941228653803,
        "precision": 0.7403700535437063,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.1483699268130406,
        "f1": 0.0756799464218265,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0756799464218265,
        "precision": 0.05889709019727178,
        "recall": 0.1483699268130406
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0005142991463657566,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0005142991463657566,
        "precision": 0.0002760006312511131,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.12668403693638774,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.12668403693638774,
        "precision": 0.10659154298717277,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.2315369261477046,
        "f1": 0.14365282459094833,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14365282459094833,
        "precision": 0.11984852331002137,
        "recall": 0.2315369261477046
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8204036371701042,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8204036371701042,
        "precision": 0.8046351740962521,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.12974051896207583,
        "f1": 0.08001078895543835,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08001078895543835,
        "precision": 0.06827948859367766,
        "recall": 0.12974051896207583
      },
      {
        "accuracy": 0.38323353293413176,
        "f1": 0.28548209017270887,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.28548209017270887,
        "precision": 0.252735886252187,
        "recall": 0.38323353293413176
      },
      {
        "accuracy": 0.2907518296739854,
        "f1": 0.222896237716597,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.222896237716597,
        "precision": 0.20161970305105084,
        "recall": 0.2907518296739854
      },
      {
        "accuracy": 0.13506320691949433,
        "f1": 0.07192828595513422,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.07192828595513422,
        "precision": 0.05862867537051139,
        "recall": 0.13506320691949433
      },
      {
        "accuracy": 0.2967398536260812,
        "f1": 0.2320699297745206,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2320699297745206,
        "precision": 0.21025718998195098,
        "recall": 0.2967398536260812
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.3993563618314117,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3993563618314117,
        "precision": 0.36761156157363745,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1052493842106567,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1052493842106567,
        "precision": 0.08861124364372255,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.4091816367265469,
        "f1": 0.329559333251948,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.329559333251948,
        "precision": 0.30103391101395094,
        "recall": 0.4091816367265469
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0004077353676401195,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004077353676401195,
        "precision": 0.0002166996177270599,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.447771124417831,
        "f1": 0.3792202966538506,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3792202966538506,
        "precision": 0.3540944565894666,
        "recall": 0.447771124417831
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.194033145829553,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.194033145829553,
        "precision": 0.16687974736876934,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.202468185496247,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.202468185496247,
        "precision": 0.17865499160409337,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.7538256819693946,
        "f1": 0.6975667712194658,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6975667712194658,
        "precision": 0.673342204479929,
        "recall": 0.7538256819693946
      },
      {
        "accuracy": 0.656686626746507,
        "f1": 0.5829373000031682,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5829373000031682,
        "precision": 0.5522241231822069,
        "recall": 0.656686626746507
      },
      {
        "accuracy": 0.14504324683965403,
        "f1": 0.0773439996963538,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.0773439996963538,
        "precision": 0.06141802525438051,
        "recall": 0.14504324683965403
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0005199586772884288,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0005199586772884288,
        "precision": 0.0002790626240979794,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.12132414705739286,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.12132414705739286,
        "precision": 0.10037766716908435,
        "recall": 0.2055888223552894
      },
      {
        "accuracy": 0.22022621423819028,
        "f1": 0.13437095966449025,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.13437095966449025,
        "precision": 0.11130161541544659,
        "recall": 0.22022621423819028
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8113439787092482,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8113439787092482,
        "precision": 0.7949830497734689,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.1543579507651364,
        "f1": 0.10052254208431019,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.10052254208431019,
        "precision": 0.08704844731497308,
        "recall": 0.1543579507651364
      },
      {
        "accuracy": 0.37059214903526283,
        "f1": 0.2731995512434634,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.2731995512434634,
        "precision": 0.24130001180899385,
        "recall": 0.37059214903526283
      },
      {
        "accuracy": 0.25615435795076513,
        "f1": 0.1929575340752985,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1929575340752985,
        "precision": 0.1725548329839747,
        "recall": 0.25615435795076513
      },
      {
        "accuracy": 0.1383898868928809,
        "f1": 0.07288816673870095,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.07288816673870095,
        "precision": 0.05897585506018577,
        "recall": 0.1383898868928809
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.19550160805062763,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.19550160805062763,
        "precision": 0.17629427904798214,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.4763805721889554,
        "f1": 0.3836902913749221,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3836902913749221,
        "precision": 0.34886180020910557,
        "recall": 0.4763805721889554
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.10073672415655116,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.10073672415655116,
        "precision": 0.08408588906299368,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.34530938123752497,
        "f1": 0.27384067843149673,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.27384067843149673,
        "precision": 0.2495918671538021,
        "recall": 0.34530938123752497
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00036139765504565315,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00036139765504565315,
        "precision": 0.00019442053957623707,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.32641067072204794,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.32641067072204794,
        "precision": 0.30163112927583985,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.2860944777112442,
        "f1": 0.1961272888418597,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.1961272888418597,
        "precision": 0.16914320247653583,
        "recall": 0.2860944777112442
      },
      {
        "accuracy": 0.26147704590818366,
        "f1": 0.19297045639361007,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.19297045639361007,
        "precision": 0.1707862053670437,
        "recall": 0.26147704590818366
      },
      {
        "accuracy": 0.7065868263473054,
        "f1": 0.6448341412413269,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6448341412413269,
        "precision": 0.6175537813262365,
        "recall": 0.7065868263473054
      },
      {
        "accuracy": 0.6227544910179641,
        "f1": 0.5485061622786174,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5485061622786174,
        "precision": 0.5177454614580363,
        "recall": 0.6227544910179641
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0037282402369427296,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0037282402369427296,
        "precision": 0.002754574263994448,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.1616394195735513,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.1616394195735513,
        "precision": 0.14832134672454034,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.12042581503659348,
        "f1": 0.09277550536584193,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.09277550536584193,
        "precision": 0.08427122638405954,
        "recall": 0.12042581503659348
      },
      {
        "accuracy": 0.10778443113772455,
        "f1": 0.08996553688207247,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.08996553688207247,
        "precision": 0.08528170624065201,
        "recall": 0.10778443113772455
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.016604863174263074,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.016604863174263074,
        "precision": 0.015260640335490636,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.10578842315369262,
        "f1": 0.08108843363334381,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.08108843363334381,
        "precision": 0.07345182404697521,
        "recall": 0.10578842315369262
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01680235251915421,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.01680235251915421,
        "precision": 0.0154960150495359,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.05772646441309116,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.05772646441309116,
        "precision": 0.05177623007213825,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.022704708343782166,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.022704708343782166,
        "precision": 0.021618249976385496,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.057088525401336576,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.057088525401336576,
        "precision": 0.053195816344518934,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.11458331671124475,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.11458331671124475,
        "precision": 0.10587284795119127,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.030509591687236395,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.030509591687236395,
        "precision": 0.02849818833847705,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0025379589591263854,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0025379589591263854,
        "precision": 0.002104846879618251,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.028304952157494418,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.028304952157494418,
        "precision": 0.026414087944642946,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.11177644710578842,
        "f1": 0.09024190487107349,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.09024190487107349,
        "precision": 0.08270671259693216,
        "recall": 0.11177644710578842
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.034507970433730856,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.034507970433730856,
        "precision": 0.03294713956810816,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.052075719642391056,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.052075719642391056,
        "precision": 0.0499524576458943,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05836223170627587,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.05836223170627587,
        "precision": 0.05449876867042536,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0001341872932025959,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0001341872932025959,
        "precision": 7.22394272181691e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.721750726957893e-05,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 6.721750726957893e-05,
        "precision": 3.428356669058364e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 2.7212106121771458e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.7212106121771458e-06,
        "precision": 1.3633934317158033e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002870495645685517,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0002870495645685517,
        "precision": 0.00015389292571769725,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001106975834858488,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.001106975834858488,
        "precision": 0.0009136588201499783,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00048289889670414485,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.00048289889670414485,
        "precision": 0.00035272584186556535,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000311700528056138,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.000311700528056138,
        "precision": 0.00017050435221367642,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002370198959371024,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0002370198959371024,
        "precision": 0.00014075529604347554,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00113487355889471,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00113487355889471,
        "precision": 0.0009420304478245624,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018951898544595312,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0018951898544595312,
        "precision": 0.0016797781034499188,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.130032156078536e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 6.130032156078536e-05,
        "precision": 3.170481620790616e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.01300449916711672,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.01300449916711672,
        "precision": 0.011215228143870859,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00040752606209926867,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00040752606209926867,
        "precision": 0.0002613823244131941,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00022153276334728784,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.00022153276334728784,
        "precision": 0.00012161204132101048,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001969108702344414,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0001969108702344414,
        "precision": 0.000104208305509514,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00029952682330553106,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.00029952682330553106,
        "precision": 0.000183183087769537,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 2.7156571211318858e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 2.7156571211318858e-05,
        "precision": 1.3861166555777333e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.19028609447771125,
        "f1": 0.1473679412551668,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.1473679412551668,
        "precision": 0.13376832458735854,
        "recall": 0.19028609447771125
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.16130129388612424,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.16130129388612424,
        "precision": 0.155687701301196,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02173378111501864,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.02173378111501864,
        "precision": 0.019746668648864256,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.14637391882900866,
        "f1": 0.12012396716033077,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.12012396716033077,
        "precision": 0.11243547568023922,
        "recall": 0.14637391882900866
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.029890782362452843,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.029890782362452843,
        "precision": 0.028122819106311057,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.07122698781584907,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.07122698781584907,
        "precision": 0.06276297482161616,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.03614252695337479,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.03614252695337479,
        "precision": 0.03390523735160132,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.09591832642138082,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.09591832642138082,
        "precision": 0.08958076522305561,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.23952095808383234,
        "f1": 0.19825583598038687,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.19825583598038687,
        "precision": 0.18423655334832978,
        "recall": 0.23952095808383234
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04959410746939545,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.04959410746939545,
        "precision": 0.046513498361950324,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000589909616137603,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.000589909616137603,
        "precision": 0.0003616574370899055,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.05544481142283779,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.05544481142283779,
        "precision": 0.05375908763242077,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.14041150503226352,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.14041150503226352,
        "precision": 0.1304054409937945,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.04526959327358529,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.04526959327358529,
        "precision": 0.04295834025812666,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.08691923130139721,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.08691923130139721,
        "precision": 0.08354816500609026,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.09656276376169921,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.09656276376169921,
        "precision": 0.09095493639344872,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.17964071856287425,
        "f1": 0.15377766661134884,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.15377766661134884,
        "precision": 0.1462655586191124,
        "recall": 0.17964071856287425
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01771877490440365,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.01771877490440365,
        "precision": 0.01627391604001851,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.19095143047238855,
        "f1": 0.15678545031931285,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.15678545031931285,
        "precision": 0.14577265034771075,
        "recall": 0.19095143047238855
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022757265889296198,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.022757265889296198,
        "precision": 0.021314326134200937,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.13040585495675316,
        "f1": 0.09941062116710819,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.09941062116710819,
        "precision": 0.08986287424411178,
        "recall": 0.13040585495675316
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.038246533579397266,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.038246533579397266,
        "precision": 0.03603159241881797,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.1156484562883862,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.1156484562883862,
        "precision": 0.10988257660350458,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09363156303687006,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.09363156303687006,
        "precision": 0.08372779974901817,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.04507132748863573,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.04507132748863573,
        "precision": 0.042763511842536024,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0023507251160332096,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0023507251160332096,
        "precision": 0.0019364846241680185,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.0591629858847208,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0591629858847208,
        "precision": 0.05589106502857981,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.15135098139090156,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.15135098139090156,
        "precision": 0.14065341748211302,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.045872948667359845,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.045872948667359845,
        "precision": 0.04222959062635959,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.1383898868928809,
        "f1": 0.12194894299979962,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.12194894299979962,
        "precision": 0.1177823876833945,
        "recall": 0.1383898868928809
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.11311994804851197,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.11311994804851197,
        "precision": 0.1075480434759893,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.1377245508982036,
        "f1": 0.0851084374847194,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.0851084374847194,
        "precision": 0.07228830315483097,
        "recall": 0.1377245508982036
      },
      {
        "accuracy": 0.37658017298735863,
        "f1": 0.2791961961563934,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.2791961961563934,
        "precision": 0.24732904321227678,
        "recall": 0.37658017298735863
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.21312354506618153,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.21312354506618153,
        "precision": 0.19078229082221096,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.07007747874180642,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.07007747874180642,
        "precision": 0.055976904263430785,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.2867598137059215,
        "f1": 0.21416599220990434,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.21416599220990434,
        "precision": 0.19145053948573845,
        "recall": 0.2867598137059215
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.4248891106675538,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.4248891106675538,
        "precision": 0.3891917463773752,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.1059346019966261,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.1059346019966261,
        "precision": 0.08626602608178671,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.40119760479041916,
        "f1": 0.31786956667196187,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.31786956667196187,
        "precision": 0.28969206848448364,
        "recall": 0.40119760479041916
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0010253358325801078,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0010253358325801078,
        "precision": 0.0008570296136803986,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.46706586826347307,
        "f1": 0.39208558869237503,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.39208558869237503,
        "precision": 0.36401557893573855,
        "recall": 0.46706586826347307
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.20116569187838415,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.20116569187838415,
        "precision": 0.17351057403452613,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.3060545575515635,
        "f1": 0.22402506194921362,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.22402506194921362,
        "precision": 0.19781156532360006,
        "recall": 0.3060545575515635
      },
      {
        "accuracy": 0.7751164337990686,
        "f1": 0.7193390995786204,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.7193390995786204,
        "precision": 0.694623451509679,
        "recall": 0.7751164337990686
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6156501811192431,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.6156501811192431,
        "precision": 0.5838933244621868,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.04258445052021833,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.04258445052021833,
        "precision": 0.038181808581010175,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.05946874636337815,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.05946874636337815,
        "precision": 0.05427946876209771,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.019014777273203214,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.019014777273203214,
        "precision": 0.015813433627804883,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.044703112449237845,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.044703112449237845,
        "precision": 0.041878357127697156,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.057348922311927154,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.057348922311927154,
        "precision": 0.05289879179976343,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.04258150365934797,
        "f1": 0.02564247167041578,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.02564247167041578,
        "precision": 0.021472962768942238,
        "recall": 0.04258150365934797
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05993938049826272,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.05993938049826272,
        "precision": 0.055234433459618676,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00033549273718644243,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00033549273718644243,
        "precision": 0.00017999968501428303,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.0671832155187284,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0671832155187284,
        "precision": 0.06326366396226675,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03464081437546272,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.03464081437546272,
        "precision": 0.030646007167963254,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.04278327842794654,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.04278327842794654,
        "precision": 0.038353895162167674,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.06105503746839171,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.06105503746839171,
        "precision": 0.05718340136933608,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.05716669840515173,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.05716669840515173,
        "precision": 0.05240427434372877,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.05870733430376049,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.05870733430376049,
        "precision": 0.054062508282167604,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.08614575580056384,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.08614575580056384,
        "precision": 0.07560958142001938,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.08782435129740519,
        "f1": 0.07083006874215532,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.07083006874215532,
        "precision": 0.06522794681743355,
        "recall": 0.08782435129740519
      },
      {
        "accuracy": 0.2268795741849634,
        "f1": 0.18818432715934222,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.18818432715934222,
        "precision": 0.17535794494817622,
        "recall": 0.2268795741849634
      },
      {
        "accuracy": 0.11709913506320692,
        "f1": 0.08231213692259755,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.08231213692259755,
        "precision": 0.07243813516268606,
        "recall": 0.11709913506320692
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.08614575450352774,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.08614575450352774,
        "precision": 0.07864648807625554,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007675365958799092,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0007675365958799092,
        "precision": 0.0005188121793620474,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.1330671989354624,
        "f1": 0.11264049885350971,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.11264049885350971,
        "precision": 0.10651139326715005,
        "recall": 0.1330671989354624
      },
      {
        "accuracy": 0.21423819028609448,
        "f1": 0.1633253977007646,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.1633253977007646,
        "precision": 0.14591863651244888,
        "recall": 0.21423819028609448
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.0831129675173935,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0831129675173935,
        "precision": 0.07570370387032072,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.24890743604981796,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.24890743604981796,
        "precision": 0.23927792435351783,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.26413838988689287,
        "f1": 0.2257591637402474,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.2257591637402474,
        "precision": 0.21251576713468423,
        "recall": 0.26413838988689287
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.025808546816530848,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.025808546816530848,
        "precision": 0.021214798943551962,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.14038589487691283,
        "f1": 0.11569656779237616,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.11569656779237616,
        "precision": 0.10775274847131135,
        "recall": 0.14038589487691283
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.12121483767603294,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12121483767603294,
        "precision": 0.11078018326022318,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.043955237146466625,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.043955237146466625,
        "precision": 0.03778851010040804,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.21224218230206254,
        "f1": 0.17879901572516343,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.17879901572516343,
        "precision": 0.16743725025582362,
        "recall": 0.21224218230206254
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0004913176529882843,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004913176529882843,
        "precision": 0.00030735580837087923,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.15562102900426253,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15562102900426253,
        "precision": 0.14586382789975602,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.09381237524950099,
        "f1": 0.06898350965217233,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.06898350965217233,
        "precision": 0.06098750809329651,
        "recall": 0.09381237524950099
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.08312688272768112,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.08312688272768112,
        "precision": 0.07554413317886371,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.1996007984031936,
        "f1": 0.1648764676818622,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1648764676818622,
        "precision": 0.1542121839997181,
        "recall": 0.1996007984031936
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.12064338944735677,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.12064338944735677,
        "precision": 0.11025404070950907,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.018049540813330003,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.018049540813330003,
        "precision": 0.01663661164849841,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.058555937082509654,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.058555937082509654,
        "precision": 0.05427264301926481,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.056381123991859954,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.056381123991859954,
        "precision": 0.05179630917069084,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.016056225880408403,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.016056225880408403,
        "precision": 0.014922633666627159,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0019927322206465536,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0019927322206465536,
        "precision": 0.001563328534924991,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.029520145104147376,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.029520145104147376,
        "precision": 0.027533038392941103,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.125275903220015,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.125275903220015,
        "precision": 0.11460467712962721,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.029176903587759293,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.029176903587759293,
        "precision": 0.02703446620361744,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.04055827152720801,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.04055827152720801,
        "precision": 0.03794220709445458,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.0665335994677312,
        "f1": 0.04906898008994469,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.04906898008994469,
        "precision": 0.04520054982639013,
        "recall": 0.0665335994677312
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.16092793008373613,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.16092793008373613,
        "precision": 0.14669397634966494,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.07451763140385895,
        "f1": 0.043421248105996256,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.043421248105996256,
        "precision": 0.03601116069928446,
        "recall": 0.07451763140385895
      },
      {
        "accuracy": 0.18562874251497005,
        "f1": 0.15442230188990536,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15442230188990536,
        "precision": 0.14409316288058804,
        "recall": 0.18562874251497005
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008254435869793391,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008254435869793391,
        "precision": 0.0007510616826336532,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.19161676646706588,
        "f1": 0.16275203321111506,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.16275203321111506,
        "precision": 0.1522756795211885,
        "recall": 0.19161676646706588
      },
      {
        "accuracy": 0.10445775116433799,
        "f1": 0.07014146310553497,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.07014146310553497,
        "precision": 0.05989528878750436,
        "recall": 0.10445775116433799
      },
      {
        "accuracy": 0.11909514304723885,
        "f1": 0.0943223849411474,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.0943223849411474,
        "precision": 0.08619591024780646,
        "recall": 0.11909514304723885
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.23841467174800504,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.23841467174800504,
        "precision": 0.22514991535371828,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.14936662546442986,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14936662546442986,
        "precision": 0.13588563613513713,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.14570858283433133,
        "f1": 0.0955157216076554,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0955157216076554,
        "precision": 0.08059829115218337,
        "recall": 0.14570858283433133
      },
      {
        "accuracy": 0.21490352628077178,
        "f1": 0.17659447819128457,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.17659447819128457,
        "precision": 0.1636378037575642,
        "recall": 0.21490352628077178
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008962636648441509,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008962636648441509,
        "precision": 0.0005092862832203428,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.2721224218230206,
        "f1": 0.2353868218800346,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2353868218800346,
        "precision": 0.22245654438621446,
        "recall": 0.2721224218230206
      },
      {
        "accuracy": 0.26413838988689287,
        "f1": 0.20056351942579487,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.20056351942579487,
        "precision": 0.17789634775662716,
        "recall": 0.26413838988689287
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.18449921945430928,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.18449921945430928,
        "precision": 0.16887740136726037,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.3532232627219482,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3532232627219482,
        "precision": 0.33870007576499517,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.3260146373918829,
        "f1": 0.27705015825029666,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.27705015825029666,
        "precision": 0.2602004144668816,
        "recall": 0.3260146373918829
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03891131923935212,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.03891131923935212,
        "precision": 0.037016700086112,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008704547311543844,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0008704547311543844,
        "precision": 0.0006037308099849683,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.04452794629713518,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.04452794629713518,
        "precision": 0.04282971351689416,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.14171656686626746,
        "f1": 0.116300756357485,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.116300756357485,
        "precision": 0.10804007603741471,
        "recall": 0.14171656686626746
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.0360220345443214,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0360220345443214,
        "precision": 0.03360553045071425,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.08915502328675981,
        "f1": 0.07699871823353299,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.07699871823353299,
        "precision": 0.07418289256134142,
        "recall": 0.08915502328675981
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.09908539648151332,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.09908539648151332,
        "precision": 0.09389185972897005,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 3.995547944147096e-05,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 3.995547944147096e-05,
        "precision": 2.0365106540225524e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.25016633399866933,
        "f1": 0.21697177101432527,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21697177101432527,
        "precision": 0.20523338717870704,
        "recall": 0.25016633399866933
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.08311276448685839,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08311276448685839,
        "precision": 0.07098318994526578,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.11820324275414094,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.11820324275414094,
        "precision": 0.10723291272193468,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.29008649367930806,
        "f1": 0.24905949192376337,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.24905949192376337,
        "precision": 0.2355937943105713,
        "recall": 0.29008649367930806
      },
      {
        "accuracy": 0.2222222222222222,
        "f1": 0.1863965191310501,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.1863965191310501,
        "precision": 0.17423302283581726,
        "recall": 0.2222222222222222
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005110434503616644,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0005110434503616644,
        "precision": 0.00031730326584743826,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007338475618921135,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0007338475618921135,
        "precision": 0.0007007456676069177,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0004186202856868297,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0004186202856868297,
        "precision": 0.00026599499993019645,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 2.6493613695204923e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 2.6493613695204923e-05,
        "precision": 1.3333765926764113e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 7.536414585017607e-05,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 7.536414585017607e-05,
        "precision": 3.911369180830259e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.1497005988023952,
        "f1": 0.10238648761602852,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.10238648761602852,
        "precision": 0.0886715044399675,
        "recall": 0.1497005988023952
      },
      {
        "accuracy": 0.20691949434464404,
        "f1": 0.1605746659638875,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.1605746659638875,
        "precision": 0.14434268109743245,
        "recall": 0.20691949434464404
      },
      {
        "accuracy": 0.36127744510978044,
        "f1": 0.3107689863178885,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3107689863178885,
        "precision": 0.2918316805542355,
        "recall": 0.36127744510978044
      },
      {
        "accuracy": 0.302727877578177,
        "f1": 0.2514262480330345,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2514262480330345,
        "precision": 0.23357278487019006,
        "recall": 0.302727877578177
      },
      {
        "accuracy": 0.08715901530272788,
        "f1": 0.06788127716121324,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.06788127716121324,
        "precision": 0.06252799013269206,
        "recall": 0.08715901530272788
      },
      {
        "accuracy": 0.16367265469061876,
        "f1": 0.14085391702761318,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.14085391702761318,
        "precision": 0.13564602351106977,
        "recall": 0.16367265469061876
      },
      {
        "accuracy": 0.18496340652029275,
        "f1": 0.15221018185078566,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.15221018185078566,
        "precision": 0.14318183575800544,
        "recall": 0.18496340652029275
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.18421641168799027,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18421641168799027,
        "precision": 0.1739988922742463,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.14278962278925839,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14278962278925839,
        "precision": 0.13493466283806657,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5533393530399519,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5533393530399519,
        "precision": 0.5265532427209073,
        "recall": 0.6167664670658682
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}