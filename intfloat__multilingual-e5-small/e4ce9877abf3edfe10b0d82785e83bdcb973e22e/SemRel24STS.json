{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 3.6125118732452393,
  "kg_co2_emissions": 0.0005684385049317885,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8013282437700434,
        "cosine_spearman": 0.7884117363892273,
        "euclidean_pearson": 0.7856339800314045,
        "euclidean_spearman": 0.7884117363892273,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7884117363892273,
        "manhattan_pearson": 0.7800289900839482,
        "manhattan_spearman": 0.7840446964380581,
        "pearson": 0.8013282437700434,
        "spearman": 0.7884117363892273
      },
      {
        "cosine_pearson": 0.7794926113368082,
        "cosine_spearman": 0.7634117143292312,
        "euclidean_pearson": 0.7767776716620979,
        "euclidean_spearman": 0.7634117143292312,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7634117143292312,
        "manhattan_pearson": 0.7779166212300856,
        "manhattan_spearman": 0.7676502030361565,
        "pearson": 0.7794926113368082,
        "spearman": 0.7634117143292312
      },
      {
        "cosine_pearson": 0.48847764748848527,
        "cosine_spearman": 0.5076148701802652,
        "euclidean_pearson": 0.5056324275704144,
        "euclidean_spearman": 0.5076148701802652,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.5076148701802652,
        "manhattan_pearson": 0.5006309235777685,
        "manhattan_spearman": 0.5051426030415299,
        "pearson": 0.48847764748848527,
        "spearman": 0.5076148701802652
      },
      {
        "cosine_pearson": 0.4653510429999577,
        "cosine_spearman": 0.45540682612863975,
        "euclidean_pearson": 0.4788689967695913,
        "euclidean_spearman": 0.45540682612863975,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.45540682612863975,
        "manhattan_pearson": 0.484934979341193,
        "manhattan_spearman": 0.4583833583756795,
        "pearson": 0.4653510429999577,
        "spearman": 0.45540682612863975
      },
      {
        "cosine_pearson": 0.4528766493770542,
        "cosine_spearman": 0.45405360263386674,
        "euclidean_pearson": 0.458116931694195,
        "euclidean_spearman": 0.45405360263386674,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.45405360263386674,
        "manhattan_pearson": 0.4574671287752063,
        "manhattan_spearman": 0.45362110459378463,
        "pearson": 0.4528766493770542,
        "spearman": 0.45405360263386674
      },
      {
        "cosine_pearson": 0.8071625938140662,
        "cosine_spearman": 0.7969894041494415,
        "euclidean_pearson": 0.8086775016053073,
        "euclidean_spearman": 0.7969894672253616,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7969894041494415,
        "manhattan_pearson": 0.8058579389893752,
        "manhattan_spearman": 0.7932849082668055,
        "pearson": 0.8071625938140662,
        "spearman": 0.7969894041494415
      },
      {
        "cosine_pearson": 0.39455419677804854,
        "cosine_spearman": 0.3535922427982074,
        "euclidean_pearson": 0.4040479817283141,
        "euclidean_spearman": 0.3535995681296493,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3535922427982074,
        "manhattan_pearson": 0.3972165460207427,
        "manhattan_spearman": 0.3471575137243313,
        "pearson": 0.39455419677804854,
        "spearman": 0.3535922427982074
      },
      {
        "cosine_pearson": 0.730935506964203,
        "cosine_spearman": 0.7251194626450058,
        "euclidean_pearson": 0.7112974168985716,
        "euclidean_spearman": 0.7251194626450058,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7251194626450058,
        "manhattan_pearson": 0.7053298256720479,
        "manhattan_spearman": 0.7126407252168284,
        "pearson": 0.730935506964203,
        "spearman": 0.7251194626450058
      },
      {
        "cosine_pearson": 0.4215106264608689,
        "cosine_spearman": 0.44441415403303786,
        "euclidean_pearson": 0.4586750783835862,
        "euclidean_spearman": 0.44441415403303786,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.44441415403303786,
        "manhattan_pearson": 0.4590321521828412,
        "manhattan_spearman": 0.44431512939112966,
        "pearson": 0.4215106264608689,
        "spearman": 0.44441415403303786
      },
      {
        "cosine_pearson": 0.4262349732772647,
        "cosine_spearman": 0.4204836066537142,
        "euclidean_pearson": 0.43237511773968446,
        "euclidean_spearman": 0.4204836066537142,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4204836066537142,
        "manhattan_pearson": 0.4359486917623216,
        "manhattan_spearman": 0.4269292570164815,
        "pearson": 0.4262349732772647,
        "spearman": 0.4204836066537142
      },
      {
        "cosine_pearson": 0.798171565145523,
        "cosine_spearman": 0.7754204835005339,
        "euclidean_pearson": 0.7924297174299969,
        "euclidean_spearman": 0.7754204835005339,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7754204835005339,
        "manhattan_pearson": 0.78941688605989,
        "manhattan_spearman": 0.7705547131622464,
        "pearson": 0.798171565145523,
        "spearman": 0.7754204835005339
      },
      {
        "cosine_pearson": 0.7940537605813077,
        "cosine_spearman": 0.7584170419193923,
        "euclidean_pearson": 0.7717309811575469,
        "euclidean_spearman": 0.7584170419193923,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7584170419193923,
        "manhattan_pearson": 0.7700171470478462,
        "manhattan_spearman": 0.7568732679605634,
        "pearson": 0.7940537605813077,
        "spearman": 0.7584170419193923
      }
    ]
  },
  "task_name": "SemRel24STS"
}