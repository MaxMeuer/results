{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 12.794548034667969,
  "kg_co2_emissions": 0.0004183449292477651,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.1115231685590967,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.1115231685590967,
        "precision": 0.09976281725609157,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.7975509298862592,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.7975509298862592,
        "precision": 0.7819472166777558,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7822186315200287,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.7822186315200287,
        "precision": 0.7647427367487247,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7262364160567754,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7262364160567754,
        "precision": 0.7065202927478377,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006725477347277226,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.006725477347277226,
        "precision": 0.005222703600811269,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8223552894211577,
        "f1": 0.7841998542597345,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.7841998542597345,
        "precision": 0.7673061284837731,
        "recall": 0.8223552894211577
      },
      {
        "accuracy": 0.825016633399867,
        "f1": 0.7860501219782657,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.7860501219782657,
        "precision": 0.7686626746506987,
        "recall": 0.825016633399867
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7544278248810361,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.7544278248810361,
        "precision": 0.7403796497359371,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.39495986382213927,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.39495986382213927,
        "precision": 0.3724624824425224,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7421157684630739,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7421157684630739,
        "precision": 0.72507207806609,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.48835662009314706,
        "f1": 0.43362481386433477,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.43362481386433477,
        "precision": 0.4125209897664987,
        "recall": 0.48835662009314706
      },
      {
        "accuracy": 0.7584830339321357,
        "f1": 0.7162246934702025,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7162246934702025,
        "precision": 0.6978820137502771,
        "recall": 0.7584830339321357
      },
      {
        "accuracy": 0.5269461077844312,
        "f1": 0.4687560572790114,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4687560572790114,
        "precision": 0.44640797769540286,
        "recall": 0.5269461077844312
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7779330228432025,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.7779330228432025,
        "precision": 0.7614105123087159,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.8137059214903526,
        "f1": 0.7729430028831227,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7729430028831227,
        "precision": 0.7546462630294966,
        "recall": 0.8137059214903526
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.512199986750885,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.512199986750885,
        "precision": 0.49008174127934606,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.005916083439110476,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.005916083439110476,
        "precision": 0.004289350190092565,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.738692456357127,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.738692456357127,
        "precision": 0.7211640211640211,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.8290086493679308,
        "f1": 0.7928048664575611,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.7928048664575611,
        "precision": 0.7762253271235307,
        "recall": 0.8290086493679308
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.5963422361625955,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.5963422361625955,
        "precision": 0.5721287583563033,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7877356398314482,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.7877356398314482,
        "precision": 0.7716677755599911,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7666698349333081,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.7666698349333081,
        "precision": 0.7538256819693946,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.1703260146373919,
        "f1": 0.13087064109469498,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.13087064109469498,
        "precision": 0.12194732854599397,
        "recall": 0.1703260146373919
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.10052081946632502,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10052081946632502,
        "precision": 0.09324057449778524,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.10645375914836992,
        "f1": 0.08059338314463257,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08059338314463257,
        "precision": 0.07546416786930904,
        "recall": 0.10645375914836992
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.011126919210751545,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.011126919210751545,
        "precision": 0.009641915009990802,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.09154371211220053,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09154371211220053,
        "precision": 0.08528876491796807,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.09220339481327215,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09220339481327215,
        "precision": 0.08450146311650286,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.08848968729208251,
        "f1": 0.06887908125508624,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06887908125508624,
        "precision": 0.06450351408955157,
        "recall": 0.08848968729208251
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.09526940179523291,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09526940179523291,
        "precision": 0.08630368959543942,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.1324018629407851,
        "f1": 0.10307653968159043,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10307653968159043,
        "precision": 0.09574841504109903,
        "recall": 0.1324018629407851
      },
      {
        "accuracy": 0.16101131071190952,
        "f1": 0.1304356322320394,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1304356322320394,
        "precision": 0.1221872804989181,
        "recall": 0.16101131071190952
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.09928216804627917,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.09928216804627917,
        "precision": 0.09218713056141234,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.14238190286094476,
        "f1": 0.11468872298537776,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.11468872298537776,
        "precision": 0.10763658172244067,
        "recall": 0.14238190286094476
      },
      {
        "accuracy": 0.14105123087159016,
        "f1": 0.1023735818386556,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1023735818386556,
        "precision": 0.09334832462956874,
        "recall": 0.14105123087159016
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.10002597793756896,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.10002597793756896,
        "precision": 0.09314940440158676,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.1355262018454632,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1355262018454632,
        "precision": 0.1269295667018983,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007566258398532144,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007566258398532144,
        "precision": 0.006178700022719161,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.09862680580414049,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09862680580414049,
        "precision": 0.0898834792994904,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.09139857829462371,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09139857829462371,
        "precision": 0.08373690618578222,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.12375249500998003,
        "f1": 0.0884193823970516,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.0884193823970516,
        "precision": 0.08062491213259902,
        "recall": 0.12375249500998003
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.09887876549754131,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09887876549754131,
        "precision": 0.09040361440195918,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.0964763264391569,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0964763264391569,
        "precision": 0.0909285016847523,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9255045464626303,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9255045464626303,
        "precision": 0.9191727655799512,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8409846972721224,
        "f1": 0.8086509520641257,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8086509520641257,
        "precision": 0.7943620695117702,
        "recall": 0.8409846972721224
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.009100900572340993,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009100900572340993,
        "precision": 0.006927179052927557,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8671989354624086,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8671989354624086,
        "precision": 0.8568751386116655,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9062763362164561,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9062763362164561,
        "precision": 0.8975604346861832,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9186626746506986,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9186626746506986,
        "precision": 0.9116829832398694,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5333839443619883,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5333839443619883,
        "precision": 0.5082425096896155,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9040807274340209,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9040807274340209,
        "precision": 0.8951763140385895,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5513470561374754,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5513470561374754,
        "precision": 0.5276906504451414,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.864105123087159,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.864105123087159,
        "precision": 0.8524680797135886,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5695887833612384,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5695887833612384,
        "precision": 0.5473410562232917,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8943446440452428,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8943446440452428,
        "precision": 0.8855289421157684,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8900421379463295,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8900421379463295,
        "precision": 0.8804502106897316,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6695519494920693,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6695519494920693,
        "precision": 0.6479622765051907,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.007191519623525942,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007191519623525942,
        "precision": 0.005329852230585218,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8848873681209011,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8848873681209011,
        "precision": 0.8749944555333777,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9172987358616101,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9172987358616101,
        "precision": 0.9097028165890441,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.7850964737192282,
        "f1": 0.7408959858061654,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7408959858061654,
        "precision": 0.7215637101864646,
        "recall": 0.7850964737192282
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.91055666444888,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.91055666444888,
        "precision": 0.9029163894433355,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.9010645375914839,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9010645375914839,
        "precision": 0.8936127744510978,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.8010217659918258,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8010217659918258,
        "precision": 0.7879415771631341,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.008699476173005255,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008699476173005255,
        "precision": 0.006634237300974003,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8652821341444096,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8652821341444096,
        "precision": 0.8551119982257706,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9106453759148369,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9106453759148369,
        "precision": 0.9033599467731205,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9205810601020182,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9205810601020182,
        "precision": 0.9137059214903526,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.6041250831669993,
        "f1": 0.5459604600323164,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.5459604600323164,
        "precision": 0.5232254254210342,
        "recall": 0.6041250831669993
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8968507429585274,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8968507429585274,
        "precision": 0.8887114659569749,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.49782711189896817,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.49782711189896817,
        "precision": 0.477413715138266,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8810157462852073,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8810157462852073,
        "precision": 0.8720743697789605,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.5321886652409817,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5321886652409817,
        "precision": 0.5088864598844639,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9127966289642937,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9127966289642937,
        "precision": 0.9055444666223109,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8743845642049234,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8743845642049234,
        "precision": 0.8641273009536482,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.6706586826347305,
        "f1": 0.6143633368184266,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6143633368184266,
        "precision": 0.5921764529548961,
        "recall": 0.6706586826347305
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.006416419239748223,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006416419239748223,
        "precision": 0.004960064064601274,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8953109653708455,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8953109653708455,
        "precision": 0.8859724994455535,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9153914393435353,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9153914393435353,
        "precision": 0.9082390774007542,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.801729873586161,
        "f1": 0.762228899953451,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.762228899953451,
        "precision": 0.745331559104014,
        "recall": 0.801729873586161
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9090929252605898,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9090929252605898,
        "precision": 0.9019405633178088,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9015635395874918,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9015635395874918,
        "precision": 0.8936412888508698,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.0058342777205052645,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0058342777205052645,
        "precision": 0.004424433697991844,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.7946456293761682,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7946456293761682,
        "precision": 0.7780217343091596,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7881902860944777,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.7881902860944777,
        "precision": 0.7726610271520451,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.7930805056553559,
        "f1": 0.7532884447555106,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.7532884447555106,
        "precision": 0.7375410794572471,
        "recall": 0.7930805056553559
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.38702705219671285,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.38702705219671285,
        "precision": 0.36445125621772323,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.780439121756487,
        "f1": 0.7393552001336432,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.7393552001336432,
        "precision": 0.7220067800906124,
        "recall": 0.780439121756487
      },
      {
        "accuracy": 0.4550898203592814,
        "f1": 0.398066349263954,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.398066349263954,
        "precision": 0.37777938591311844,
        "recall": 0.4550898203592814
      },
      {
        "accuracy": 0.7684630738522954,
        "f1": 0.7222560650704363,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7222560650704363,
        "precision": 0.7024791686468331,
        "recall": 0.7684630738522954
      },
      {
        "accuracy": 0.4976713240186294,
        "f1": 0.4376709426294466,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.4376709426294466,
        "precision": 0.4148805157288191,
        "recall": 0.4976713240186294
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7628108861641796,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.7628108861641796,
        "precision": 0.7447992903082724,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7863542755758325,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.7863542755758325,
        "precision": 0.7702040363717011,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4677459895024765,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.4677459895024765,
        "precision": 0.442130047167032,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0023414169970647487,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0023414169970647487,
        "precision": 0.0014137127104327716,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7260510724582581,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7260510724582581,
        "precision": 0.7069960607884761,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.8403193612774451,
        "f1": 0.8082427737118355,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8082427737118355,
        "precision": 0.7940225609387286,
        "recall": 0.8403193612774451
      },
      {
        "accuracy": 0.6713240186294078,
        "f1": 0.6152499714375962,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.6152499714375962,
        "precision": 0.5914068688020783,
        "recall": 0.6713240186294078
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7835662009314704,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.7835662009314704,
        "precision": 0.7689509869150586,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7657035136077052,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7657035136077052,
        "precision": 0.7513560181224851,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004596514258723244,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.004596514258723244,
        "precision": 0.004072036691781771,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0030840282585103116,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0030840282585103116,
        "precision": 0.002608799575107922,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006579433725142309,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0006579433725142309,
        "precision": 0.00038391231006001464,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.0068098563033806596,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0068098563033806596,
        "precision": 0.005338980357731675,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0047226416487322585,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0047226416487322585,
        "precision": 0.0039486345881694605,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0032919336269890517,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0032919336269890517,
        "precision": 0.002751336157802015,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.003371697790568856,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003371697790568856,
        "precision": 0.002319086119946282,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007372096182471117,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007372096182471117,
        "precision": 0.006223079800719299,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004666734324627502,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004666734324627502,
        "precision": 0.0039030453453658006,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0020784962265148724,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0020784962265148724,
        "precision": 0.0018292291520155908,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003230906931360162,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.003230906931360162,
        "precision": 0.002777164992429636,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.027112448547676558,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.027112448547676558,
        "precision": 0.024179625726531914,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004883524978064126,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.004883524978064126,
        "precision": 0.004185872823645999,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.0064123416293539025,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0064123416293539025,
        "precision": 0.005207804921445901,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006203696969533716,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.006203696969533716,
        "precision": 0.0052652669790307915,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0058912418327968395,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0058912418327968395,
        "precision": 0.00504427981090575,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0038421921104127023,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0038421921104127023,
        "precision": 0.0034445544193619144,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8575663487839137,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8575663487839137,
        "precision": 0.8452705699711688,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.8566787060799036,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8566787060799036,
        "precision": 0.8474669708202641,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.44278691294659367,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.44278691294659367,
        "precision": 0.42153154009441435,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.8429807052561543,
        "f1": 0.8101479580521497,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8101479580521497,
        "precision": 0.7963184741627857,
        "recall": 0.8429807052561543
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.4329773981470588,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.4329773981470588,
        "precision": 0.41377483128980136,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8178436777239172,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8178436777239172,
        "precision": 0.8046795298292305,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.5482368596141052,
        "f1": 0.49255162415683484,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.49255162415683484,
        "precision": 0.4728107277508475,
        "recall": 0.5482368596141052
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8580521496689162,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8580521496689162,
        "precision": 0.8467509425593257,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8538827107689382,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8538827107689382,
        "precision": 0.8432024839210469,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.6061210911510313,
        "f1": 0.5478307934395759,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.5478307934395759,
        "precision": 0.5250994957581784,
        "recall": 0.6061210911510313
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006034166737927971,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.006034166737927971,
        "precision": 0.004447013463761171,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.8216376770268986,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8216376770268986,
        "precision": 0.8094651965909451,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8852073630516745,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8852073630516745,
        "precision": 0.8760479041916166,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.7584830339321357,
        "f1": 0.7146579043784632,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7146579043784632,
        "precision": 0.6960642207648196,
        "recall": 0.7584830339321357
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8596267781896526,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8596267781896526,
        "precision": 0.8491350632069194,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.8482843836137249,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8482843836137249,
        "precision": 0.8387447327567087,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8775464943129613,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8775464943129613,
        "precision": 0.8671213129296962,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.48156337637375557,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.48156337637375557,
        "precision": 0.4578269387151622,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8643823464182746,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8643823464182746,
        "precision": 0.8528165890441339,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.47076536238212885,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.47076536238212885,
        "precision": 0.45075193528287344,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8683743623863385,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8683743623863385,
        "precision": 0.8579174983366599,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5203904840631387,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.5203904840631387,
        "precision": 0.496739796390495,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.8994899090707474,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.8994899090707474,
        "precision": 0.8901086715457974,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8803852612235846,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8803852612235846,
        "precision": 0.8705921490352628,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.6009386469965312,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6009386469965312,
        "precision": 0.5798414375730332,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.008638591629390137,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.008638591629390137,
        "precision": 0.006743787422336319,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8690396983810158,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.8690396983810158,
        "precision": 0.8593812375249502,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9135063206919495,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9135063206919495,
        "precision": 0.9053005100909293,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.7797737857618097,
        "f1": 0.7336438234641827,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7336438234641827,
        "precision": 0.7136776951148209,
        "recall": 0.7797737857618097
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9049013084941229,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9049013084941229,
        "precision": 0.8967287646928366,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8933466400532267,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.8933466400532267,
        "precision": 0.8845309381237524,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.42180402579604176,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.42180402579604176,
        "precision": 0.3948847928887849,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8863753973534413,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8863753973534413,
        "precision": 0.876763140385895,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.49367930805056554,
        "f1": 0.41810631336579446,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.41810631336579446,
        "precision": 0.39191654029803813,
        "recall": 0.49367930805056554
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.8360431761629366,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8360431761629366,
        "precision": 0.8228432024839211,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.5375914836992681,
        "f1": 0.468414952162936,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.468414952162936,
        "precision": 0.44463507370519434,
        "recall": 0.5375914836992681
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9069416722111332,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9069416722111332,
        "precision": 0.8986915058771348,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9036498431708013,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9036498431708013,
        "precision": 0.8950876025726324,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.6813040585495675,
        "f1": 0.6166609061818643,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6166609061818643,
        "precision": 0.5906774234119544,
        "recall": 0.6813040585495675
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0028267096370489003,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0028267096370489003,
        "precision": 0.00215841100357692,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8822133510756266,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8822133510756266,
        "precision": 0.8718562874251498,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9253493013972055,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9253493013972055,
        "precision": 0.9189398979818141,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.7704590818363274,
        "f1": 0.7223563455100381,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7223563455100381,
        "precision": 0.7022782717393495,
        "recall": 0.7704590818363274
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9017869023857048,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9017869023857048,
        "precision": 0.8924595253936572,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.911998801819161,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.911998801819161,
        "precision": 0.9046129962297627,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.49280443442120087,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.49280443442120087,
        "precision": 0.47203086823551776,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.3002893683532406,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3002893683532406,
        "precision": 0.28456502099216674,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.49567531603459747,
        "f1": 0.4325660035240873,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.4325660035240873,
        "precision": 0.4089677787282578,
        "recall": 0.49567531603459747
      },
      {
        "accuracy": 0.3200266134397871,
        "f1": 0.2784842680052261,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2784842680052261,
        "precision": 0.2640042379317027,
        "recall": 0.3200266134397871
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.4854527412411644,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.4854527412411644,
        "precision": 0.46007903163591785,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.48902195608782434,
        "f1": 0.4260046980290703,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.4260046980290703,
        "precision": 0.4026071788047836,
        "recall": 0.48902195608782434
      },
      {
        "accuracy": 0.3772455089820359,
        "f1": 0.3237049710103602,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3237049710103602,
        "precision": 0.3042116824551954,
        "recall": 0.3772455089820359
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.009055706089190574,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.009055706089190574,
        "precision": 0.007036484420442489,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.47296839702029325,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.47296839702029325,
        "precision": 0.44895703099295914,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.488640146723979,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.488640146723979,
        "precision": 0.4649619373142914,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.3616112172000395,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.3616112172000395,
        "precision": 0.33896096695497896,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.5349301397205589,
        "f1": 0.47050660583594717,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.47050660583594717,
        "precision": 0.44713975740344053,
        "recall": 0.5349301397205589
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.47071330261616356,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.47071330261616356,
        "precision": 0.4503904157496972,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.4951398789722143,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4951398789722143,
        "precision": 0.4711909514304724,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8436143585844184,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8436143585844184,
        "precision": 0.8296074517631403,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5178192252044548,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5178192252044548,
        "precision": 0.4936191349864005,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8827677977378577,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8827677977378577,
        "precision": 0.8723663783544022,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.83301333840256,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.83301333840256,
        "precision": 0.8180490870111629,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.630890119712475,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.630890119712475,
        "precision": 0.6074272090739157,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007329295517498491,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.007329295517498491,
        "precision": 0.0054896642949950865,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8732091372809936,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8732091372809936,
        "precision": 0.8621867376358393,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8870259481037924,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.8870259481037924,
        "precision": 0.8765247283211356,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.7003881126635618,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7003881126635618,
        "precision": 0.6791087377913726,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8856509203814594,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.8856509203814594,
        "precision": 0.8756043468618319,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.89736083388778,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.89736083388778,
        "precision": 0.888999778221335,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.4750499001996008,
        "f1": 0.4157279906150586,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4157279906150586,
        "precision": 0.3949368458849497,
        "recall": 0.4750499001996008
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.3667229649431912,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3667229649431912,
        "precision": 0.34689268556534025,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.46602103394482125,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.46602103394482125,
        "precision": 0.4451848135231368,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.4338332701772488,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4338332701772488,
        "precision": 0.41176456979850196,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.5016633399866933,
        "f1": 0.4394719323926128,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4394719323926128,
        "precision": 0.41624120685996935,
        "recall": 0.5016633399866933
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007448116095904015,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007448116095904015,
        "precision": 0.006003389393453026,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.5229540918163673,
        "f1": 0.4612357283357388,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4612357283357388,
        "precision": 0.4396328508104955,
        "recall": 0.5229540918163673
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.46113021049989217,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.46113021049989217,
        "precision": 0.4372452366805765,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.41650033266799735,
        "f1": 0.34963081569867993,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.34963081569867993,
        "precision": 0.32679385247669734,
        "recall": 0.41650033266799735
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4715067103885816,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4715067103885816,
        "precision": 0.44901295293011867,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.496693160708551,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.496693160708551,
        "precision": 0.4775204807688228,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.5615435795076513,
        "f1": 0.5012152942791664,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5012152942791664,
        "precision": 0.4790686685367911,
        "recall": 0.5615435795076513
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8569749390108672,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8569749390108672,
        "precision": 0.8449434464404525,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8068101891455184,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8068101891455184,
        "precision": 0.7926063217480382,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.5888223552894212,
        "f1": 0.5273286427478043,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5273286427478043,
        "precision": 0.5030584333977547,
        "recall": 0.5888223552894212
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007685844792717566,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.007685844792717566,
        "precision": 0.006274876184267926,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8232202262142383,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8232202262142383,
        "precision": 0.8104568640496785,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8717343091594589,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8717343091594589,
        "precision": 0.861283781643063,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.7465069860279441,
        "f1": 0.7012815638564142,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7012815638564142,
        "precision": 0.6815500866399069,
        "recall": 0.7465069860279441
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8524728321135506,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8524728321135506,
        "precision": 0.8422044799290308,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.8629407850964738,
        "f1": 0.8351424135855273,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8351424135855273,
        "precision": 0.8231220099483573,
        "recall": 0.8629407850964738
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.5287465097410424,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5287465097410424,
        "precision": 0.504608939888381,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.5642049234863606,
        "f1": 0.5006331252838239,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5006331252838239,
        "precision": 0.47731349280782376,
        "recall": 0.5642049234863606
      },
      {
        "accuracy": 0.479707252162342,
        "f1": 0.41932106483004683,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.41932106483004683,
        "precision": 0.39626169276867884,
        "recall": 0.479707252162342
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.005608400151497864,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005608400151497864,
        "precision": 0.004266514079754462,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.5848303393213573,
        "f1": 0.5248744546381157,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5248744546381157,
        "precision": 0.5027802610636941,
        "recall": 0.5848303393213573
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5300523759448016,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5300523759448016,
        "precision": 0.5075869710600249,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.4823685961410512,
        "f1": 0.4155439297155864,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.4155439297155864,
        "precision": 0.39142074012333494,
        "recall": 0.4823685961410512
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5825739961967507,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5825739961967507,
        "precision": 0.5601349803445611,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.5788423153692615,
        "f1": 0.5284141315762284,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5284141315762284,
        "precision": 0.5108938042071774,
        "recall": 0.5788423153692615
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8666223109336881,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8666223109336881,
        "precision": 0.8550343756930583,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6231890715922652,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6231890715922652,
        "precision": 0.6013999079338987,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.0049975931261679344,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0049975931261679344,
        "precision": 0.003402673621248938,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.887447327567088,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.887447327567088,
        "precision": 0.8778997560434685,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9049456642271013,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9049456642271013,
        "precision": 0.8966733200266134,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.812375249500998,
        "f1": 0.7745217745217744,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7745217745217744,
        "precision": 0.757972943002883,
        "recall": 0.812375249500998
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9080727434020847,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9080727434020847,
        "precision": 0.9009980039920158,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8862940785096474,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8862940785096474,
        "precision": 0.876979374584165,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5476063745524824,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5476063745524824,
        "precision": 0.5233624769552914,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.004833272548005564,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004833272548005564,
        "precision": 0.0034057251342526408,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.830793967620315,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.830793967620315,
        "precision": 0.818059119855527,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.9000221778664891,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9000221778664891,
        "precision": 0.8923153692614771,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.7691284098469727,
        "f1": 0.7252114817983082,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7252114817983082,
        "precision": 0.7063764246398977,
        "recall": 0.7691284098469727
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8793302284320248,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.8793302284320248,
        "precision": 0.87008205810601,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8655260906757911,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8655260906757911,
        "precision": 0.8560212907518296,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.005394281242644911,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005394281242644911,
        "precision": 0.0036735837604167884,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.6912840984697272,
        "f1": 0.6350805511484154,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6350805511484154,
        "precision": 0.61257194605498,
        "recall": 0.6912840984697272
      },
      {
        "accuracy": 0.6739853626081171,
        "f1": 0.6158744184258373,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6158744184258373,
        "precision": 0.5930457987344215,
        "recall": 0.6739853626081171
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4286923507482389,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4286923507482389,
        "precision": 0.40120132510352075,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.6753160345974717,
        "f1": 0.613155353923817,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.613155353923817,
        "precision": 0.5890654791353395,
        "recall": 0.6753160345974717
      },
      {
        "accuracy": 0.6633399866932801,
        "f1": 0.6096938398335604,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6096938398335604,
        "precision": 0.5900300169262246,
        "recall": 0.6633399866932801
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002953150078161753,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.002953150078161753,
        "precision": 0.002813755225726684,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006301097274383019,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.006301097274383019,
        "precision": 0.004860046488619361,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.00380815625721832,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.00380815625721832,
        "precision": 0.00288561562564183,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007466577573125339,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.007466577573125339,
        "precision": 0.0069103919696143976,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004100018067905854,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004100018067905854,
        "precision": 0.0036533237053337792,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8764914615214017,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8764914615214017,
        "precision": 0.8659902417387448,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7164076608687386,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7164076608687386,
        "precision": 0.6960475873649526,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8648480816145487,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8648480816145487,
        "precision": 0.8529718341095587,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8710578842315368,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8710578842315368,
        "precision": 0.8613455628425688,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.7970725216234198,
        "f1": 0.7570198707923258,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7570198707923258,
        "precision": 0.7403985679434782,
        "recall": 0.7970725216234198
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9039603333016507,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9039603333016507,
        "precision": 0.8962852073630516,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8881348414282547,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8881348414282547,
        "precision": 0.8793191394987803,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7586077004240676,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7586077004240676,
        "precision": 0.7430702087887716,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.719661734731595,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.719661734731595,
        "precision": 0.7043310204986853,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.896806387225549,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.896806387225549,
        "precision": 0.8891328454202706,
        "recall": 0.914836992681304
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}