{
  "dataset_revision": "155048684cea7a6d6af1ddbfeb9a04820311ce93",
  "evaluation_time": 30.30282711982727,
  "kg_co2_emissions": 0.002253938216385397,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.77890625,
        "ap": 0.7989371788636485,
        "ap_weighted": 0.7989371788636485,
        "f1": 0.7731352811511867,
        "f1_weighted": 0.7708838401950698,
        "hf_subset": "default",
        "languages": [
          "ron-Latn"
        ],
        "main_score": 0.77890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.861328125,
            "ap": 0.8538030020703934,
            "ap_weighted": 0.8538030020703934,
            "f1": 0.860560030686613,
            "f1_weighted": 0.8618334502061757
          },
          {
            "accuracy": 0.833984375,
            "ap": 0.8540630545696539,
            "ap_weighted": 0.8540630545696539,
            "f1": 0.833974241591894,
            "f1_weighted": 0.833814640414225
          },
          {
            "accuracy": 0.59033203125,
            "ap": 0.6786625955801673,
            "ap_weighted": 0.6786625955801673,
            "f1": 0.5544758880744711,
            "f1_weighted": 0.5389238259742417
          },
          {
            "accuracy": 0.87158203125,
            "ap": 0.8645224756271894,
            "ap_weighted": 0.8645224756271894,
            "f1": 0.8708228858262854,
            "f1_weighted": 0.8720413867611648
          },
          {
            "accuracy": 0.78466796875,
            "ap": 0.8136822026328807,
            "ap_weighted": 0.8136822026328807,
            "f1": 0.7840785779091075,
            "f1_weighted": 0.7826904798539216
          },
          {
            "accuracy": 0.66650390625,
            "ap": 0.7353337453776333,
            "ap_weighted": 0.7353337453776333,
            "f1": 0.6523667686863076,
            "f1_weighted": 0.6437407186474444
          },
          {
            "accuracy": 0.6962890625,
            "ap": 0.7253959150035638,
            "ap_weighted": 0.7253959150035638,
            "f1": 0.6942805276441004,
            "f1_weighted": 0.6912314265375539
          },
          {
            "accuracy": 0.794921875,
            "ap": 0.8080952631627484,
            "ap_weighted": 0.8080952631627484,
            "f1": 0.7949122912428579,
            "f1_weighted": 0.7947397836142989
          },
          {
            "accuracy": 0.85302734375,
            "ap": 0.846400056427062,
            "ap_weighted": 0.846400056427062,
            "f1": 0.8523273755438776,
            "f1_weighted": 0.8535783825505645
          },
          {
            "accuracy": 0.83642578125,
            "ap": 0.8094134781851924,
            "ap_weighted": 0.8094134781851924,
            "f1": 0.8335542243063526,
            "f1_weighted": 0.8362443073911078
          }
        ]
      }
    ]
  },
  "task_name": "RomanianSentimentClassification"
}