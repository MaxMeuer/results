{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 12.819427967071533,
  "kg_co2_emissions": 0.00038071287865172767,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.525,
        "f1": 0.4059597980269748,
        "f1_weighted": 0.5782982149316257,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.525,
        "scores_per_experiment": [
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.42353479853479853,
            "f1_weighted": 0.6402507748661594
          },
          {
            "accuracy": 0.6538461538461539,
            "f1": 0.49012539184952975,
            "f1_weighted": 0.6890040993489268
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.42454311454311455,
            "f1_weighted": 0.5905910305910307
          },
          {
            "accuracy": 0.5,
            "f1": 0.4040220785503804,
            "f1_weighted": 0.600901698688346
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.4056156843342198,
            "f1_weighted": 0.5985446985446985
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.39458991143627264,
            "f1_weighted": 0.5412939486389621
          },
          {
            "accuracy": 0.38461538461538464,
            "f1": 0.32468117029257315,
            "f1_weighted": 0.41183276588377854
          },
          {
            "accuracy": 0.5192307692307693,
            "f1": 0.3797603765511339,
            "f1_weighted": 0.5799800862381093
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.4056897264448053,
            "f1_weighted": 0.5637299157537724
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.4070357277329205,
            "f1_weighted": 0.5668531307624727
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5095238095238095,
        "f1": 0.38677046932627474,
        "f1_weighted": 0.5701856823341778,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5095238095238095,
        "scores_per_experiment": [
          {
            "accuracy": 0.580952380952381,
            "f1": 0.4171385991058122,
            "f1_weighted": 0.6306777375629834
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.4095168631112148,
            "f1_weighted": 0.6083961566888397
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.4353808353808354,
            "f1_weighted": 0.6445583245583246
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.40436417129780977,
            "f1_weighted": 0.6174149659863944
          },
          {
            "accuracy": 0.5047619047619047,
            "f1": 0.36653211653211654,
            "f1_weighted": 0.5569417283702998
          },
          {
            "accuracy": 0.4380952380952381,
            "f1": 0.33266393442622955,
            "f1_weighted": 0.4815347384855582
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.3853433698794524,
            "f1_weighted": 0.5250214938972916
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3684633027522936,
            "f1_weighted": 0.5580559196155526
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.31989389920424405,
            "f1_weighted": 0.4728836680560819
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.42840760157273916,
            "f1_weighted": 0.6063720901204518
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}