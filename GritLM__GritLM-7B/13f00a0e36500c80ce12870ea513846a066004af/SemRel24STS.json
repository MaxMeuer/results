{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 50.42055153846741,
  "kg_co2_emissions": 0.0044312911014040566,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8173526133645369,
        "cosine_spearman": 0.8055417888189433,
        "euclidean_pearson": 0.7944120911880461,
        "euclidean_spearman": 0.8055417888189433,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8055417888189433,
        "manhattan_pearson": 0.7894586363117663,
        "manhattan_spearman": 0.8027988941630586,
        "pearson": 0.8173526133645369,
        "spearman": 0.8055417888189433
      },
      {
        "cosine_pearson": 0.7452200375342335,
        "cosine_spearman": 0.7341684229448878,
        "euclidean_pearson": 0.7332845166745416,
        "euclidean_spearman": 0.7341684229448878,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7341684229448878,
        "manhattan_pearson": 0.7331336185871105,
        "manhattan_spearman": 0.7317917003054905,
        "pearson": 0.7452200375342335,
        "spearman": 0.7341684229448878
      },
      {
        "cosine_pearson": 0.6044716432499363,
        "cosine_spearman": 0.6074410936420381,
        "euclidean_pearson": 0.5950014466754606,
        "euclidean_spearman": 0.6074410936420381,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6074410936420381,
        "manhattan_pearson": 0.5826021637736147,
        "manhattan_spearman": 0.5936330407301862,
        "pearson": 0.6044716432499363,
        "spearman": 0.6074410936420381
      },
      {
        "cosine_pearson": 0.39431281592421835,
        "cosine_spearman": 0.3434480367358384,
        "euclidean_pearson": 0.4012548053988328,
        "euclidean_spearman": 0.3434480367358384,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.3434480367358384,
        "manhattan_pearson": 0.3921821244393185,
        "manhattan_spearman": 0.3328582648448191,
        "pearson": 0.39431281592421835,
        "spearman": 0.3434480367358384
      },
      {
        "cosine_pearson": 0.4179663683213838,
        "cosine_spearman": 0.4019889139753316,
        "euclidean_pearson": 0.415049031298759,
        "euclidean_spearman": 0.4019889139753316,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.4019889139753316,
        "manhattan_pearson": 0.41779135764958064,
        "manhattan_spearman": 0.407901558186846,
        "pearson": 0.4179663683213838,
        "spearman": 0.4019889139753316
      },
      {
        "cosine_pearson": 0.8078041779152929,
        "cosine_spearman": 0.7941546785897405,
        "euclidean_pearson": 0.8022610012144802,
        "euclidean_spearman": 0.794154888746938,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7941546785897405,
        "manhattan_pearson": 0.7958924680818124,
        "manhattan_spearman": 0.7821111642054743,
        "pearson": 0.8078041779152929,
        "spearman": 0.7941546785897405
      },
      {
        "cosine_pearson": 0.546961233425916,
        "cosine_spearman": 0.5278334229272471,
        "euclidean_pearson": 0.5448445557993925,
        "euclidean_spearman": 0.5278334229272471,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5278334229272471,
        "manhattan_pearson": 0.5502135996491826,
        "manhattan_spearman": 0.535170114247044,
        "pearson": 0.546961233425916,
        "spearman": 0.5278334229272471
      },
      {
        "cosine_pearson": 0.7535902030908129,
        "cosine_spearman": 0.7627220191054013,
        "euclidean_pearson": 0.7301246881825891,
        "euclidean_spearman": 0.7627220191054013,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7627220191054013,
        "manhattan_pearson": 0.7242948699449997,
        "manhattan_spearman": 0.7555140956649063,
        "pearson": 0.7535902030908129,
        "spearman": 0.7627220191054013
      },
      {
        "cosine_pearson": 0.5417149683256354,
        "cosine_spearman": 0.539427704587249,
        "euclidean_pearson": 0.5522959084924308,
        "euclidean_spearman": 0.539427704587249,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.539427704587249,
        "manhattan_pearson": 0.5508698746570958,
        "manhattan_spearman": 0.536004827517615,
        "pearson": 0.5417149683256354,
        "spearman": 0.539427704587249
      },
      {
        "cosine_pearson": 0.49435558519233125,
        "cosine_spearman": 0.47647268248682384,
        "euclidean_pearson": 0.4944661630483482,
        "euclidean_spearman": 0.47647268248682384,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.47647268248682384,
        "manhattan_pearson": 0.5007403382985519,
        "manhattan_spearman": 0.48456692660776496,
        "pearson": 0.49435558519233125,
        "spearman": 0.47647268248682384
      },
      {
        "cosine_pearson": 0.8020283967027622,
        "cosine_spearman": 0.7696118610065451,
        "euclidean_pearson": 0.7918817013591533,
        "euclidean_spearman": 0.7696118610065451,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7696118610065451,
        "manhattan_pearson": 0.7911296821798767,
        "manhattan_spearman": 0.7692439740215686,
        "pearson": 0.8020283967027622,
        "spearman": 0.7696118610065451
      },
      {
        "cosine_pearson": 0.807452384755674,
        "cosine_spearman": 0.7872287342440499,
        "euclidean_pearson": 0.7859852586491558,
        "euclidean_spearman": 0.7872287342440499,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7872287342440499,
        "manhattan_pearson": 0.7859336382141817,
        "manhattan_spearman": 0.7870899114188458,
        "pearson": 0.807452384755674,
        "spearman": 0.7872287342440499
      }
    ]
  },
  "task_name": "SemRel24STS"
}