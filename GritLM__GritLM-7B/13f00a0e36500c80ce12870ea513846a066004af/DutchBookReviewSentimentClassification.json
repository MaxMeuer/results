{
  "dataset_revision": "3f756ab4572e071eb53e887ab629f19fa747d39e",
  "evaluation_time": 47.10078692436218,
  "kg_co2_emissions": 0.0038006618593155205,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.8326888489208633,
        "ap": 0.7764811660985276,
        "ap_weighted": 0.7764811660985276,
        "f1": 0.8323696918061282,
        "f1_weighted": 0.8323696918061282,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ],
        "main_score": 0.8326888489208633,
        "scores_per_experiment": [
          {
            "accuracy": 0.8259892086330936,
            "ap": 0.7660208363387755,
            "ap_weighted": 0.7660208363387755,
            "f1": 0.8259461013870512,
            "f1_weighted": 0.8259461013870512
          },
          {
            "accuracy": 0.8268884892086331,
            "ap": 0.7933065023391123,
            "ap_weighted": 0.7933065023391123,
            "f1": 0.8255194689942692,
            "f1_weighted": 0.8255194689942693
          },
          {
            "accuracy": 0.8349820143884892,
            "ap": 0.7864431524370589,
            "ap_weighted": 0.7864431524370589,
            "f1": 0.8348494913304927,
            "f1_weighted": 0.8348494913304927
          },
          {
            "accuracy": 0.8489208633093526,
            "ap": 0.789973481965281,
            "ap_weighted": 0.789973481965281,
            "f1": 0.8488108225346459,
            "f1_weighted": 0.8488108225346458
          },
          {
            "accuracy": 0.8655575539568345,
            "ap": 0.8141661736923458,
            "ap_weighted": 0.8141661736923458,
            "f1": 0.8655477408677842,
            "f1_weighted": 0.8655477408677842
          },
          {
            "accuracy": 0.8035071942446043,
            "ap": 0.7453003350744063,
            "ap_weighted": 0.7453003350744063,
            "f1": 0.80349571270027,
            "f1_weighted": 0.80349571270027
          },
          {
            "accuracy": 0.8282374100719424,
            "ap": 0.7705189312138212,
            "ap_weighted": 0.7705189312138212,
            "f1": 0.828230603439561,
            "f1_weighted": 0.828230603439561
          },
          {
            "accuracy": 0.8196942446043165,
            "ap": 0.7508409605382147,
            "ap_weighted": 0.7508409605382147,
            "f1": 0.8190074414392803,
            "f1_weighted": 0.8190074414392803
          },
          {
            "accuracy": 0.8439748201438849,
            "ap": 0.7753419809321436,
            "ap_weighted": 0.7753419809321436,
            "f1": 0.8431528447204464,
            "f1_weighted": 0.8431528447204464
          },
          {
            "accuracy": 0.829136690647482,
            "ap": 0.7728993064541172,
            "ap_weighted": 0.7728993064541172,
            "f1": 0.829136690647482,
            "f1_weighted": 0.829136690647482
          }
        ]
      }
    ]
  },
  "task_name": "DutchBookReviewSentimentClassification"
}