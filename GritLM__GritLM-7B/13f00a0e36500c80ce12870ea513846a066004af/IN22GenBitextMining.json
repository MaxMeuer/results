{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 422.68011593818665,
  "kg_co2_emissions": 0.03453321792816337,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.5537109375,
        "f1": 0.5005006820436508,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.5005006820436508,
        "precision": 0.47987157428075394,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166666,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.9607747395833333,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.93251953125,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.93251953125,
        "precision": 0.9248860677083333,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.84658203125,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.84658203125,
        "precision": 0.8319498697916667,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.00530123866052715,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.00530123866052715,
        "precision": 0.0037667947714976908,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9326171875,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9326171875,
        "precision": 0.9251302083333334,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.7822265625,
        "f1": 0.7349989149305556,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.7349989149305556,
        "precision": 0.7153169177827381,
        "recall": 0.7822265625
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9541015625,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9541015625,
        "precision": 0.9490885416666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.70703125,
        "f1": 0.6510130602904041,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.6510130602904041,
        "precision": 0.6286237444196429,
        "recall": 0.70703125
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7894903273809524,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7894903273809524,
        "precision": 0.7715657552083334,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.7802951388888888,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.7802951388888888,
        "precision": 0.7645914713541666,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8899739583333333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.8899739583333333,
        "precision": 0.87744140625,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8429547991071429,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.8429547991071429,
        "precision": 0.8286946614583334,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.95263671875,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.95263671875,
        "precision": 0.9471028645833334,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7894856770833334,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7894856770833334,
        "precision": 0.7708658854166667,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.89111328125,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.89111328125,
        "precision": 0.8802083333333333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0037783267267036125,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0037783267267036125,
        "precision": 0.0027472205129483087,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9228515625,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9228515625,
        "precision": 0.9148763020833333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9402669270833334,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9402669270833334,
        "precision": 0.9337565104166667,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9640299479166666,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9640299479166666,
        "precision": 0.9597981770833334,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9441731770833333,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9441731770833333,
        "precision": 0.93798828125,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8865559895833333,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8865559895833333,
        "precision": 0.87451171875,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5579840307148078,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5579840307148078,
        "precision": 0.5393637294860869,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.48601005185991825,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.48601005185991825,
        "precision": 0.4690984163177831,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.4106578515183754,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4106578515183754,
        "precision": 0.39280533079117064,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005667904590813597,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005667904590813597,
        "precision": 0.004676193670334295,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.48836859472438,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.48836859472438,
        "precision": 0.4703534895551498,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4132115586619263,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4132115586619263,
        "precision": 0.39295220788269203,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5192976160270177,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5192976160270177,
        "precision": 0.5001670547525902,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.46741318035263346,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.46741318035263346,
        "precision": 0.4507923454469507,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.4624780752917339,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4624780752917339,
        "precision": 0.44300512792902347,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5859740194701133,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5859740194701133,
        "precision": 0.5717579675099207,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5208550210268561,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5208550210268561,
        "precision": 0.5010306908146906,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5519970172827904,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5519970172827904,
        "precision": 0.5339748692445728,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5224586383461463,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5224586383461463,
        "precision": 0.5040998610413534,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.416924442830333,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.416924442830333,
        "precision": 0.39809190343714707,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.6181640625,
        "f1": 0.5725929497126647,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5725929497126647,
        "precision": 0.5569584746037382,
        "recall": 0.6181640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0038585816226323366,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0038585816226323366,
        "precision": 0.002898156227612602,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5620038840995473,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5620038840995473,
        "precision": 0.543178429372277,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.5927734375,
        "f1": 0.5361013309397256,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5361013309397256,
        "precision": 0.5166610154360038,
        "recall": 0.5927734375
      },
      {
        "accuracy": 0.6083984375,
        "f1": 0.5511026372354497,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.5511026372354497,
        "precision": 0.5301415035845314,
        "recall": 0.6083984375
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.5147239622739394,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5147239622739394,
        "precision": 0.49587997587265165,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.4573593492538805,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4573593492538805,
        "precision": 0.439541406348189,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8935546875,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8935546875,
        "precision": 0.8828125,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003051609248225152,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003051609248225152,
        "precision": 0.0023104703342162226,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8986002604166667,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8986002604166667,
        "precision": 0.8873697916666666,
        "recall": 0.921875
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7769391741071429,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7769391741071429,
        "precision": 0.75791015625,
        "recall": 0.8212890625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.7998883928571429,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7998883928571429,
        "precision": 0.78125,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8637369791666667,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8637369791666667,
        "precision": 0.85078125,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9110351562500001,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9110351562500001,
        "precision": 0.9024251302083334,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9690755208333333,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9690755208333333,
        "precision": 0.96533203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9194986979166666,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9194986979166666,
        "precision": 0.9110514322916667,
        "recall": 0.9375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7760904947916667,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7760904947916667,
        "precision": 0.7570568266369048,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002168753896105507,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002168753896105507,
        "precision": 0.0013458596662514414,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9372395833333333,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9372395833333333,
        "precision": 0.9302571614583333,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8767903645833333,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8767903645833333,
        "precision": 0.86376953125,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028730364119114605,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0028730364119114605,
        "precision": 0.001841321812667413,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8669270833333333,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8669270833333333,
        "precision": 0.8534342447916667,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6927594866071429,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6927594866071429,
        "precision": 0.669677734375,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9283854166666667,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9283854166666667,
        "precision": 0.9200846354166666,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8657877604166666,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8657877604166666,
        "precision": 0.8524576822916667,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.902734375,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.902734375,
        "precision": 0.8929850260416667,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9514973958333333,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9514973958333333,
        "precision": 0.94580078125,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8943359375,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8943359375,
        "precision": 0.88427734375,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7463076636904762,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.7463076636904762,
        "precision": 0.72548828125,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96484375,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.96484375,
        "precision": 0.96044921875,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005031093580898268,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.005031093580898268,
        "precision": 0.003974877119408369,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9742838541666667,
        "precision": 0.97119140625,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9007161458333333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9007161458333333,
        "precision": 0.8896484375,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0028079816520448888,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028079816520448888,
        "precision": 0.001685794150772599,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7567382812499999,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7567382812499999,
        "precision": 0.738671875,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5320591517857143,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.5320591517857143,
        "precision": 0.5099950749120671,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9030273437499999,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9030273437499999,
        "precision": 0.8935058593749999,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5577962239583333,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5577962239583333,
        "precision": 0.5359956287202381,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6400910612824675,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.6400910612824675,
        "precision": 0.6182942708333332,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.703125,
        "f1": 0.6575272817460318,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.6575272817460318,
        "precision": 0.6388989997632575,
        "recall": 0.703125
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7467944653003247,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7467944653003247,
        "precision": 0.728915550595238,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6734569466991343,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.6734569466991343,
        "precision": 0.6546223958333333,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8489908854166666,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8489908854166666,
        "precision": 0.834912109375,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6506401909722221,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.6506401909722221,
        "precision": 0.6317158400410353,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7334007626488095,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.7334007626488095,
        "precision": 0.7151622953869048,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004950699799332612,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.004950699799332612,
        "precision": 0.0033322638172344297,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8015159970238095,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.8015159970238095,
        "precision": 0.784423828125,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.869921875,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.869921875,
        "precision": 0.857421875,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8556640625,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.8556640625,
        "precision": 0.8422688802083333,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8293503534226191,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8293503534226191,
        "precision": 0.8149181547619047,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7159877232142857,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7159877232142857,
        "precision": 0.6952962239583333,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0021484375,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0021484375,
        "precision": 0.0020616319444444445,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002189214316769653,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.002189214316769653,
        "precision": 0.0018273946357074816,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001808549355251655,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.001808549355251655,
        "precision": 0.001490635016025641,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009793407716927453,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0009793407716927453,
        "precision": 0.0009779536146723646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032768254215994573,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0032768254215994573,
        "precision": 0.0029405863972020887,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956452299829642,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.001956452299829642,
        "precision": 0.00195479148890785,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014841774049363335,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0014841774049363335,
        "precision": 0.0012668783785364116,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010968451593905107,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0010968451593905107,
        "precision": 0.0010380048741415369,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004951203564062068,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004951203564062068,
        "precision": 0.004917894806523299,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003098068678253824,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.003098068678253824,
        "precision": 0.0026546698559891365,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002862621265312097,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.002862621265312097,
        "precision": 0.002588099021154203,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005887910695162814,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.005887910695162814,
        "precision": 0.0046572463203825385,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011796448182270713,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0011796448182270713,
        "precision": 0.0010871144473076078,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002616684402968784,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002616684402968784,
        "precision": 0.0024476882711438417,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013710859530938124,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0013710859530938124,
        "precision": 0.00122265625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012539985665251873,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0012539985665251873,
        "precision": 0.0011297165506448069,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026163736979166663,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0026163736979166663,
        "precision": 0.002447548152515723,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7071289062499999,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.7071289062499999,
        "precision": 0.6864420572916666,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8791341145833333,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8791341145833333,
        "precision": 0.866943359375,
        "recall": 0.90625
      },
      {
        "accuracy": 0.677734375,
        "f1": 0.6241009424603174,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6241009424603174,
        "precision": 0.6029378255208333,
        "recall": 0.677734375
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7211100260416666,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.7211100260416666,
        "precision": 0.7022251674107143,
        "recall": 0.765625
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7123597864808802,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.7123597864808802,
        "precision": 0.6949788411458333,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8039713541666667,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8039713541666667,
        "precision": 0.7870117187500001,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7462100074404762,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.7462100074404762,
        "precision": 0.7290852864583333,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8888346354166666,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8888346354166666,
        "precision": 0.8771158854166667,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7840169270833333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.7840169270833333,
        "precision": 0.7685872395833333,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8182152157738096,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.8182152157738096,
        "precision": 0.80322265625,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004759850051526292,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.004759850051526292,
        "precision": 0.00346661873859927,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.86650390625,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.86650390625,
        "precision": 0.8536783854166666,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8564778645833333,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8564778645833333,
        "precision": 0.8432454427083333,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8880208333333333,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.8880208333333333,
        "precision": 0.8758138020833333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8566080729166666,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8566080729166666,
        "precision": 0.8437011718749999,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8285667782738094,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8285667782738094,
        "precision": 0.812744140625,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5838077341495311,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5838077341495311,
        "precision": 0.5612410583314765,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.437746001114189,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.437746001114189,
        "precision": 0.4179149192821068,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.6983948722718254,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6983948722718254,
        "precision": 0.6791596912202381,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5714190323565322,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.5714190323565322,
        "precision": 0.5536093463827839,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7611629201961233,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.7611629201961233,
        "precision": 0.7444944351438492,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.589992769243114,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.589992769243114,
        "precision": 0.5697381882440475,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7201397343975469,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.7201397343975469,
        "precision": 0.700322033110119,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6489591788419913,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.6489591788419913,
        "precision": 0.625927734375,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.6107937635281385,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6107937635281385,
        "precision": 0.5912462022569445,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005869838169642857,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.005869838169642857,
        "precision": 0.0045755405618686865,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6661165638130252,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.6661165638130252,
        "precision": 0.6463102178312139,
        "recall": 0.71875
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.7500124007936508,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.7500124007936508,
        "precision": 0.7320851159474207,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.678889269367785,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.678889269367785,
        "precision": 0.6588553292410715,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6630805121527777,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.6630805121527777,
        "precision": 0.6426440042162698,
        "recall": 0.71875
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7576529102408008,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.7576529102408008,
        "precision": 0.7388602120535714,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7768903459821428,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7768903459821428,
        "precision": 0.7573172433035715,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7887772817460317,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7887772817460317,
        "precision": 0.7712181454613096,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.870166015625,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.870166015625,
        "precision": 0.858114769345238,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9482421875,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9482421875,
        "precision": 0.9420572916666667,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8979166666666667,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8979166666666667,
        "precision": 0.88671875,
        "recall": 0.921875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7478060169380252,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7478060169380252,
        "precision": 0.7307832263764881,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9601236979166667,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9601236979166667,
        "precision": 0.95556640625,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002428594374251543,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.002428594374251543,
        "precision": 0.001810515873015873,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666667,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9820963541666667,
        "precision": 0.9801432291666666,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9056640625,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9056640625,
        "precision": 0.895263671875,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.6416015625,
        "f1": 0.5818713042371553,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5818713042371553,
        "precision": 0.5590448288690476,
        "recall": 0.6416015625
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7548131284947691,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7548131284947691,
        "precision": 0.7409435453869048,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.7177734375,
        "f1": 0.6673351088208465,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6673351088208465,
        "precision": 0.6473395826179029,
        "recall": 0.7177734375
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6920832910579005,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6920832910579005,
        "precision": 0.6751049223400297,
        "recall": 0.734375
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7731506124084249,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7731506124084249,
        "precision": 0.7556338355654761,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.5109630766369048,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5109630766369048,
        "precision": 0.48594063542794014,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7731631324404762,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7731631324404762,
        "precision": 0.7567778087797619,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006186903916396104,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006186903916396104,
        "precision": 0.004717146531005226,
        "recall": 0.015625
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7977408008658009,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7977408008658009,
        "precision": 0.7820963541666666,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7348399105235043,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7348399105235043,
        "precision": 0.7165717230902777,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7501547280844156,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7501547280844156,
        "precision": 0.7320452008928571,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.78125,
        "f1": 0.736084829883658,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.736084829883658,
        "precision": 0.7187829748376622,
        "recall": 0.78125
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6062336751789876,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6062336751789876,
        "precision": 0.5826059492807539,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7612498449900793,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.7612498449900793,
        "precision": 0.746283965058379,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7424967447916666,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.7424967447916666,
        "precision": 0.7229910714285714,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7035311259920635,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.7035311259920635,
        "precision": 0.68388671875,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8372612847222222,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8372612847222222,
        "precision": 0.8235595703125,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6390848572000916,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6390848572000916,
        "precision": 0.6154552641369048,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8390516493055555,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.8390516493055555,
        "precision": 0.8264567057291667,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002995517936924187,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002995517936924187,
        "precision": 0.0019922053857600736,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7961286272321428,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.7961286272321428,
        "precision": 0.7787690662202382,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.7993815104166666,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.7993815104166666,
        "precision": 0.7800618489583333,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7773111979166667,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7773111979166667,
        "precision": 0.7569173177083334,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.837890625,
        "f1": 0.7974198598710318,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.7974198598710318,
        "precision": 0.780453636532738,
        "recall": 0.837890625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8664388020833333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8664388020833333,
        "precision": 0.8541666666666667,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7929578993055555,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7929578993055555,
        "precision": 0.7753824869791667,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8186686197916666,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8186686197916666,
        "precision": 0.8046642485119047,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8910342261904762,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8910342261904762,
        "precision": 0.8817057291666666,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6137362041170635,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6137362041170635,
        "precision": 0.5928369915674603,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8903645833333333,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8903645833333333,
        "precision": 0.8811360677083333,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0035867458939449364,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0035867458939449364,
        "precision": 0.0023410939646291208,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8858072916666666,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8858072916666666,
        "precision": 0.8744303385416667,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8477213541666666,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8477213541666666,
        "precision": 0.8338053385416666,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8503929501488094,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8503929501488094,
        "precision": 0.8375418526785714,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8707194010416666,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8707194010416666,
        "precision": 0.8598563058035713,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.818359375,
        "f1": 0.7785016741071429,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7785016741071429,
        "precision": 0.7620442708333334,
        "recall": 0.818359375
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8316080729166666,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8316080729166666,
        "precision": 0.817138671875,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9705403645833334,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9705403645833334,
        "precision": 0.9671223958333334,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6759803185096154,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.6759803185096154,
        "precision": 0.6538178943452381,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8888997395833333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.8888997395833333,
        "precision": 0.878173828125,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004271544750060375,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.004271544750060375,
        "precision": 0.0030113935814619405,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.951171875,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.951171875,
        "precision": 0.9454752604166667,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9597981770833333,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9597981770833333,
        "precision": 0.9549153645833334,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9384765625,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9384765625,
        "precision": 0.93115234375,
        "recall": 0.953125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8464704241071429,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8464704241071429,
        "precision": 0.8326009114583333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9219401041666667,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9219401041666667,
        "precision": 0.914306640625,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6469029017857143,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6469029017857143,
        "precision": 0.6242536272321428,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8790364583333333,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8790364583333333,
        "precision": 0.8688151041666667,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006692341946248196,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006692341946248196,
        "precision": 0.005290303253321256,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9166666666666666,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9166666666666666,
        "precision": 0.90869140625,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.88896484375,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.88896484375,
        "precision": 0.87841796875,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8955729166666666,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8955729166666666,
        "precision": 0.8851725260416667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.94677734375,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.94677734375,
        "precision": 0.94091796875,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8137090773809523,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8137090773809523,
        "precision": 0.7996303013392858,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7477918836805555,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7477918836805555,
        "precision": 0.7278006417410714,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9674479166666666,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9674479166666666,
        "precision": 0.96337890625,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004164758199791545,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004164758199791545,
        "precision": 0.0026766703161225647,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9284505208333333,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9284505208333333,
        "precision": 0.9204915364583334,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6744032118055556,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.6744032118055556,
        "precision": 0.6561402708619506,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005808221726190476,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005808221726190476,
        "precision": 0.004364912203111216,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6901692708333333,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.6901692708333333,
        "precision": 0.6697916666666667,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7130611359126984,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.7130611359126984,
        "precision": 0.6925374348958333,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7629115513392857,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7629115513392857,
        "precision": 0.7445731026785714,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6897382240155677,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.6897382240155677,
        "precision": 0.6695172991071427,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.745365978422619,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.745365978422619,
        "precision": 0.7270926339285715,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0031099142015906783,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031099142015906783,
        "precision": 0.001885243120594683,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.974609375,
        "precision": 0.9716796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9454752604166667,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9454752604166667,
        "precision": 0.9392903645833334,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.94580078125,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.94580078125,
        "precision": 0.93994140625,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9473307291666666,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9473307291666666,
        "precision": 0.9418131510416667,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.856640625,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.856640625,
        "precision": 0.8423665364583334,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022430673999768733,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0022430673999768733,
        "precision": 0.0021159911352826156,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005099138098569652,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.005099138098569652,
        "precision": 0.0049987488612389715,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004533497991405082,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004533497991405082,
        "precision": 0.0043059242277992274,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004574730282738095,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.004574730282738095,
        "precision": 0.004403329110360361,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003976950513371538,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.003976950513371538,
        "precision": 0.0036649155890804597,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9825846354166666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9825846354166666,
        "precision": 0.9807942708333334,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8881510416666666,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8881510416666666,
        "precision": 0.8768229166666666,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9069661458333332,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9069661458333332,
        "precision": 0.8973795572916666,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.89384765625,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.89384765625,
        "precision": 0.8831380208333333,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9020833333333333,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9020833333333333,
        "precision": 0.891845703125,
        "recall": 0.923828125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}