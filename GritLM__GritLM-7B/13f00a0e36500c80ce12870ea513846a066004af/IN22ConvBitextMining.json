{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 333.2541489601135,
  "kg_co2_emissions": 0.027355910267255795,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.19693945442448438,
        "f1": 0.16668937257759614,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.16668937257759614,
        "precision": 0.15607699944027287,
        "recall": 0.19693945442448438
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.5993731300118526,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.5993731300118526,
        "precision": 0.5824726208957746,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5184741295519738,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.5184741295519738,
        "precision": 0.4985457656116339,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.5116433799068529,
        "f1": 0.4515513945653666,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.4515513945653666,
        "precision": 0.4285690523714476,
        "recall": 0.5116433799068529
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0018548724364203378,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0018548724364203378,
        "precision": 0.0014060813812546494,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.5542248835662009,
        "f1": 0.4944840477774609,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.4944840477774609,
        "precision": 0.47103729049836834,
        "recall": 0.5542248835662009
      },
      {
        "accuracy": 0.3872255489021956,
        "f1": 0.3347859835883788,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.3347859835883788,
        "precision": 0.31565621301150243,
        "recall": 0.3872255489021956
      },
      {
        "accuracy": 0.6653359946773121,
        "f1": 0.6198471263341522,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6198471263341522,
        "precision": 0.6028728257770174,
        "recall": 0.6653359946773121
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.2206544582792088,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.2206544582792088,
        "precision": 0.20649549866116731,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.4597471723220226,
        "f1": 0.40472837393995076,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.40472837393995076,
        "precision": 0.3839638423969762,
        "recall": 0.4597471723220226
      },
      {
        "accuracy": 0.4031936127744511,
        "f1": 0.35374583278774896,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.35374583278774896,
        "precision": 0.33564854418147827,
        "recall": 0.4031936127744511
      },
      {
        "accuracy": 0.5163007318695941,
        "f1": 0.46490568646257274,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.46490568646257274,
        "precision": 0.44424618775916175,
        "recall": 0.5163007318695941
      },
      {
        "accuracy": 0.4138389886892881,
        "f1": 0.3640036227801873,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.3640036227801873,
        "precision": 0.34447443496844693,
        "recall": 0.4138389886892881
      },
      {
        "accuracy": 0.6174318030605456,
        "f1": 0.5696347232275375,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.5696347232275375,
        "precision": 0.551111005502223,
        "recall": 0.6174318030605456
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.393313421257533,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.393313421257533,
        "precision": 0.3731233540614778,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4693497084714649,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.4693497084714649,
        "precision": 0.44717417017816224,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0031713401936077153,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0031713401936077153,
        "precision": 0.0024906509990207477,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.4566666446847262,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.4566666446847262,
        "precision": 0.43882743430148613,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5676982494846766,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.5676982494846766,
        "precision": 0.5465373485832568,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5354973554574353,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.5354973554574353,
        "precision": 0.5156234742562088,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.5854956753160346,
        "f1": 0.5352892579439485,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.5352892579439485,
        "precision": 0.5155659580310279,
        "recall": 0.5854956753160346
      },
      {
        "accuracy": 0.49833666001330673,
        "f1": 0.44243998774936893,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.44243998774936893,
        "precision": 0.4200823842511056,
        "recall": 0.49833666001330673
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.22630374726183106,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22630374726183106,
        "precision": 0.2122883861905818,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.1996007984031936,
        "f1": 0.16346077535647882,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.16346077535647882,
        "precision": 0.1520728195011208,
        "recall": 0.1996007984031936
      },
      {
        "accuracy": 0.14703925482368596,
        "f1": 0.11090687659281076,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11090687659281076,
        "precision": 0.10046663646669517,
        "recall": 0.14703925482368596
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.00197394699694448,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00197394699694448,
        "precision": 0.0014757665419755873,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.16351384556815798,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16351384556815798,
        "precision": 0.152584009470237,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.14129090752098603,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14129090752098603,
        "precision": 0.12964452740107313,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.19176703388280236,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.19176703388280236,
        "precision": 0.17932610552434844,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.18829008649367932,
        "f1": 0.15006324041060162,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15006324041060162,
        "precision": 0.13875221207724392,
        "recall": 0.18829008649367932
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.1359335737080248,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1359335737080248,
        "precision": 0.12559842259854,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.24750499001996007,
        "f1": 0.21600544880580552,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21600544880580552,
        "precision": 0.20585644287154312,
        "recall": 0.24750499001996007
      },
      {
        "accuracy": 0.19760479041916168,
        "f1": 0.15989773705310373,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.15989773705310373,
        "precision": 0.14673303705239835,
        "recall": 0.19760479041916168
      },
      {
        "accuracy": 0.23020625415834997,
        "f1": 0.1979075180143631,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1979075180143631,
        "precision": 0.18692945998335223,
        "recall": 0.23020625415834997
      },
      {
        "accuracy": 0.24417831004657353,
        "f1": 0.20631691440074673,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.20631691440074673,
        "precision": 0.19455613808368563,
        "recall": 0.24417831004657353
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1430426784718202,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1430426784718202,
        "precision": 0.13200558959041991,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.24750499001996007,
        "f1": 0.20926898431301388,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20926898431301388,
        "precision": 0.19734987696564543,
        "recall": 0.24750499001996007
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002784655211071728,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002784655211071728,
        "precision": 0.0018948721581192487,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.22554890219560877,
        "f1": 0.19559762491588184,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.19559762491588184,
        "precision": 0.18607288749357553,
        "recall": 0.22554890219560877
      },
      {
        "accuracy": 0.2375249500998004,
        "f1": 0.2002591659924054,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2002591659924054,
        "precision": 0.18843056930132776,
        "recall": 0.2375249500998004
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.15574496029585846,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.15574496029585846,
        "precision": 0.14420725521944136,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.17455835360026978,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.17455835360026978,
        "precision": 0.16540252827677976,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.14101612282603243,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14101612282603243,
        "precision": 0.13053081948511716,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8709802616988247,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8709802616988247,
        "precision": 0.8621376295028989,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5957735323004784,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5957735323004784,
        "precision": 0.5759522469103308,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001211726992518351,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001211726992518351,
        "precision": 0.0009759825643801257,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.4870259481037924,
        "f1": 0.4342163464169452,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4342163464169452,
        "precision": 0.4155820021479195,
        "recall": 0.4870259481037924
      },
      {
        "accuracy": 0.5016633399866933,
        "f1": 0.44410640423027414,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.44410640423027414,
        "precision": 0.42391539482389745,
        "recall": 0.5016633399866933
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.934752716788645,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.934752716788645,
        "precision": 0.9300953648259038,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.39188290086493677,
        "f1": 0.33265625111932495,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.33265625111932495,
        "precision": 0.31269003268280576,
        "recall": 0.39188290086493677
      },
      {
        "accuracy": 0.6826347305389222,
        "f1": 0.6299909080348202,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6299909080348202,
        "precision": 0.609289909838812,
        "recall": 0.6826347305389222
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5685681546958993,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5685681546958993,
        "precision": 0.5485312443895278,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.7159015302727878,
        "f1": 0.6694916231842379,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6694916231842379,
        "precision": 0.6514083425261069,
        "recall": 0.7159015302727878
      },
      {
        "accuracy": 0.5489021956087824,
        "f1": 0.4922164998879989,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4922164998879989,
        "precision": 0.47092082938665636,
        "recall": 0.5489021956087824
      },
      {
        "accuracy": 0.844311377245509,
        "f1": 0.8159437738280054,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8159437738280054,
        "precision": 0.804601907296518,
        "recall": 0.844311377245509
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4461898713395719,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4461898713395719,
        "precision": 0.4256709665861949,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.7084333977547551,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7084333977547551,
        "precision": 0.6924917361045105,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0023496390359438457,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023496390359438457,
        "precision": 0.0017182786103278453,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.7438456420492349,
        "f1": 0.7013492777905129,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7013492777905129,
        "precision": 0.6845379347125854,
        "recall": 0.7438456420492349
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8482938884136488,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8482938884136488,
        "precision": 0.8368374362386338,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.7984031936127745,
        "f1": 0.7597281627221747,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7597281627221747,
        "precision": 0.7441783100465735,
        "recall": 0.7984031936127745
      },
      {
        "accuracy": 0.7638057218895542,
        "f1": 0.7239035637239231,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7239035637239231,
        "precision": 0.7080402686690113,
        "recall": 0.7638057218895542
      },
      {
        "accuracy": 0.6979374584165003,
        "f1": 0.6452902904000709,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6452902904000709,
        "precision": 0.6255198431346136,
        "recall": 0.6979374584165003
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.537322445056976,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.537322445056976,
        "precision": 0.5143178517272434,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0025834197111299787,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0025834197111299787,
        "precision": 0.0021226047734575672,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.47704590818363274,
        "f1": 0.42120075649858196,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.42120075649858196,
        "precision": 0.40100356996271047,
        "recall": 0.47704590818363274
      },
      {
        "accuracy": 0.46773120425815035,
        "f1": 0.4059595575563639,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4059595575563639,
        "precision": 0.383902315662325,
        "recall": 0.46773120425815035
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9120330767037353,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9120330767037353,
        "precision": 0.9055999112885341,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.49966733200266134,
        "f1": 0.44460332858536455,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.44460332858536455,
        "precision": 0.42463461475143993,
        "recall": 0.49966733200266134
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.634023487416701,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.634023487416701,
        "precision": 0.6110361288005999,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.5582168995342648,
        "f1": 0.4993324052889133,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.4993324052889133,
        "precision": 0.4776000908236437,
        "recall": 0.5582168995342648
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6379146468966829,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6379146468966829,
        "precision": 0.6172990072690671,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.4657351962741184,
        "f1": 0.4052977073935158,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.4052977073935158,
        "precision": 0.3833312451575925,
        "recall": 0.4657351962741184
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7873190127681146,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7873190127681146,
        "precision": 0.7730602287488515,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.3925637759411389,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.3925637759411389,
        "precision": 0.370871992586896,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.7238855622089155,
        "f1": 0.6725247916864683,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6725247916864683,
        "precision": 0.6525533182718811,
        "recall": 0.7238855622089155
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003258163605968944,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003258163605968944,
        "precision": 0.002589720687735185,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.7159015302727878,
        "f1": 0.6720517598761111,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.6720517598761111,
        "precision": 0.6553314246927022,
        "recall": 0.7159015302727878
      },
      {
        "accuracy": 0.846307385229541,
        "f1": 0.8156845040078573,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8156845040078573,
        "precision": 0.8027009473117258,
        "recall": 0.846307385229541
      },
      {
        "accuracy": 0.7764471057884231,
        "f1": 0.7357829794955544,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7357829794955544,
        "precision": 0.7187070303836771,
        "recall": 0.7764471057884231
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.680655091932537,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.680655091932537,
        "precision": 0.6613870143311261,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.6580172987358616,
        "f1": 0.5987485346766784,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5987485346766784,
        "precision": 0.575998003992016,
        "recall": 0.6580172987358616
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028964997694205944,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028964997694205944,
        "precision": 0.00259442721577276,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.4171656686626746,
        "f1": 0.356526332025334,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.356526332025334,
        "precision": 0.33513969951095696,
        "recall": 0.4171656686626746
      },
      {
        "accuracy": 0.3359946773120426,
        "f1": 0.28288456756520625,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.28288456756520625,
        "precision": 0.2652203976383204,
        "recall": 0.3359946773120426
      },
      {
        "accuracy": 0.6786427145708582,
        "f1": 0.6273400769408753,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6273400769408753,
        "precision": 0.6068220701454233,
        "recall": 0.6786427145708582
      },
      {
        "accuracy": 0.21490352628077178,
        "f1": 0.175876407373049,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.175876407373049,
        "precision": 0.16318810402848208,
        "recall": 0.21490352628077178
      },
      {
        "accuracy": 0.40252827677977376,
        "f1": 0.34747277930910664,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.34747277930910664,
        "precision": 0.32753199709287534,
        "recall": 0.40252827677977376
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.2729460559400679,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.2729460559400679,
        "precision": 0.2556139284682199,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.4564204923486361,
        "f1": 0.39697578388197147,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.39697578388197147,
        "precision": 0.3751908474463364,
        "recall": 0.4564204923486361
      },
      {
        "accuracy": 0.3047238855622089,
        "f1": 0.2557409139245466,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.2557409139245466,
        "precision": 0.2386832610855154,
        "recall": 0.3047238855622089
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.48264996259008236,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.48264996259008236,
        "precision": 0.4614108384538113,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.4324683965402528,
        "f1": 0.3725595613819167,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.3725595613819167,
        "precision": 0.3503007213087053,
        "recall": 0.4324683965402528
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.38477528292310487,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.38477528292310487,
        "precision": 0.3647938730523561,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0018401431611852874,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0018401431611852874,
        "precision": 0.001230719917813815,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.37192856691271625,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.37192856691271625,
        "precision": 0.3524455058137693,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.6094477711244178,
        "f1": 0.5501642218209085,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.5501642218209085,
        "precision": 0.5264101426776078,
        "recall": 0.6094477711244178
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.49830053697319165,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.49830053697319165,
        "precision": 0.47711011358715943,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.4312542598969744,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.4312542598969744,
        "precision": 0.41103192594915033,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.4258150365934797,
        "f1": 0.3724133743095819,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.3724133743095819,
        "precision": 0.352012905406119,
        "recall": 0.4258150365934797
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002946060585620176,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.002946060585620176,
        "precision": 0.00222710966305744,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0023993175205050347,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0023993175205050347,
        "precision": 0.0017467008591254187,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016516751263080107,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0016516751263080107,
        "precision": 0.0012875747337302566,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004120252499580799,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.004120252499580799,
        "precision": 0.003514591846443957,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0032268795741849637,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0032268795741849637,
        "precision": 0.0025476727536023576,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0019879423493248476,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0019879423493248476,
        "precision": 0.0017241153569701295,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0016849097823614678,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0016849097823614678,
        "precision": 0.0012607717214021847,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002590263498811529,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.002590263498811529,
        "precision": 0.0020715066219304163,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0038564977991601525,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0038564977991601525,
        "precision": 0.003421462481247687,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0036400760659811597,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0036400760659811597,
        "precision": 0.0032604709648851454,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0019584157138835016,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0019584157138835016,
        "precision": 0.001521224311467255,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0064113955727437555,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0064113955727437555,
        "precision": 0.0053092990608422826,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0017228464493026278,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0017228464493026278,
        "precision": 0.001556643009133569,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0012975400587092038,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0012975400587092038,
        "precision": 0.001025626283755214,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0028309902561399567,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0028309902561399567,
        "precision": 0.0022959519140435918,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015856007411468947,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0015856007411468947,
        "precision": 0.0012602201171818363,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018685573701302891,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0018685573701302891,
        "precision": 0.0017119491480628362,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.35662009314703924,
        "f1": 0.3051511977600976,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.3051511977600976,
        "precision": 0.2864785841552896,
        "recall": 0.35662009314703924
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.48640673476002816,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.48640673476002816,
        "precision": 0.4695863003372698,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.23619427811044577,
        "f1": 0.1979937911574638,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.1979937911574638,
        "precision": 0.1846574047671852,
        "recall": 0.23619427811044577
      },
      {
        "accuracy": 0.3978709248170326,
        "f1": 0.3449629988552144,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.3449629988552144,
        "precision": 0.32484660309011604,
        "recall": 0.3978709248170326
      },
      {
        "accuracy": 0.3320026613439787,
        "f1": 0.289530341027347,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.289530341027347,
        "precision": 0.2738894697377731,
        "recall": 0.3320026613439787
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3608111486354999,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.3608111486354999,
        "precision": 0.344167708538966,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.35728542914171657,
        "f1": 0.30989842382057947,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.30989842382057947,
        "precision": 0.2925294746652032,
        "recall": 0.35728542914171657
      },
      {
        "accuracy": 0.48835662009314706,
        "f1": 0.4398525699922905,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.4398525699922905,
        "precision": 0.42157433569609215,
        "recall": 0.48835662009314706
      },
      {
        "accuracy": 0.4411177644710579,
        "f1": 0.3883941592524426,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.3883941592524426,
        "precision": 0.36796750414514884,
        "recall": 0.4411177644710579
      },
      {
        "accuracy": 0.4251497005988024,
        "f1": 0.37644284819933527,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.37644284819933527,
        "precision": 0.35860923655334837,
        "recall": 0.4251497005988024
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0036367402232021875,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0036367402232021875,
        "precision": 0.0032914688962183015,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.40119760479041916,
        "f1": 0.36025559788034833,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.36025559788034833,
        "precision": 0.3453548650654439,
        "recall": 0.40119760479041916
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.44280222623536,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.44280222623536,
        "precision": 0.4226665716186674,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.46174318030605455,
        "f1": 0.40874812701160007,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.40874812701160007,
        "precision": 0.3889144178066334,
        "recall": 0.46174318030605455
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.3991292214845109,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.3991292214845109,
        "precision": 0.38219115659235414,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.4384564204923486,
        "f1": 0.3900802531541054,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.3900802531541054,
        "precision": 0.3719743053575389,
        "recall": 0.4384564204923486
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.4317055551087487,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.4317055551087487,
        "precision": 0.4084471582974577,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.14594258234182284,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.14594258234182284,
        "precision": 0.13515941440093135,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4455543938577871,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.4455543938577871,
        "precision": 0.4188321769160092,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.3040585495675316,
        "f1": 0.2535482426200989,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.2535482426200989,
        "precision": 0.23656950168926213,
        "recall": 0.3040585495675316
      },
      {
        "accuracy": 0.490352628077179,
        "f1": 0.4295361657637107,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.4295361657637107,
        "precision": 0.4071975097424199,
        "recall": 0.490352628077179
      },
      {
        "accuracy": 0.30671989354624085,
        "f1": 0.2544916850247365,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.2544916850247365,
        "precision": 0.23712484842724363,
        "recall": 0.30671989354624085
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4486994265437379,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.4486994265437379,
        "precision": 0.4236505824330176,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.3865602129075183,
        "f1": 0.3281986772006732,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.3281986772006732,
        "precision": 0.30595343704126143,
        "recall": 0.3865602129075183
      },
      {
        "accuracy": 0.4218230206254158,
        "f1": 0.35623255653195773,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.35623255653195773,
        "precision": 0.33339347316393225,
        "recall": 0.4218230206254158
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0039037433303699535,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0039037433303699535,
        "precision": 0.0030445921449628317,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.38456420492348636,
        "f1": 0.33106960802222457,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.33106960802222457,
        "precision": 0.31239946753918807,
        "recall": 0.38456420492348636
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.4951547122205805,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.4951547122205805,
        "precision": 0.4723220226214238,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.3457684173436878,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.3457684173436878,
        "precision": 0.32503087398296976,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.3814539419329839,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.3814539419329839,
        "precision": 0.3602865697177075,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.5163007318695941,
        "f1": 0.45439747286054666,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.45439747286054666,
        "precision": 0.4310817758422549,
        "recall": 0.5163007318695941
      },
      {
        "accuracy": 0.30073186959414505,
        "f1": 0.25727935797504936,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.25727935797504936,
        "precision": 0.24414842799417466,
        "recall": 0.30073186959414505
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.4765363244704562,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.4765363244704562,
        "precision": 0.4599042071540323,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.48170326014637393,
        "f1": 0.43299395115994116,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.43299395115994116,
        "precision": 0.4174547329225261,
        "recall": 0.48170326014637393
      },
      {
        "accuracy": 0.6646706586826348,
        "f1": 0.6184740710131106,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.6184740710131106,
        "precision": 0.6028049963322893,
        "recall": 0.6646706586826348
      },
      {
        "accuracy": 0.4471057884231537,
        "f1": 0.3948471689333373,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.3948471689333373,
        "precision": 0.37746384140674333,
        "recall": 0.4471057884231537
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7912444619031445,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.7912444619031445,
        "precision": 0.7793666875004202,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.41317365269461076,
        "f1": 0.3633081913160962,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.3633081913160962,
        "precision": 0.3486615367655123,
        "recall": 0.41317365269461076
      },
      {
        "accuracy": 0.6367265469061876,
        "f1": 0.5830771027601152,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.5830771027601152,
        "precision": 0.5637148269294895,
        "recall": 0.6367265469061876
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008099820885033515,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0008099820885033515,
        "precision": 0.0004672938016040247,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.6679973386560213,
        "f1": 0.6245657641490213,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.6245657641490213,
        "precision": 0.6092988604058569,
        "recall": 0.6679973386560213
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8339907486614074,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8339907486614074,
        "precision": 0.8223523851767364,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.812375249500998,
        "f1": 0.7776452386232826,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7776452386232826,
        "precision": 0.7643154675589805,
        "recall": 0.812375249500998
      },
      {
        "accuracy": 0.7105788423153693,
        "f1": 0.6663071286508623,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.6663071286508623,
        "precision": 0.6509151871397968,
        "recall": 0.7105788423153693
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5423402180900054,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.5423402180900054,
        "precision": 0.5251250903413683,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.2158280264867091,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.2158280264867091,
        "precision": 0.20099431506617133,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.3373253493013972,
        "f1": 0.28758231492762426,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.28758231492762426,
        "precision": 0.2704841879492578,
        "recall": 0.3373253493013972
      },
      {
        "accuracy": 0.3040585495675316,
        "f1": 0.25987265235610646,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.25987265235610646,
        "precision": 0.24429735880255896,
        "recall": 0.3040585495675316
      },
      {
        "accuracy": 0.2801064537591484,
        "f1": 0.23568349912328618,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.23568349912328618,
        "precision": 0.22015217043581364,
        "recall": 0.2801064537591484
      },
      {
        "accuracy": 0.36194278110445777,
        "f1": 0.3146414792857202,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3146414792857202,
        "precision": 0.298569912580697,
        "recall": 0.36194278110445777
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.1695402446555313,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.1695402446555313,
        "precision": 0.15682161806160946,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.36327345309381237,
        "f1": 0.3192805562662198,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3192805562662198,
        "precision": 0.3033107066290699,
        "recall": 0.36327345309381237
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.005667368965772159,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.005667368965772159,
        "precision": 0.004657883389469454,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.3466400532268796,
        "f1": 0.3066461391049995,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.3066461391049995,
        "precision": 0.2928317394884261,
        "recall": 0.3466400532268796
      },
      {
        "accuracy": 0.3685961410512309,
        "f1": 0.31643733013493497,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.31643733013493497,
        "precision": 0.29868189652087473,
        "recall": 0.3685961410512309
      },
      {
        "accuracy": 0.3193612774451098,
        "f1": 0.26867617117118114,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.26867617117118114,
        "precision": 0.25273464656524625,
        "recall": 0.3193612774451098
      },
      {
        "accuracy": 0.2994011976047904,
        "f1": 0.2525637577101213,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.2525637577101213,
        "precision": 0.2365966073550904,
        "recall": 0.2994011976047904
      },
      {
        "accuracy": 0.2554890219560878,
        "f1": 0.2060580955583005,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.2060580955583005,
        "precision": 0.1896874517882502,
        "recall": 0.2554890219560878
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.3650331611908458,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.3650331611908458,
        "precision": 0.3458371690407619,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.5063206919494344,
        "f1": 0.45325486592951664,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.45325486592951664,
        "precision": 0.43235228888627975,
        "recall": 0.5063206919494344
      },
      {
        "accuracy": 0.34930139720558884,
        "f1": 0.301991750394944,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.301991750394944,
        "precision": 0.2852730953205443,
        "recall": 0.34930139720558884
      },
      {
        "accuracy": 0.6387225548902196,
        "f1": 0.5865142730412192,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.5865142730412192,
        "precision": 0.5664311182275253,
        "recall": 0.6387225548902196
      },
      {
        "accuracy": 0.37192282102461743,
        "f1": 0.31560802857620984,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.31560802857620984,
        "precision": 0.2949582498077613,
        "recall": 0.37192282102461743
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5542671271214186,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.5542671271214186,
        "precision": 0.5322643313661277,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002574530708983453,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002574530708983453,
        "precision": 0.0018762137321072085,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.4717232202262142,
        "f1": 0.418945749478801,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.418945749478801,
        "precision": 0.39999422625092335,
        "recall": 0.4717232202262142
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5558187857090052,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.5558187857090052,
        "precision": 0.5334410543991382,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4681858172876137,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.4681858172876137,
        "precision": 0.44446532620185314,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.552228875582169,
        "f1": 0.4913010438958542,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.4913010438958542,
        "precision": 0.4681047956996061,
        "recall": 0.552228875582169
      },
      {
        "accuracy": 0.6433799068529608,
        "f1": 0.5857059330113222,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.5857059330113222,
        "precision": 0.5626054362581309,
        "recall": 0.6433799068529608
      },
      {
        "accuracy": 0.4244843646041251,
        "f1": 0.37464010448042384,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.37464010448042384,
        "precision": 0.35715135385794067,
        "recall": 0.4244843646041251
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3599423689926894,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3599423689926894,
        "precision": 0.34379133959678754,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4867951353486677,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4867951353486677,
        "precision": 0.47088156077677035,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.29740518962075846,
        "f1": 0.2536426454780351,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2536426454780351,
        "precision": 0.23879251616277564,
        "recall": 0.29740518962075846
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5077531952781454,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5077531952781454,
        "precision": 0.4885007356065241,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0023260668206071516,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023260668206071516,
        "precision": 0.001794240555523959,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5189620758483033,
        "f1": 0.47213750729592835,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.47213750729592835,
        "precision": 0.4552458343439076,
        "recall": 0.5189620758483033
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.47583855488047105,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.47583855488047105,
        "precision": 0.45640678719521033,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.45442448436460414,
        "f1": 0.4047570820650049,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.4047570820650049,
        "precision": 0.3868396804275048,
        "recall": 0.45442448436460414
      },
      {
        "accuracy": 0.4870259481037924,
        "f1": 0.4407558742572924,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4407558742572924,
        "precision": 0.4237722560576852,
        "recall": 0.4870259481037924
      },
      {
        "accuracy": 0.41583499667332,
        "f1": 0.36618489812102584,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.36618489812102584,
        "precision": 0.3482774291498948,
        "recall": 0.41583499667332
      },
      {
        "accuracy": 0.4278110445775116,
        "f1": 0.36738305495790524,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.36738305495790524,
        "precision": 0.34596960353867584,
        "recall": 0.4278110445775116
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6722168605402139,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.6722168605402139,
        "precision": 0.6528672813103951,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.37391882900864937,
        "f1": 0.3193533997866509,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.3193533997866509,
        "precision": 0.2993073857095813,
        "recall": 0.37391882900864937
      },
      {
        "accuracy": 0.5542248835662009,
        "f1": 0.4978942067764423,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.4978942067764423,
        "precision": 0.47706306962793993,
        "recall": 0.5542248835662009
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003894278057030008,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.003894278057030008,
        "precision": 0.0030785883531105765,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.6087824351297405,
        "f1": 0.5580273795842658,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.5580273795842658,
        "precision": 0.537387418525143,
        "recall": 0.6087824351297405
      },
      {
        "accuracy": 0.7844311377245509,
        "f1": 0.7430852580553178,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.7430852580553178,
        "precision": 0.7257374140607673,
        "recall": 0.7844311377245509
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.601492253588062,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.601492253588062,
        "precision": 0.5798160293170272,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.6260811709913506,
        "f1": 0.5758240133489634,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.5758240133489634,
        "precision": 0.5557583246206,
        "recall": 0.6260811709913506
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.4865690751918297,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.4865690751918297,
        "precision": 0.4651004462381707,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4749559082892416,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4749559082892416,
        "precision": 0.45624408488679946,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.2417138934105002,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2417138934105002,
        "precision": 0.22661969508276894,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.43221582882261517,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.43221582882261517,
        "precision": 0.41272032654268187,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004249367251614084,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004249367251614084,
        "precision": 0.0036312877500221117,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.45856410207120546,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.45856410207120546,
        "precision": 0.44123565039233703,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.48369926813040587,
        "f1": 0.4309179577114296,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4309179577114296,
        "precision": 0.41102987165861415,
        "recall": 0.48369926813040587
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.4300742312902203,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.4300742312902203,
        "precision": 0.40992802754279806,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.588174507535785,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.588174507535785,
        "precision": 0.5684944924964885,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.4031936127744511,
        "f1": 0.35143037385394776,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.35143037385394776,
        "precision": 0.33250958400659,
        "recall": 0.4031936127744511
      },
      {
        "accuracy": 0.4424484364604125,
        "f1": 0.3829477623573643,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3829477623573643,
        "precision": 0.3608090696913052,
        "recall": 0.4424484364604125
      },
      {
        "accuracy": 0.7059214903526281,
        "f1": 0.6558919678680157,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6558919678680157,
        "precision": 0.6356931639366769,
        "recall": 0.7059214903526281
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.00277440017454603,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00277440017454603,
        "precision": 0.0020705176393799145,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.7531603459747173,
        "f1": 0.7157531977891259,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7157531977891259,
        "precision": 0.7015774921463545,
        "recall": 0.7531603459747173
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7789817191014796,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7789817191014796,
        "precision": 0.7632180084275894,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7478091436175268,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7478091436175268,
        "precision": 0.7316050438804929,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.7478376580172987,
        "f1": 0.703186268156328,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.703186268156328,
        "precision": 0.684892120520863,
        "recall": 0.7478376580172987
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.576621936502176,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.576621936502176,
        "precision": 0.557425624940595,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.33623802456137786,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.33623802456137786,
        "precision": 0.3174804551551058,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003585921228436532,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.003585921228436532,
        "precision": 0.002796022390167433,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.3666001330671989,
        "f1": 0.32012826999520283,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.32012826999520283,
        "precision": 0.30335798103683387,
        "recall": 0.3666001330671989
      },
      {
        "accuracy": 0.49434464404524286,
        "f1": 0.4327652055196965,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.4327652055196965,
        "precision": 0.41030029887315317,
        "recall": 0.49434464404524286
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.38965778436836324,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.38965778436836324,
        "precision": 0.36973086793446075,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.4291417165668663,
        "f1": 0.37774357913491413,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.37774357913491413,
        "precision": 0.35927129627229426,
        "recall": 0.4291417165668663
      },
      {
        "accuracy": 0.44843646041250834,
        "f1": 0.39635121291807923,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.39635121291807923,
        "precision": 0.37712095261701933,
        "recall": 0.44843646041250834
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003797639213031339,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003797639213031339,
        "precision": 0.003125755309720712,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6446573705996038,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6446573705996038,
        "precision": 0.6291152063357651,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6388403088003887,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6388403088003887,
        "precision": 0.6199978350177952,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5619781600819526,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.5619781600819526,
        "precision": 0.540223281191345,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.626746506986028,
        "f1": 0.5764317924996567,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5764317924996567,
        "precision": 0.5564656401482748,
        "recall": 0.626746506986028
      },
      {
        "accuracy": 0.5302727877578177,
        "f1": 0.47706760600972176,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.47706760600972176,
        "precision": 0.45637352039547646,
        "recall": 0.5302727877578177
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004542851753617102,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004542851753617102,
        "precision": 0.0041033266431307214,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0021461455212484666,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0021461455212484666,
        "precision": 0.0017934309755401605,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0021173280215447607,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0021173280215447607,
        "precision": 0.0016309517026950086,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0032396037592502193,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0032396037592502193,
        "precision": 0.002602724905541073,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0041561399255478785,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0041561399255478785,
        "precision": 0.003791219609582883,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6912508796740334,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6912508796740334,
        "precision": 0.6746876617136097,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6402977594594361,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.6402977594594361,
        "precision": 0.6205792119464774,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.677977378576181,
        "f1": 0.6247894930529662,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6247894930529662,
        "precision": 0.6040049530568492,
        "recall": 0.677977378576181
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.5056378492506236,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5056378492506236,
        "precision": 0.485595171074213,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.7731204258150366,
        "f1": 0.7326637729831343,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7326637729831343,
        "precision": 0.715640940341539,
        "recall": 0.7731204258150366
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6763077020562049,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6763077020562049,
        "precision": 0.6578243224949811,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.6427145708582834,
        "f1": 0.5877483128980134,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5877483128980134,
        "precision": 0.5664488317182929,
        "recall": 0.6427145708582834
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.6703439681483593,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6703439681483593,
        "precision": 0.652613027912429,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.521963388674085,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.521963388674085,
        "precision": 0.49974118833605746,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.6007292293719438,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6007292293719438,
        "precision": 0.5802181351582548,
        "recall": 0.6520292747837658
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}