{
  "dataset_revision": "a4654f4896408912913a62ace89614879a549287",
  "evaluation_time": 90.40545439720154,
  "kg_co2_emissions": 0.006871981743592211,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.899560546875,
        "ap": 0.8597282332462648,
        "ap_weighted": 0.8597282332462648,
        "f1": 0.8988811900366729,
        "f1_weighted": 0.8991461208294063,
        "hf_subset": "default",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.899560546875,
        "scores_per_experiment": [
          {
            "accuracy": 0.91845703125,
            "ap": 0.8667875986884176,
            "ap_weighted": 0.8667875986884176,
            "f1": 0.9184546787777261,
            "f1_weighted": 0.9184726431114534
          },
          {
            "accuracy": 0.9296875,
            "ap": 0.897834921821962,
            "ap_weighted": 0.897834921821962,
            "f1": 0.9294986359294184,
            "f1_weighted": 0.9296483017966717
          },
          {
            "accuracy": 0.9248046875,
            "ap": 0.9034996695446732,
            "ap_weighted": 0.9034996695446732,
            "f1": 0.9242705391959123,
            "f1_weighted": 0.9245314023211644
          },
          {
            "accuracy": 0.89990234375,
            "ap": 0.8538443651208363,
            "ap_weighted": 0.8538443651208363,
            "f1": 0.8996864964080054,
            "f1_weighted": 0.8998773508998743
          },
          {
            "accuracy": 0.89599609375,
            "ap": 0.861926475051704,
            "ap_weighted": 0.861926475051704,
            "f1": 0.8952133990715774,
            "f1_weighted": 0.8955848473935407
          },
          {
            "accuracy": 0.865234375,
            "ap": 0.8324510909854427,
            "ap_weighted": 0.8324510909854427,
            "f1": 0.8630267642166727,
            "f1_weighted": 0.8637399923159015
          },
          {
            "accuracy": 0.87890625,
            "ap": 0.84144358576343,
            "ap_weighted": 0.84144358576343,
            "f1": 0.8777402905516785,
            "f1_weighted": 0.8782299935199736
          },
          {
            "accuracy": 0.8955078125,
            "ap": 0.8742891042529212,
            "ap_weighted": 0.8742891042529212,
            "f1": 0.8940032427454212,
            "f1_weighted": 0.8945212093822434
          },
          {
            "accuracy": 0.9052734375,
            "ap": 0.8548182987343433,
            "ap_weighted": 0.8548182987343433,
            "f1": 0.9052123294207463,
            "f1_weighted": 0.9053110424718485
          },
          {
            "accuracy": 0.8818359375,
            "ap": 0.8103872224989179,
            "ap_weighted": 0.8103872224989179,
            "f1": 0.8817055240495695,
            "f1_weighted": 0.8815444250813904
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.893212890625,
        "ap": 0.8546761008728051,
        "ap_weighted": 0.8546761008728051,
        "f1": 0.892764328175408,
        "f1_weighted": 0.8928575645439107,
        "hf_subset": "default",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.893212890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.9091796875,
            "ap": 0.8572687700878769,
            "ap_weighted": 0.8572687700878769,
            "f1": 0.909154649442376,
            "f1_weighted": 0.9091237200770758
          },
          {
            "accuracy": 0.91455078125,
            "ap": 0.8773551586500558,
            "ap_weighted": 0.8773551586500558,
            "f1": 0.914497759025389,
            "f1_weighted": 0.9145414243868333
          },
          {
            "accuracy": 0.912109375,
            "ap": 0.8874910840282472,
            "ap_weighted": 0.8874910840282472,
            "f1": 0.9117754332490593,
            "f1_weighted": 0.9118867471660395
          },
          {
            "accuracy": 0.8984375,
            "ap": 0.8550693191590287,
            "ap_weighted": 0.8550693191590287,
            "f1": 0.8983816793893129,
            "f1_weighted": 0.8984305224236642
          },
          {
            "accuracy": 0.8818359375,
            "ap": 0.8471011996956004,
            "ap_weighted": 0.8471011996956004,
            "f1": 0.8812969731226319,
            "f1_weighted": 0.8814610057592223
          },
          {
            "accuracy": 0.87353515625,
            "ap": 0.8490751079094447,
            "ap_weighted": 0.8490751079094447,
            "f1": 0.8721522511198657,
            "f1_weighted": 0.8724249366384838
          },
          {
            "accuracy": 0.865234375,
            "ap": 0.8264357416577084,
            "ap_weighted": 0.8264357416577084,
            "f1": 0.8645075367874426,
            "f1_weighted": 0.8647110514869587
          },
          {
            "accuracy": 0.89306640625,
            "ap": 0.8758472953535228,
            "ap_weighted": 0.8758472953535228,
            "f1": 0.8919841369040953,
            "f1_weighted": 0.8922058701359392
          },
          {
            "accuracy": 0.90380859375,
            "ap": 0.85753097968376,
            "ap_weighted": 0.85753097968376,
            "f1": 0.9038019654197708,
            "f1_weighted": 0.9038183412944547
          },
          {
            "accuracy": 0.88037109375,
            "ap": 0.8135863525028062,
            "ap_weighted": 0.8135863525028062,
            "f1": 0.880090897294135,
            "f1_weighted": 0.8799720260704348
          }
        ]
      }
    ]
  },
  "task_name": "MovieReviewSentimentClassification"
}