{
  "dataset_revision": "52483dba0ff23291271ee9249839865e3c3e7e50",
  "evaluation_time": 30.25859832763672,
  "kg_co2_emissions": 0.0021807538970755585,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.6579747935680139,
        "ap": 0.4951435348921108,
        "ap_weighted": 0.4951435348921108,
        "f1": 0.6472438738183336,
        "f1_weighted": 0.6567405216563008,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6579747935680139,
        "scores_per_experiment": [
          {
            "accuracy": 0.6418948283355063,
            "ap": 0.49430524015805594,
            "ap_weighted": 0.49430524015805594,
            "f1": 0.6418298184236177,
            "f1_weighted": 0.642985317180088
          },
          {
            "accuracy": 0.6484137331594959,
            "ap": 0.4498972910328843,
            "ap_weighted": 0.4498972910328843,
            "f1": 0.6030319553999015,
            "f1_weighted": 0.6351725203684575
          },
          {
            "accuracy": 0.6970882225119513,
            "ap": 0.4993566178356156,
            "ap_weighted": 0.4993566178356156,
            "f1": 0.6520305739813934,
            "f1_weighted": 0.6820145888851825
          },
          {
            "accuracy": 0.6714471968709257,
            "ap": 0.5032381383510176,
            "ap_weighted": 0.5032381383510176,
            "f1": 0.6658807097122152,
            "f1_weighted": 0.6762077616463885
          },
          {
            "accuracy": 0.6358105171664493,
            "ap": 0.4912781370241729,
            "ap_weighted": 0.4912781370241729,
            "f1": 0.6358104483813698,
            "f1_weighted": 0.6357725478024703
          },
          {
            "accuracy": 0.6201651455888744,
            "ap": 0.4781186583146262,
            "ap_weighted": 0.4781186583146262,
            "f1": 0.6201650738488271,
            "f1_weighted": 0.620204602614887
          },
          {
            "accuracy": 0.686657974793568,
            "ap": 0.5219166295983844,
            "ap_weighted": 0.5219166295983844,
            "f1": 0.6833267638943634,
            "f1_weighted": 0.6911042944259809
          },
          {
            "accuracy": 0.6814428509343764,
            "ap": 0.5113074561154886,
            "ap_weighted": 0.5113074561154886,
            "f1": 0.675079952154889,
            "f1_weighted": 0.6859680180787944
          },
          {
            "accuracy": 0.6053889613211647,
            "ap": 0.46998289506874097,
            "ap_weighted": 0.46998289506874097,
            "f1": 0.6051794930715342,
            "f1_weighted": 0.6030018137216017
          },
          {
            "accuracy": 0.691438504997827,
            "ap": 0.5320342854221219,
            "ap_weighted": 0.5320342854221219,
            "f1": 0.6901039493152243,
            "f1_weighted": 0.6949737518391585
          }
        ]
      }
    ]
  },
  "task_name": "FrenkEnClassification"
}