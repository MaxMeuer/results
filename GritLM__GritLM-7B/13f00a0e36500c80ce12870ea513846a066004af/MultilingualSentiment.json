{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 79.04653453826904,
  "kg_co2_emissions": 0.005882636814064985,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.6808333333333333,
        "f1": 0.6768896830726693,
        "f1_weighted": 0.6768896830726693,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.6808333333333333,
        "scores_per_experiment": [
          {
            "accuracy": 0.6686666666666666,
            "f1": 0.6673897084573852,
            "f1_weighted": 0.6673897084573852
          },
          {
            "accuracy": 0.6516666666666666,
            "f1": 0.641378346875865,
            "f1_weighted": 0.641378346875865
          },
          {
            "accuracy": 0.6953333333333334,
            "f1": 0.6873426026733913,
            "f1_weighted": 0.6873426026733914
          },
          {
            "accuracy": 0.673,
            "f1": 0.6707656126958073,
            "f1_weighted": 0.6707656126958074
          },
          {
            "accuracy": 0.696,
            "f1": 0.6892437489999136,
            "f1_weighted": 0.6892437489999137
          },
          {
            "accuracy": 0.6883333333333334,
            "f1": 0.6902827876777057,
            "f1_weighted": 0.6902827876777057
          },
          {
            "accuracy": 0.6903333333333334,
            "f1": 0.6804641999725741,
            "f1_weighted": 0.680464199972574
          },
          {
            "accuracy": 0.6723333333333333,
            "f1": 0.6733287760815111,
            "f1_weighted": 0.6733287760815111
          },
          {
            "accuracy": 0.6823333333333333,
            "f1": 0.6803641816351931,
            "f1_weighted": 0.6803641816351932
          },
          {
            "accuracy": 0.6903333333333334,
            "f1": 0.688336865657346,
            "f1_weighted": 0.688336865657346
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6812666666666668,
        "f1": 0.6777360167689757,
        "f1_weighted": 0.6777360167689757,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.6812666666666668,
        "scores_per_experiment": [
          {
            "accuracy": 0.673,
            "f1": 0.6726637674985416,
            "f1_weighted": 0.6726637674985416
          },
          {
            "accuracy": 0.6566666666666666,
            "f1": 0.6470273391281745,
            "f1_weighted": 0.6470273391281745
          },
          {
            "accuracy": 0.684,
            "f1": 0.6761558725052442,
            "f1_weighted": 0.6761558725052442
          },
          {
            "accuracy": 0.672,
            "f1": 0.6702622498205031,
            "f1_weighted": 0.6702622498205031
          },
          {
            "accuracy": 0.694,
            "f1": 0.6895880183838825,
            "f1_weighted": 0.6895880183838825
          },
          {
            "accuracy": 0.6936666666666667,
            "f1": 0.6957072687698694,
            "f1_weighted": 0.6957072687698694
          },
          {
            "accuracy": 0.683,
            "f1": 0.6743933850754557,
            "f1_weighted": 0.6743933850754557
          },
          {
            "accuracy": 0.6876666666666666,
            "f1": 0.6895051951962522,
            "f1_weighted": 0.6895051951962522
          },
          {
            "accuracy": 0.685,
            "f1": 0.6815417756207237,
            "f1_weighted": 0.6815417756207236
          },
          {
            "accuracy": 0.6836666666666666,
            "f1": 0.6805152956911109,
            "f1_weighted": 0.6805152956911109
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}