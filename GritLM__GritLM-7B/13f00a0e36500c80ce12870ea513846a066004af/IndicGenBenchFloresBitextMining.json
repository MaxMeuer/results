{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 1781.8327984809875,
  "kg_co2_emissions": 0.15457181215357851,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.9407114624505929,
        "f1": 0.9246565029173724,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9246565029173724,
        "precision": 0.9180171277997365,
        "recall": 0.9407114624505929
      },
      {
        "accuracy": 0.9061264822134387,
        "f1": 0.8788537549407114,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8788537549407114,
        "precision": 0.8663866930171278,
        "recall": 0.9061264822134387
      },
      {
        "accuracy": 0.6096837944664032,
        "f1": 0.5615958646096986,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.5615958646096986,
        "precision": 0.5482077447955946,
        "recall": 0.6096837944664032
      },
      {
        "accuracy": 0.6482213438735178,
        "f1": 0.5849548069409729,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.5849548069409729,
        "precision": 0.5623506022962546,
        "recall": 0.6482213438735178
      },
      {
        "accuracy": 0.9822134387351779,
        "f1": 0.9767786561264822,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9767786561264822,
        "precision": 0.974308300395257,
        "recall": 0.9822134387351779
      },
      {
        "accuracy": 0.958498023715415,
        "f1": 0.9464426877470355,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9464426877470355,
        "precision": 0.9410408432147563,
        "recall": 0.958498023715415
      },
      {
        "accuracy": 0.724308300395257,
        "f1": 0.6803075994441374,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6803075994441374,
        "precision": 0.666278007639755,
        "recall": 0.724308300395257
      },
      {
        "accuracy": 0.7539525691699605,
        "f1": 0.6972214379823076,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.6972214379823076,
        "precision": 0.6747898237028672,
        "recall": 0.7539525691699605
      },
      {
        "accuracy": 0.45652173913043476,
        "f1": 0.40641136535234945,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.40641136535234945,
        "precision": 0.39117765248674957,
        "recall": 0.45652173913043476
      },
      {
        "accuracy": 0.5345849802371542,
        "f1": 0.4727193206442218,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.4727193206442218,
        "precision": 0.45072268928668763,
        "recall": 0.5345849802371542
      },
      {
        "accuracy": 0.8883399209486166,
        "f1": 0.8644042058073679,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8644042058073679,
        "precision": 0.855033191446235,
        "recall": 0.8883399209486166
      },
      {
        "accuracy": 0.8656126482213439,
        "f1": 0.8310519794215446,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8310519794215446,
        "precision": 0.8166349049501224,
        "recall": 0.8656126482213439
      },
      {
        "accuracy": 0.6452569169960475,
        "f1": 0.5880415688071642,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5880415688071642,
        "precision": 0.569576272084157,
        "recall": 0.6452569169960475
      },
      {
        "accuracy": 0.6788537549407114,
        "f1": 0.6127823976638206,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.6127823976638206,
        "precision": 0.587946660278676,
        "recall": 0.6788537549407114
      },
      {
        "accuracy": 0.6679841897233202,
        "f1": 0.6234922384378906,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.6234922384378906,
        "precision": 0.608889167274003,
        "recall": 0.6679841897233202
      },
      {
        "accuracy": 0.6709486166007905,
        "f1": 0.6077131421499009,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.6077131421499009,
        "precision": 0.5835834455399673,
        "recall": 0.6709486166007905
      },
      {
        "accuracy": 0.9456521739130435,
        "f1": 0.9305194805194805,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9305194805194805,
        "precision": 0.92383069828722,
        "recall": 0.9456521739130435
      },
      {
        "accuracy": 0.8873517786561265,
        "f1": 0.8565240918501789,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.8565240918501789,
        "precision": 0.8436853002070394,
        "recall": 0.8873517786561265
      },
      {
        "accuracy": 0.6768774703557312,
        "f1": 0.6342913577967926,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6342913577967926,
        "precision": 0.6197793795383936,
        "recall": 0.6768774703557312
      },
      {
        "accuracy": 0.741106719367589,
        "f1": 0.6819852249200075,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.6819852249200075,
        "precision": 0.6591661961227178,
        "recall": 0.741106719367589
      },
      {
        "accuracy": 0.9041501976284585,
        "f1": 0.8864106907585169,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8864106907585169,
        "precision": 0.8795587866240041,
        "recall": 0.9041501976284585
      },
      {
        "accuracy": 0.8873517786561265,
        "f1": 0.8556653491436099,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.8556653491436099,
        "precision": 0.8417654808959157,
        "recall": 0.8873517786561265
      },
      {
        "accuracy": 0.9357707509881423,
        "f1": 0.9195181629964237,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9195181629964237,
        "precision": 0.9129117259552042,
        "recall": 0.9357707509881423
      },
      {
        "accuracy": 0.908102766798419,
        "f1": 0.8822134387351778,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.8822134387351778,
        "precision": 0.8707509881422926,
        "recall": 0.908102766798419
      },
      {
        "accuracy": 0.3606719367588933,
        "f1": 0.3199531283386676,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.3199531283386676,
        "precision": 0.3096805951598406,
        "recall": 0.3606719367588933
      },
      {
        "accuracy": 0.44565217391304346,
        "f1": 0.3673909696646447,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.3673909696646447,
        "precision": 0.3428336169288778,
        "recall": 0.44565217391304346
      },
      {
        "accuracy": 0.45948616600790515,
        "f1": 0.4195649333099926,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4195649333099926,
        "precision": 0.408488958361102,
        "recall": 0.45948616600790515
      },
      {
        "accuracy": 0.5810276679841897,
        "f1": 0.5079789281864381,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5079789281864381,
        "precision": 0.4814868404542318,
        "recall": 0.5810276679841897
      },
      {
        "accuracy": 0.6571146245059288,
        "f1": 0.6044360470447427,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6044360470447427,
        "precision": 0.5855291528926944,
        "recall": 0.6571146245059288
      },
      {
        "accuracy": 0.6324110671936759,
        "f1": 0.5537239632348328,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.5537239632348328,
        "precision": 0.523707608267885,
        "recall": 0.6324110671936759
      },
      {
        "accuracy": 0.8754940711462451,
        "f1": 0.8499071187161925,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8499071187161925,
        "precision": 0.8399376315384219,
        "recall": 0.8754940711462451
      },
      {
        "accuracy": 0.8843873517786561,
        "f1": 0.8514822134387352,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.8514822134387352,
        "precision": 0.836907114624506,
        "recall": 0.8843873517786561
      },
      {
        "accuracy": 0.9446640316205533,
        "f1": 0.9325301510084119,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9325301510084119,
        "precision": 0.9274374176548089,
        "recall": 0.9446640316205533
      },
      {
        "accuracy": 0.9229249011857708,
        "f1": 0.9009881422924901,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9009881422924901,
        "precision": 0.8909749670619236,
        "recall": 0.9229249011857708
      },
      {
        "accuracy": 0.9318181818181818,
        "f1": 0.9151170085952696,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9151170085952696,
        "precision": 0.9078905695753521,
        "recall": 0.9318181818181818
      },
      {
        "accuracy": 0.9169960474308301,
        "f1": 0.8921277997364954,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.8921277997364954,
        "precision": 0.8809617918313571,
        "recall": 0.9169960474308301
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.09321765414257094,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.09321765414257094,
        "precision": 0.08903238588692165,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.19960474308300397,
        "f1": 0.1476005536109667,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.1476005536109667,
        "precision": 0.13388514197555698,
        "recall": 0.19960474308300397
      },
      {
        "accuracy": 0.2618577075098814,
        "f1": 0.23038992724762142,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.23038992724762142,
        "precision": 0.22167616173660873,
        "recall": 0.2618577075098814
      },
      {
        "accuracy": 0.3349802371541502,
        "f1": 0.2683500321593207,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2683500321593207,
        "precision": 0.24991230352483548,
        "recall": 0.3349802371541502
      },
      {
        "accuracy": 0.9258893280632411,
        "f1": 0.9092693236714976,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9092693236714976,
        "precision": 0.9025609354413702,
        "recall": 0.9258893280632411
      },
      {
        "accuracy": 0.9071146245059288,
        "f1": 0.8802371541501975,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.8802371541501975,
        "precision": 0.8681159420289855,
        "recall": 0.9071146245059288
      },
      {
        "accuracy": 0.7282608695652174,
        "f1": 0.6870111834768157,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6870111834768157,
        "precision": 0.6724638679282947,
        "recall": 0.7282608695652174
      },
      {
        "accuracy": 0.7381422924901185,
        "f1": 0.6781079427818559,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6781079427818559,
        "precision": 0.6535603888864759,
        "recall": 0.7381422924901185
      },
      {
        "accuracy": 0.9041501976284585,
        "f1": 0.8836544795783926,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8836544795783926,
        "precision": 0.8755749191519941,
        "recall": 0.9041501976284585
      },
      {
        "accuracy": 0.8992094861660079,
        "f1": 0.8691370223978919,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.8691370223978919,
        "precision": 0.8556818181818181,
        "recall": 0.8992094861660079
      },
      {
        "accuracy": 0.9041501976284585,
        "f1": 0.8833003952569171,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8833003952569171,
        "precision": 0.874838276090639,
        "recall": 0.9041501976284585
      },
      {
        "accuracy": 0.8794466403162056,
        "f1": 0.8453580839450404,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.8453580839450404,
        "precision": 0.8303453792584228,
        "recall": 0.8794466403162056
      },
      {
        "accuracy": 0.9298418972332015,
        "f1": 0.914401540488497,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.914401540488497,
        "precision": 0.9080862977602108,
        "recall": 0.9298418972332015
      },
      {
        "accuracy": 0.91600790513834,
        "f1": 0.8903162055335968,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8903162055335968,
        "precision": 0.87832674571805,
        "recall": 0.91600790513834
      },
      {
        "accuracy": 0.33893280632411066,
        "f1": 0.3141803615465018,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.3141803615465018,
        "precision": 0.3066401064516008,
        "recall": 0.33893280632411066
      },
      {
        "accuracy": 0.4654150197628458,
        "f1": 0.39511383607493444,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.39511383607493444,
        "precision": 0.37156821562018033,
        "recall": 0.4654150197628458
      },
      {
        "accuracy": 0.9308300395256917,
        "f1": 0.9143524459729994,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9143524459729994,
        "precision": 0.9071247592986723,
        "recall": 0.9308300395256917
      },
      {
        "accuracy": 0.9071146245059288,
        "f1": 0.8814417466591379,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.8814417466591379,
        "precision": 0.8700428194993413,
        "recall": 0.9071146245059288
      },
      {
        "accuracy": 0.9298418972332015,
        "f1": 0.9147374364765669,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9147374364765669,
        "precision": 0.9085144927536232,
        "recall": 0.9298418972332015
      },
      {
        "accuracy": 0.8962450592885376,
        "f1": 0.8654479578392622,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.8654479578392622,
        "precision": 0.8511528326745718,
        "recall": 0.8962450592885376
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.010351966873706002,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.010351966873706002,
        "precision": 0.009957433870477348,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.006326977419689059,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.006326977419689059,
        "precision": 0.00427020310396577,
        "recall": 0.024703557312252964
      }
    ],
    "validation": [
      {
        "accuracy": 0.9478435305917753,
        "f1": 0.9334503510531595,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9334503510531595,
        "precision": 0.9271743802837082,
        "recall": 0.9478435305917753
      },
      {
        "accuracy": 0.8916750250752257,
        "f1": 0.862038496441706,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.862038496441706,
        "precision": 0.8489969909729188,
        "recall": 0.8916750250752257
      },
      {
        "accuracy": 0.6389167502507522,
        "f1": 0.5885077377050739,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.5885077377050739,
        "precision": 0.5719909729187562,
        "recall": 0.6389167502507522
      },
      {
        "accuracy": 0.6670010030090271,
        "f1": 0.604404555658317,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.604404555658317,
        "precision": 0.5816930539840649,
        "recall": 0.6670010030090271
      },
      {
        "accuracy": 0.9719157472417251,
        "f1": 0.9639585422935474,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9639585422935474,
        "precision": 0.9604647275158809,
        "recall": 0.9719157472417251
      },
      {
        "accuracy": 0.9438314944834504,
        "f1": 0.9261116683383483,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9261116683383483,
        "precision": 0.917753259779338,
        "recall": 0.9438314944834504
      },
      {
        "accuracy": 0.7432296890672017,
        "f1": 0.6993652424695553,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6993652424695553,
        "precision": 0.6838964512585376,
        "recall": 0.7432296890672017
      },
      {
        "accuracy": 0.7191574724172518,
        "f1": 0.6590904710790684,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.6590904710790684,
        "precision": 0.6357513015236185,
        "recall": 0.7191574724172518
      },
      {
        "accuracy": 0.4884653961885657,
        "f1": 0.43310982792252684,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.43310982792252684,
        "precision": 0.41610856395032453,
        "recall": 0.4884653961885657
      },
      {
        "accuracy": 0.5416248746238717,
        "f1": 0.4792806123999705,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.4792806123999705,
        "precision": 0.4574563247846255,
        "recall": 0.5416248746238717
      },
      {
        "accuracy": 0.8956870611835507,
        "f1": 0.8713585200044578,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8713585200044578,
        "precision": 0.8616926537187319,
        "recall": 0.8956870611835507
      },
      {
        "accuracy": 0.847542627883651,
        "f1": 0.8059392463103596,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8059392463103596,
        "precision": 0.7881238954960118,
        "recall": 0.847542627883651
      },
      {
        "accuracy": 0.633901705115346,
        "f1": 0.5824437022192053,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5824437022192053,
        "precision": 0.5672249975033324,
        "recall": 0.633901705115346
      },
      {
        "accuracy": 0.6529588766298897,
        "f1": 0.5831851476284776,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.5831851476284776,
        "precision": 0.5571727086019965,
        "recall": 0.6529588766298897
      },
      {
        "accuracy": 0.675025075225677,
        "f1": 0.6254976068917895,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.6254976068917895,
        "precision": 0.6088792357906303,
        "recall": 0.675025075225677
      },
      {
        "accuracy": 0.6870611835506519,
        "f1": 0.6217665623132023,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.6217665623132023,
        "precision": 0.5969113690277181,
        "recall": 0.6870611835506519
      },
      {
        "accuracy": 0.917753259779338,
        "f1": 0.8983139895878111,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8983139895878111,
        "precision": 0.8903591727563643,
        "recall": 0.917753259779338
      },
      {
        "accuracy": 0.8826479438314945,
        "f1": 0.8487462387161485,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.8487462387161485,
        "precision": 0.8336843864928118,
        "recall": 0.8826479438314945
      },
      {
        "accuracy": 0.7111334002006018,
        "f1": 0.6655032919827303,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6655032919827303,
        "precision": 0.6495625121175685,
        "recall": 0.7111334002006018
      },
      {
        "accuracy": 0.7191574724172518,
        "f1": 0.6606545827960071,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.6606545827960071,
        "precision": 0.6385425507291104,
        "recall": 0.7191574724172518
      },
      {
        "accuracy": 0.9007021063189569,
        "f1": 0.8802214947651256,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8802214947651256,
        "precision": 0.872444715097674,
        "recall": 0.9007021063189569
      },
      {
        "accuracy": 0.8565697091273822,
        "f1": 0.8188613459425897,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.8188613459425897,
        "precision": 0.803259779338014,
        "recall": 0.8565697091273822
      },
      {
        "accuracy": 0.9368104312938816,
        "f1": 0.9205807899890147,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9205807899890147,
        "precision": 0.9138582413908392,
        "recall": 0.9368104312938816
      },
      {
        "accuracy": 0.8886659979939819,
        "f1": 0.8577255576252568,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.8577255576252568,
        "precision": 0.8443162821798729,
        "recall": 0.8886659979939819
      },
      {
        "accuracy": 0.4062186559679037,
        "f1": 0.3604571999907953,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.3604571999907953,
        "precision": 0.34856385638139015,
        "recall": 0.4062186559679037
      },
      {
        "accuracy": 0.4563691073219659,
        "f1": 0.3877932860630955,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.3877932860630955,
        "precision": 0.3665691630335562,
        "recall": 0.4563691073219659
      },
      {
        "accuracy": 0.551654964894684,
        "f1": 0.49687653545679233,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.49687653545679233,
        "precision": 0.4806141499026035,
        "recall": 0.551654964894684
      },
      {
        "accuracy": 0.6028084252758275,
        "f1": 0.5367658531149002,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5367658531149002,
        "precision": 0.5136799036247381,
        "recall": 0.6028084252758275
      },
      {
        "accuracy": 0.6659979939819458,
        "f1": 0.616826823332115,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.616826823332115,
        "precision": 0.6002186282349352,
        "recall": 0.6659979939819458
      },
      {
        "accuracy": 0.6228686058174524,
        "f1": 0.552275875244782,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.552275875244782,
        "precision": 0.5262255019025329,
        "recall": 0.6228686058174524
      },
      {
        "accuracy": 0.8545636910732196,
        "f1": 0.8255058214937854,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8255058214937854,
        "precision": 0.8137517681248875,
        "recall": 0.8545636910732196
      },
      {
        "accuracy": 0.8184553660982948,
        "f1": 0.7730747798952413,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7730747798952413,
        "precision": 0.7542795051822133,
        "recall": 0.8184553660982948
      },
      {
        "accuracy": 0.9358074222668004,
        "f1": 0.9192131951409784,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9192131951409784,
        "precision": 0.9121782012704781,
        "recall": 0.9358074222668004
      },
      {
        "accuracy": 0.9037111334002006,
        "f1": 0.8788388976453169,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.8788388976453169,
        "precision": 0.8675789272579645,
        "recall": 0.9037111334002006
      },
      {
        "accuracy": 0.9297893681043129,
        "f1": 0.9130097362795457,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9130097362795457,
        "precision": 0.9063607489134069,
        "recall": 0.9297893681043129
      },
      {
        "accuracy": 0.8976930792377131,
        "f1": 0.8674356402540957,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.8674356402540957,
        "precision": 0.8535941156803745,
        "recall": 0.8976930792377131
      },
      {
        "accuracy": 0.10431293881644935,
        "f1": 0.0825447904709413,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.0825447904709413,
        "precision": 0.07855783021494712,
        "recall": 0.10431293881644935
      },
      {
        "accuracy": 0.20361083249749248,
        "f1": 0.14744362402336325,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.14744362402336325,
        "precision": 0.1333802679809741,
        "recall": 0.20361083249749248
      },
      {
        "accuracy": 0.3049147442326981,
        "f1": 0.26873535542063814,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.26873535542063814,
        "precision": 0.2586653034052355,
        "recall": 0.3049147442326981
      },
      {
        "accuracy": 0.33600802407221664,
        "f1": 0.2750453144284583,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2750453144284583,
        "precision": 0.25551681662602904,
        "recall": 0.33600802407221664
      },
      {
        "accuracy": 0.9157472417251755,
        "f1": 0.8956798968333572,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8956798968333572,
        "precision": 0.8873819259977735,
        "recall": 0.9157472417251755
      },
      {
        "accuracy": 0.8696088264794383,
        "f1": 0.8342073840569327,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.8342073840569327,
        "precision": 0.8186559679037112,
        "recall": 0.8696088264794383
      },
      {
        "accuracy": 0.7382146439317954,
        "f1": 0.6934844215185239,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6934844215185239,
        "precision": 0.6781746968262397,
        "recall": 0.7382146439317954
      },
      {
        "accuracy": 0.695085255767302,
        "f1": 0.6264683661373732,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6264683661373732,
        "precision": 0.5995267910513647,
        "recall": 0.695085255767302
      },
      {
        "accuracy": 0.9107321965897693,
        "f1": 0.8895575615736098,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8895575615736098,
        "precision": 0.8811374599990447,
        "recall": 0.9107321965897693
      },
      {
        "accuracy": 0.8575727181544633,
        "f1": 0.8201103309929789,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.8201103309929789,
        "precision": 0.8037039690500072,
        "recall": 0.8575727181544633
      },
      {
        "accuracy": 0.9037111334002006,
        "f1": 0.879806953327515,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.879806953327515,
        "precision": 0.8699041569151901,
        "recall": 0.9037111334002006
      },
      {
        "accuracy": 0.8515546639919759,
        "f1": 0.8115704255624014,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.8115704255624014,
        "precision": 0.7945542978140772,
        "recall": 0.8515546639919759
      },
      {
        "accuracy": 0.925777331995988,
        "f1": 0.9065251309484007,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9065251309484007,
        "precision": 0.8983295123465634,
        "recall": 0.925777331995988
      },
      {
        "accuracy": 0.8826479438314945,
        "f1": 0.8469408224674022,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8469408224674022,
        "precision": 0.8304413239719158,
        "recall": 0.8826479438314945
      },
      {
        "accuracy": 0.436308926780341,
        "f1": 0.38788755700942873,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.38788755700942873,
        "precision": 0.3746382495997721,
        "recall": 0.436308926780341
      },
      {
        "accuracy": 0.45336008024072216,
        "f1": 0.38430910632515447,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.38430910632515447,
        "precision": 0.3623547166231824,
        "recall": 0.45336008024072216
      },
      {
        "accuracy": 0.9267803410230692,
        "f1": 0.909744384669159,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.909744384669159,
        "precision": 0.902953304357517,
        "recall": 0.9267803410230692
      },
      {
        "accuracy": 0.880641925777332,
        "f1": 0.8476262119692409,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.8476262119692409,
        "precision": 0.833426469885848,
        "recall": 0.880641925777332
      },
      {
        "accuracy": 0.9247743229689067,
        "f1": 0.9049704669564248,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9049704669564248,
        "precision": 0.8967652958876631,
        "recall": 0.9247743229689067
      },
      {
        "accuracy": 0.8746238716148446,
        "f1": 0.8393012370444667,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.8393012370444667,
        "precision": 0.8236972823231599,
        "recall": 0.8746238716148446
      },
      {
        "accuracy": 0.009027081243731194,
        "f1": 0.0070485790842118035,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0070485790842118035,
        "precision": 0.007034919457211199,
        "recall": 0.009027081243731194
      },
      {
        "accuracy": 0.01805416248746239,
        "f1": 0.004216223538775105,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.004216223538775105,
        "precision": 0.0032630593165972857,
        "recall": 0.01805416248746239
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}