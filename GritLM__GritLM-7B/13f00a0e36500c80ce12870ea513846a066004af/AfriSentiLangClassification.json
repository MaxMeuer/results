{
  "dataset_revision": "f17cb5f3ec522ac604601fd09db9fd644ac66ca5",
  "evaluation_time": 50.61111378669739,
  "kg_co2_emissions": 0.003721090738385589,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.92724609375,
        "f1": 0.9216138794751044,
        "f1_weighted": 0.9269008841076823,
        "hf_subset": "default",
        "languages": [
          "amh-Ethi",
          "arq-Arab",
          "ary-Arab",
          "hau-Latn",
          "ibo-Latn",
          "kin-Latn",
          "por-Latn",
          "pcm-Latn",
          "swa-Latn",
          "twi-Latn",
          "tso-Latn",
          "yor-Latn"
        ],
        "main_score": 0.92724609375,
        "scores_per_experiment": [
          {
            "accuracy": 0.91943359375,
            "f1": 0.9138176664174069,
            "f1_weighted": 0.919546683905426
          },
          {
            "accuracy": 0.93115234375,
            "f1": 0.926174553081995,
            "f1_weighted": 0.9303948390280166
          },
          {
            "accuracy": 0.92626953125,
            "f1": 0.9207497879469315,
            "f1_weighted": 0.9255725639084146
          },
          {
            "accuracy": 0.9404296875,
            "f1": 0.9351625271324702,
            "f1_weighted": 0.9399592625584287
          },
          {
            "accuracy": 0.93310546875,
            "f1": 0.9289975595565901,
            "f1_weighted": 0.9324150874222821
          },
          {
            "accuracy": 0.91845703125,
            "f1": 0.9101811007446647,
            "f1_weighted": 0.9178818154756627
          },
          {
            "accuracy": 0.9296875,
            "f1": 0.9242759464367967,
            "f1_weighted": 0.929447423608292
          },
          {
            "accuracy": 0.9228515625,
            "f1": 0.917516126834876,
            "f1_weighted": 0.9223025739302203
          },
          {
            "accuracy": 0.92626953125,
            "f1": 0.9206031223740245,
            "f1_weighted": 0.9264762425624026
          },
          {
            "accuracy": 0.9248046875,
            "f1": 0.9186604042252894,
            "f1_weighted": 0.9250123486776781
          }
        ]
      }
    ]
  },
  "task_name": "AfriSentiLangClassification"
}