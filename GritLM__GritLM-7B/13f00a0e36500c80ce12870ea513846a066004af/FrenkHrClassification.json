{
  "dataset_revision": "e7fc9f3d8d6c5640a26679d8a50b1666b02cc41f",
  "evaluation_time": 22.99011540412903,
  "kg_co2_emissions": 0.001634000414640535,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.6128834355828221,
        "ap": 0.636649589465317,
        "ap_weighted": 0.636649589465317,
        "f1": 0.6084463835432811,
        "f1_weighted": 0.6098902531391394,
        "hf_subset": "default",
        "languages": [
          "hrv-Latn"
        ],
        "main_score": 0.6128834355828221,
        "scores_per_experiment": [
          {
            "accuracy": 0.5828220858895705,
            "ap": 0.6208775480722148,
            "ap_weighted": 0.6208775480722148,
            "f1": 0.5818721595728533,
            "f1_weighted": 0.5793985890649659
          },
          {
            "accuracy": 0.6484190655969797,
            "ap": 0.6600300376098815,
            "ap_weighted": 0.6600300376098815,
            "f1": 0.6480566317923584,
            "f1_weighted": 0.6494583978308203
          },
          {
            "accuracy": 0.662104766399245,
            "ap": 0.6495599586297554,
            "ap_weighted": 0.6495599586297554,
            "f1": 0.648492032012811,
            "f1_weighted": 0.6570775215658856
          },
          {
            "accuracy": 0.6427560169891459,
            "ap": 0.6594220808666083,
            "ap_weighted": 0.6594220808666083,
            "f1": 0.642744559764473,
            "f1_weighted": 0.6429956639385512
          },
          {
            "accuracy": 0.6021708352996696,
            "ap": 0.643040604870442,
            "ap_weighted": 0.643040604870442,
            "f1": 0.5980714905278932,
            "f1_weighted": 0.59303351073828
          },
          {
            "accuracy": 0.6488909863142992,
            "ap": 0.6537720594859702,
            "ap_weighted": 0.6537720594859702,
            "f1": 0.6465894927503744,
            "f1_weighted": 0.6501292167697442
          },
          {
            "accuracy": 0.4884379424256725,
            "ap": 0.5494629733158141,
            "ap_weighted": 0.5494629733158141,
            "f1": 0.47134729574223244,
            "f1_weighted": 0.4831447762612475
          },
          {
            "accuracy": 0.6446436998584237,
            "ap": 0.6588298644789303,
            "ap_weighted": 0.6588298644789303,
            "f1": 0.6445040400837982,
            "f1_weighted": 0.6453785762915722
          },
          {
            "accuracy": 0.6352052855120339,
            "ap": 0.6496577208012906,
            "ap_weighted": 0.6496577208012906,
            "f1": 0.6348067592944981,
            "f1_weighted": 0.6363040792260971
          },
          {
            "accuracy": 0.5733836715431807,
            "ap": 0.6218430465222632,
            "ap_weighted": 0.6218430465222632,
            "f1": 0.5679793738915181,
            "f1_weighted": 0.56198219970423
          }
        ]
      }
    ]
  },
  "task_name": "FrenkHrClassification"
}