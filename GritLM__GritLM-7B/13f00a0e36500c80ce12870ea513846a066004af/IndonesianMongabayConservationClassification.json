{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 46.039501905441284,
  "kg_co2_emissions": 0.0033145458570811833,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.2344933469805527,
        "f1": 0.23355591337128367,
        "f1_weighted": 0.23803804087591912,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.23355591337128367,
        "scores_per_experiment": [
          {
            "accuracy": 0.23132036847492324,
            "f1": 0.2346285041469707,
            "f1_weighted": 0.2352187954771069
          },
          {
            "accuracy": 0.218014329580348,
            "f1": 0.22587932599150573,
            "f1_weighted": 0.22560532090775465
          },
          {
            "accuracy": 0.2743091095189355,
            "f1": 0.2682875041656884,
            "f1_weighted": 0.26288909085721646
          },
          {
            "accuracy": 0.2241555783009212,
            "f1": 0.2120649982995703,
            "f1_weighted": 0.2195022423837997
          },
          {
            "accuracy": 0.3070624360286592,
            "f1": 0.3036560535648021,
            "f1_weighted": 0.3153447669877284
          },
          {
            "accuracy": 0.18730808597748208,
            "f1": 0.18959492663196367,
            "f1_weighted": 0.19646675781100892
          },
          {
            "accuracy": 0.2517911975435005,
            "f1": 0.25929334652453884,
            "f1_weighted": 0.26104376027754894
          },
          {
            "accuracy": 0.2128966223132037,
            "f1": 0.2181630055053884,
            "f1_weighted": 0.22132390948154343
          },
          {
            "accuracy": 0.2538382804503582,
            "f1": 0.23886043564911033,
            "f1_weighted": 0.2524430268586819
          },
          {
            "accuracy": 0.1842374616171955,
            "f1": 0.1851310332332984,
            "f1_weighted": 0.19054273771680177
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2432926829268293,
        "f1": 0.24041997312958605,
        "f1_weighted": 0.24844773998459155,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.24041997312958605,
        "scores_per_experiment": [
          {
            "accuracy": 0.23983739837398374,
            "f1": 0.2369835704295943,
            "f1_weighted": 0.24422218586374234
          },
          {
            "accuracy": 0.241869918699187,
            "f1": 0.2477815844013027,
            "f1_weighted": 0.2544177464995054
          },
          {
            "accuracy": 0.2926829268292683,
            "f1": 0.27716943860609183,
            "f1_weighted": 0.2744234383187143
          },
          {
            "accuracy": 0.22357723577235772,
            "f1": 0.21414390101920824,
            "f1_weighted": 0.21363323971997036
          },
          {
            "accuracy": 0.3008130081300813,
            "f1": 0.2996834094032736,
            "f1_weighted": 0.3157404566598529
          },
          {
            "accuracy": 0.20528455284552846,
            "f1": 0.20679710113198924,
            "f1_weighted": 0.21553213349385578
          },
          {
            "accuracy": 0.2764227642276423,
            "f1": 0.2833321543581659,
            "f1_weighted": 0.288641599189851
          },
          {
            "accuracy": 0.18902439024390244,
            "f1": 0.19172925183002185,
            "f1_weighted": 0.2042376280783437
          },
          {
            "accuracy": 0.2682926829268293,
            "f1": 0.25077496183083664,
            "f1_weighted": 0.27389506008884895
          },
          {
            "accuracy": 0.1951219512195122,
            "f1": 0.19580435828537646,
            "f1_weighted": 0.19973391193323065
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}