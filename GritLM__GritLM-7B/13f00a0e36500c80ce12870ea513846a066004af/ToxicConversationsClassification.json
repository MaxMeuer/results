{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 27.56035852432251,
  "kg_co2_emissions": 0.0019250130560489233,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.63896484375,
        "ap": 0.10684807308978347,
        "ap_weighted": 0.10684807308978347,
        "f1": 0.4846259538523321,
        "f1_weighted": 0.7178570154310535,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.63896484375,
        "scores_per_experiment": [
          {
            "accuracy": 0.68408203125,
            "ap": 0.10044132719949408,
            "ap_weighted": 0.10044132719949408,
            "f1": 0.49983825641548285,
            "f1_weighted": 0.7553782948826652
          },
          {
            "accuracy": 0.64697265625,
            "ap": 0.10777621573889626,
            "ap_weighted": 0.10777621573889626,
            "f1": 0.4912745244561716,
            "f1_weighted": 0.7281885396481929
          },
          {
            "accuracy": 0.7236328125,
            "ap": 0.12189882873398855,
            "ap_weighted": 0.12189882873398855,
            "f1": 0.5371296775471349,
            "f1_weighted": 0.7844615272846269
          },
          {
            "accuracy": 0.74951171875,
            "ap": 0.125615802744709,
            "ap_weighted": 0.125615802744709,
            "f1": 0.5513955481316474,
            "f1_weighted": 0.8023524020229331
          },
          {
            "accuracy": 0.44482421875,
            "ap": 0.09490167100892251,
            "ap_weighted": 0.09490167100892251,
            "f1": 0.37894951612451544,
            "f1_weighted": 0.5492163636902356
          },
          {
            "accuracy": 0.546875,
            "ap": 0.10414396098815114,
            "ap_weighted": 0.10414396098815114,
            "f1": 0.44079278770331665,
            "f1_weighted": 0.6458216374785208
          },
          {
            "accuracy": 0.69580078125,
            "ap": 0.09524951822836425,
            "ap_weighted": 0.09524951822836425,
            "f1": 0.49828377333146157,
            "f1_weighted": 0.7632793543832593
          },
          {
            "accuracy": 0.5966796875,
            "ap": 0.11161237192053163,
            "ap_weighted": 0.11161237192053163,
            "f1": 0.47107901072444736,
            "f1_weighted": 0.6880485164970452
          },
          {
            "accuracy": 0.658203125,
            "ap": 0.10654383373302896,
            "ap_weighted": 0.10654383373302896,
            "f1": 0.4951060221003815,
            "f1_weighted": 0.7366690851578921
          },
          {
            "accuracy": 0.64306640625,
            "ap": 0.10029720060174828,
            "ap_weighted": 0.10029720060174828,
            "f1": 0.4824104219887617,
            "f1_weighted": 0.7251544332651639
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}