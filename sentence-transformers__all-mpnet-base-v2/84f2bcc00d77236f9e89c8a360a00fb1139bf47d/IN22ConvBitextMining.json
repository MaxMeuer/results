{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 25.585864543914795,
  "kg_co2_emissions": 0.004094865740032054,
  "mteb_version": "1.12.66",
  "scores": {
    "test": [
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.09666866363473149,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.09666866363473149,
        "precision": 0.0848144407525645,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0030912691455450333,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0030912691455450333,
        "precision": 0.002474676338712971,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006166884478681936,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.006166884478681936,
        "precision": 0.005353009893928057,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.80355604747765e-05,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.80355604747765e-05,
        "precision": 1.4148926613386761e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005947610264075435,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.005947610264075435,
        "precision": 0.004620159808107904,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0031138789282077178,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0031138789282077178,
        "precision": 0.002464805219116686,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003509650380314911,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.003509650380314911,
        "precision": 0.0030430382857527453,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00036108398675757485,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.00036108398675757485,
        "precision": 0.00023614845607224485,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 5.1179691898254774e-05,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 5.1179691898254774e-05,
        "precision": 2.6613439787092483e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004941569851749492,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.004941569851749492,
        "precision": 0.004016155142473933,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001058629014121066,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.001058629014121066,
        "precision": 0.000917959096887274,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0061494994197747385,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0061494994197747385,
        "precision": 0.005281851200627459,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0030082691759338465,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0030082691759338465,
        "precision": 0.0022162025156037134,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0076180818028233985,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0076180818028233985,
        "precision": 0.006220898453147439,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016887300962511698,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0016887300962511698,
        "precision": 0.0015652176232151369,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0028749106467346338,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0028749106467346338,
        "precision": 0.0023985988410787844,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0039148119053525636,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0039148119053525636,
        "precision": 0.003423067056145726,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0026279907717033464,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0026279907717033464,
        "precision": 0.002352927005597235,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002137496167539529,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.002137496167539529,
        "precision": 0.0016871624711653841,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0021992051932171693,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0021992051932171693,
        "precision": 0.0021058201526533153,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0022662493942156837,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0022662493942156837,
        "precision": 0.0019426231815694375,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0001855359287222618,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0001855359287222618,
        "precision": 9.928832523789376e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.06802916469236003,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.06802916469236003,
        "precision": 0.05913015002348697,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0025495434503250733,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0025495434503250733,
        "precision": 0.00231537809827733,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003546835740379742,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.003546835740379742,
        "precision": 0.0031832645487057092,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007503878490248895,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.007503878490248895,
        "precision": 0.006068685476590939,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008746776599306834,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0008746776599306834,
        "precision": 0.0007821409322688831,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005165980138770625,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.005165980138770625,
        "precision": 0.004592627442298113,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010026565647270381,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0010026565647270381,
        "precision": 0.0008679092188520344,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.000998003992015968,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.000998003992015968,
        "precision": 0.0008871146595697493,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006606284540581963,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.006606284540581963,
        "precision": 0.005605046831977076,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006966226277603522,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0006966226277603522,
        "precision": 0.0006811217097774712,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.008227358397096702,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.008227358397096702,
        "precision": 0.007370279861141681,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001273040240515917,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.001273040240515917,
        "precision": 0.0008229911208305564,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006616397553364781,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.006616397553364781,
        "precision": 0.0053499204082961315,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006860940374558299,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0006860940374558299,
        "precision": 0.0006757767651886456,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.001118489147622988,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.001118489147622988,
        "precision": 0.0010028281311801229,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008044458307717018,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.008044458307717018,
        "precision": 0.007155394040002719,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007102945171865485,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0007102945171865485,
        "precision": 0.00042212967277472415,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0032027568311436216,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0032027568311436216,
        "precision": 0.0026672744505485723,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002415057658262377,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.002415057658262377,
        "precision": 0.002052627485783832,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0011088933244621866,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0011088933244621866,
        "precision": 0.000998003992015968,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0013807005181124723,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0013807005181124723,
        "precision": 0.0010658896877523865,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017357085524959067,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017357085524959067,
        "precision": 0.001589674839666085,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027549776783194002,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0027549776783194002,
        "precision": 0.0024965908831821866,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.06395098211465476,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06395098211465476,
        "precision": 0.059162489236551645,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028057991441085774,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0028057991441085774,
        "precision": 0.0025673732755912477,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.049810964869083915,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.049810964869083915,
        "precision": 0.046332025420906475,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.011771949496500395,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011771949496500395,
        "precision": 0.009530180247019949,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.06221237274629682,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06221237274629682,
        "precision": 0.05825830629644055,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012529724334463023,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0012529724334463023,
        "precision": 0.00107747297375428,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.023804227463484224,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.023804227463484224,
        "precision": 0.021591124944362477,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01928792727195921,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.01928792727195921,
        "precision": 0.017585199970429514,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.021847370621142056,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021847370621142056,
        "precision": 0.019847715034716943,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.020048937778994903,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.020048937778994903,
        "precision": 0.017336560790510165,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004203471010373334,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004203471010373334,
        "precision": 0.0034964694225562173,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019922852707283844,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.019922852707283844,
        "precision": 0.01805957463064302,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012657526562977243,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0012657526562977243,
        "precision": 0.0010435396670698662,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.027527813626842968,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.027527813626842968,
        "precision": 0.026329763152125298,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01849969675299053,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.01849969675299053,
        "precision": 0.016280167136577883,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024152225645660617,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024152225645660617,
        "precision": 0.0018183107404285861,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.057406399322566984,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.057406399322566984,
        "precision": 0.05363741750967299,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.01990739674083143,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01990739674083143,
        "precision": 0.018307644304566866,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.02640651245813802,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02640651245813802,
        "precision": 0.024385764196603047,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.029527530684041188,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.029527530684041188,
        "precision": 0.028072147563202993,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001513514159960398,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001513514159960398,
        "precision": 0.0012361991811027583,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026211790429221346,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026211790429221346,
        "precision": 0.002340790843873323,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.055312425771450506,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.055312425771450506,
        "precision": 0.05013267858062139,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003172823085291149,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003172823085291149,
        "precision": 0.0028070530636338455,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.07950111029170302,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07950111029170302,
        "precision": 0.07395263938354228,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.01375806587882436,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01375806587882436,
        "precision": 0.011729359788081055,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2170227771151311,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2170227771151311,
        "precision": 0.20023590385366832,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007693094220040329,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0007693094220040329,
        "precision": 0.000721000703048927,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.025974358691682665,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.025974358691682665,
        "precision": 0.02397122668159542,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.14437791084497673,
        "f1": 0.10536667319767784,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10536667319767784,
        "precision": 0.09374716545375228,
        "recall": 0.14437791084497673
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.019748646625285502,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.019748646625285502,
        "precision": 0.01808938685562796,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.09713905522288756,
        "f1": 0.07271119875910295,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07271119875910295,
        "precision": 0.06572773423072824,
        "recall": 0.09713905522288756
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0038006166344995863,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0038006166344995863,
        "precision": 0.0031357188700986663,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.14171656686626746,
        "f1": 0.10836423870356005,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.10836423870356005,
        "precision": 0.0976528424632217,
        "recall": 0.14171656686626746
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008986501581856018,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0008986501581856018,
        "precision": 0.0005529131277634272,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.023064786463356964,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.023064786463356964,
        "precision": 0.021454499406116198,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.032789631470597706,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.032789631470597706,
        "precision": 0.028352759452920432,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0037649133242599773,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037649133242599773,
        "precision": 0.002925713521459327,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.13409952581609266,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.13409952581609266,
        "precision": 0.12100362178626703,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019353544726527575,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.019353544726527575,
        "precision": 0.017620063637983407,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.029350236515905175,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.029350236515905175,
        "precision": 0.026749425349284456,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.03387751756666102,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03387751756666102,
        "precision": 0.03161379347134772,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.285224881911237e-05,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 3.285224881911237e-05,
        "precision": 1.657182158910343e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009973745006143263,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0009973745006143263,
        "precision": 0.0008560221604720841,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.004184153498824019,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.004184153498824019,
        "precision": 0.0028814897117840307,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005646223168195674,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.005646223168195674,
        "precision": 0.004775173642513317,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007804464205829736,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.007804464205829736,
        "precision": 0.006548492191181263,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0050154486304333935,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0050154486304333935,
        "precision": 0.0038891692986950744,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.006451027154898727,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.006451027154898727,
        "precision": 0.005025638277895904,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.867432017132616e-05,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 6.867432017132616e-05,
        "precision": 3.524023802587576e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005194594204482339,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.005194594204482339,
        "precision": 0.0038198406780919356,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002459778367298366,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.002459778367298366,
        "precision": 0.0019883200738595214,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004740928100306662,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.004740928100306662,
        "precision": 0.003907419494922222,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011755195171283615,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0011755195171283615,
        "precision": 0.0009495641208327625,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0001676141884815224,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0001676141884815224,
        "precision": 9.022455010876839e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0021353658532352786,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0021353658532352786,
        "precision": 0.0016896572755480536,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.143756217319236e-05,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 3.143756217319236e-05,
        "precision": 1.5863990227118375e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007214699280466852,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.007214699280466852,
        "precision": 0.005886292330252784,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013367224314457366,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0013367224314457366,
        "precision": 0.0011186286635388432,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0003424502030975719,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0003424502030975719,
        "precision": 0.00018204200961874023,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0037146819102848194,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.0037146819102848194,
        "precision": 0.002471051890580508,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003346497744635212,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.003346497744635212,
        "precision": 0.0023468930667593043,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.005025505267605103,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.005025505267605103,
        "precision": 0.003685541648657024,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004208036428277137,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.004208036428277137,
        "precision": 0.0033595456371373848,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0027372841879395905,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0027372841879395905,
        "precision": 0.002441527004267649,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0035141034211820634,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0035141034211820634,
        "precision": 0.0032242717025325724,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.05453155857998348,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05453155857998348,
        "precision": 0.05111591925461326,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.09660838533094022,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09660838533094022,
        "precision": 0.08943728704207746,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003303781220412555,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003303781220412555,
        "precision": 0.0031028908458455096,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.015502873423256623,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015502873423256623,
        "precision": 0.01338101031236363,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.12508316699933467,
        "f1": 0.10152535237365574,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.10152535237365574,
        "precision": 0.09449635896741684,
        "recall": 0.12508316699933467
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010534486582390774,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0010534486582390774,
        "precision": 0.0009160423115122412,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02194788361146098,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02194788361146098,
        "precision": 0.020491093911124515,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.05426882873831081,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05426882873831081,
        "precision": 0.048086894993082614,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.02299102695645278,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02299102695645278,
        "precision": 0.021207020369041155,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.18899819408801444,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18899819408801444,
        "precision": 0.17043003939211523,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0037597470779342076,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0037597470779342076,
        "precision": 0.0028162064943545455,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.07518296739853626,
        "f1": 0.053385100890090915,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.053385100890090915,
        "precision": 0.047122685845240736,
        "recall": 0.07518296739853626
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0005463648929357726,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0005463648929357726,
        "precision": 0.00034456085295938443,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.026034394483211137,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.026034394483211137,
        "precision": 0.025049075094650188,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.035263878577251835,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.035263878577251835,
        "precision": 0.030210340623724383,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0031062186057009247,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031062186057009247,
        "precision": 0.0022360788039645116,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09912353724141913,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.09912353724141913,
        "precision": 0.09079713348675425,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.018840230520241058,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.018840230520241058,
        "precision": 0.017319272308645658,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.03200851783686115,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.03200851783686115,
        "precision": 0.030200709691727654,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.030496944034574654,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.030496944034574654,
        "precision": 0.028457343626219357,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002124958149080118,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0002124958149080118,
        "precision": 0.00011453801245872956,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662326739154217,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0006662326739154217,
        "precision": 0.0006657846366157323,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0031172223454325916,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.0031172223454325916,
        "precision": 0.0027580244222709417,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00433946675279855,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.00433946675279855,
        "precision": 0.0042212257766586,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002357894729181688,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.002357894729181688,
        "precision": 0.0022065350701273804,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005842491820899968,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.005842491820899968,
        "precision": 0.0056952658151189885,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005412191038570655,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.005412191038570655,
        "precision": 0.005369265444463885,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.021222600863319424,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.021222600863319424,
        "precision": 0.018845025997387937,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.00809897423371243,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.00809897423371243,
        "precision": 0.00787517245187272,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.290531871433054e-05,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 8.290531871433054e-05,
        "precision": 4.3903192967910615e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.027252021530131978,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.027252021530131978,
        "precision": 0.025179193542466997,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007640826943398271,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0007640826943398271,
        "precision": 0.000717315369261477,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.028475165760272966,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.028475165760272966,
        "precision": 0.023982692518412247,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000751500002997009,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.000751500002997009,
        "precision": 0.0007111936147769672,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.023302700772950692,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.023302700772950692,
        "precision": 0.020564493481570252,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.036531170463306194,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.036531170463306194,
        "precision": 0.033687372340650494,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007912928459244109,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0007912928459244109,
        "precision": 0.0007326622072421466,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.025947820986005486,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.025947820986005486,
        "precision": 0.022601055843990265,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.00514289821706102,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.00514289821706102,
        "precision": 0.005011301091464191,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004664865671713127,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.004664865671713127,
        "precision": 0.003932468061208552,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.0499001996007984,
        "f1": 0.03899666704057921,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.03899666704057921,
        "precision": 0.03601183875634973,
        "recall": 0.0499001996007984
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00536798343050246,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.00536798343050246,
        "precision": 0.005156824160865548,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0010270541019287897,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010270541019287897,
        "precision": 0.0008541544322748125,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026833046707589073,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026833046707589073,
        "precision": 0.0024669116785279717,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05639279849613053,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05639279849613053,
        "precision": 0.05134143198351593,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.25482368596141053,
        "f1": 0.21020213061131224,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21020213061131224,
        "precision": 0.19488492951566802,
        "recall": 0.25482368596141053
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00179087291347255,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00179087291347255,
        "precision": 0.0016717036520036855,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.08996170933406859,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08996170933406859,
        "precision": 0.08357079943612761,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.011975836370176872,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011975836370176872,
        "precision": 0.009547643529679458,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015126655025044676,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0015126655025044676,
        "precision": 0.0012572806037323945,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02436374141879704,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02436374141879704,
        "precision": 0.022510743626892194,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.13003135697746476,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13003135697746476,
        "precision": 0.11670811815522394,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02257100460274369,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02257100460274369,
        "precision": 0.020532963875532297,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.06409017021540124,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06409017021540124,
        "precision": 0.05682294372120602,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.001836379869814963,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001836379869814963,
        "precision": 0.0014130089623125288,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.09358542775361312,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09358542775361312,
        "precision": 0.08244683896507185,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011968656963698729,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011968656963698729,
        "precision": 0.0009985979004161693,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02484120927202891,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02484120927202891,
        "precision": 0.02354201147450922,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.02917443246720238,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.02917443246720238,
        "precision": 0.02489646878556094,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0030278548242620093,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0030278548242620093,
        "precision": 0.002268478915185502,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.1579761955195299,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1579761955195299,
        "precision": 0.1445170505549747,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01928057928513158,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01928057928513158,
        "precision": 0.017362575461869832,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.027426413194168466,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.027426413194168466,
        "precision": 0.025514529812630738,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.06121091151031271,
        "f1": 0.04400196577149113,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.04400196577149113,
        "precision": 0.03977792326011853,
        "recall": 0.06121091151031271
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00010817446801094476,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.00010817446801094476,
        "precision": 5.5947790939683165e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000724107739326314,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.000724107739326314,
        "precision": 0.0006960370760681923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007637002193948236,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0007637002193948236,
        "precision": 0.0007158014564254716,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006765103022252499,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0006765103022252499,
        "precision": 0.0006709485751401919,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008708058908410085,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0008708058908410085,
        "precision": 0.0007760096272726185,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.022208858636004344,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.022208858636004344,
        "precision": 0.019556527616494637,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007163080163301712,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0007163080163301712,
        "precision": 0.000691302396037525,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013318290954323238,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0013318290954323238,
        "precision": 0.001331251045920923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.577096803360626e-05,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 3.577096803360626e-05,
        "precision": 1.8258813609289126e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.02427661181136143,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.02427661181136143,
        "precision": 0.02009483587104208,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02156398436338556,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.02156398436338556,
        "precision": 0.018176680586517068,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006995353316414498,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0006995353316414498,
        "precision": 0.0006828080533610649,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.015522808307482613,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.015522808307482613,
        "precision": 0.013137176567212569,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.008740316347857437,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.008740316347857437,
        "precision": 0.006991536376094739,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0007846132022179668,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0007846132022179668,
        "precision": 0.0007265913302494835,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.013515297447433176,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.013515297447433176,
        "precision": 0.01145903777192923,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000700647397409738,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.000700647397409738,
        "precision": 0.0006832622671533086,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0030850459680382817,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0030850459680382817,
        "precision": 0.002345126793200708,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03730266768804372,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.03730266768804372,
        "precision": 0.03207913783784997,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009007314651345738,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0009007314651345738,
        "precision": 0.0007996401520261513,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007128153708232987,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0007128153708232987,
        "precision": 0.0006894708036961347,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.022563104244186526,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.022563104244186526,
        "precision": 0.02110032397717896,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02660304272748056,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.02660304272748056,
        "precision": 0.02539309060855333,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002677759269117246,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.002677759269117246,
        "precision": 0.002669595646225001,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.019325402409487245,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.019325402409487245,
        "precision": 0.018618671747414262,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007907641507109238,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.007907641507109238,
        "precision": 0.006337998976087286,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.017947353218477635,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.017947353218477635,
        "precision": 0.016626819561999046,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0020226214238190285,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0020226214238190285,
        "precision": 0.0020095862696375955,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00083613065252466,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00083613065252466,
        "precision": 0.0005079182554020113,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.01497005988023952,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.01497005988023952,
        "precision": 0.014105123087159017,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0032084249255003284,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0032084249255003284,
        "precision": 0.003049456642271013,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012422097719564124,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012422097719564124,
        "precision": 0.001010525602503821,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016473571646365185,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0016473571646365185,
        "precision": 0.0012591606879446295,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007287013275037226,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0007287013275037226,
        "precision": 0.000453877910939835,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.02052614143751019,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02052614143751019,
        "precision": 0.019740310166980763,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0027612715788994813,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0027612715788994813,
        "precision": 0.002714139984678806,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0022062303059036978,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0022062303059036978,
        "precision": 0.0018845912883173757,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.02152684308372931,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.02152684308372931,
        "precision": 0.02066934281932366,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.011844174133049296,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.011844174133049296,
        "precision": 0.010979859725814852,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.020758483033932136,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.020758483033932136,
        "precision": 0.01961262659865454,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.09846972721224219,
        "f1": 0.07589556430462853,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.07589556430462853,
        "precision": 0.06948250764784364,
        "recall": 0.09846972721224219
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017246484946269601,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017246484946269601,
        "precision": 0.0015575828096190082,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0025432141084557186,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0025432141084557186,
        "precision": 0.0023847659783353867,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.016182417912291497,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.016182417912291497,
        "precision": 0.013465299194672856,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.1324018629407851,
        "f1": 0.09896109656588697,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09896109656588697,
        "precision": 0.08883580677825006,
        "recall": 0.1324018629407851
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00012090356192951101,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00012090356192951101,
        "precision": 6.249029578523899e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0665335994677312,
        "f1": 0.04831003866354218,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04831003866354218,
        "precision": 0.04359396399316559,
        "recall": 0.0665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0033291952680005845,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0033291952680005845,
        "precision": 0.002941634461573307,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.16633399866932802,
        "f1": 0.12524560026104922,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.12524560026104922,
        "precision": 0.11247198502687526,
        "recall": 0.16633399866932802
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.3592155151732626e-06,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 1.3592155151732626e-06,
        "precision": 6.803026530442864e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0027064951844146005,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0027064951844146005,
        "precision": 0.0021973366641067347,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0015743371408163073,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0015743371408163073,
        "precision": 0.0012897247791096458,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06886073679329273,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06886073679329273,
        "precision": 0.06135051325919588,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003089908069778837,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003089908069778837,
        "precision": 0.0025674866588627303,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.12749722370480854,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12749722370480854,
        "precision": 0.11442963039769427,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000921230323967145,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.000921230323967145,
        "precision": 0.0006826058955514009,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002178183315907867,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.002178183315907867,
        "precision": 0.0020990720795929655,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.055857272627527176,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.055857272627527176,
        "precision": 0.04993907234914296,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0021431837570726835,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0021431837570726835,
        "precision": 0.0018195366616172062,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05404287673433592,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05404287673433592,
        "precision": 0.04837727493372087,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009781679568115697,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009781679568115697,
        "precision": 0.0006616803023988653,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00042558889864279084,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.00042558889864279084,
        "precision": 0.0002499630368891846,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004523454214403578,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004523454214403578,
        "precision": 0.003650514929044826,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 8.480963351956474e-05,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 8.480963351956474e-05,
        "precision": 4.353633221982905e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662284641537404,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0006662284641537404,
        "precision": 0.0006657825289019278,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008704836672002643,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.008704836672002643,
        "precision": 0.008123246261100985,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.009213539128894648,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.009213539128894648,
        "precision": 0.008787315913120196,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004471787629251572,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.004471787629251572,
        "precision": 0.004010596884255507,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.012005618392843942,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.012005618392843942,
        "precision": 0.011658501179459263,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.024868200242770793,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.024868200242770793,
        "precision": 0.021928941798233865,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.009356031102012823,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.009356031102012823,
        "precision": 0.009003031119756573,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.02741511038446579,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.02741511038446579,
        "precision": 0.02381821791157833,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.010725627064378133,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.010725627064378133,
        "precision": 0.01009145190460486,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.221445428773891e-05,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 3.221445428773891e-05,
        "precision": 1.640643375783658e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0007185628742514971,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0007185628742514971,
        "precision": 0.0006930583277888668,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.010825764019376793,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.010825764019376793,
        "precision": 0.009078518475359468,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006973863949196918,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0006973863949196918,
        "precision": 0.0006816601794533123,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.015203470820497635,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.015203470820497635,
        "precision": 0.013038610754138603,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.03533099751630432,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.03533099751630432,
        "precision": 0.03323597422577421,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007176088512628649,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007176088512628649,
        "precision": 0.0006922065691483378,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006396731339528672,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.006396731339528672,
        "precision": 0.00517825003276008,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.010390767001725369,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.010390767001725369,
        "precision": 0.009909234204044418,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007055905704949081,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.007055905704949081,
        "precision": 0.005996740136630291,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.0658682634730539,
        "f1": 0.05061131537590384,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.05061131537590384,
        "precision": 0.04674889473087196,
        "recall": 0.0658682634730539
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.012050907930727241,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.012050907930727241,
        "precision": 0.011350316551299252,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0012992216444420905,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012992216444420905,
        "precision": 0.0010132749545573572,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014376961679865776,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0014376961679865776,
        "precision": 0.0011818291128184557,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.016974687224970968,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.016974687224970968,
        "precision": 0.014211625127293789,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.07390438496226918,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.07390438496226918,
        "precision": 0.06689726667597012,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0014522929842049228,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0014522929842049228,
        "precision": 0.0013941089341637492,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.24550898203592814,
        "f1": 0.19096309545411339,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19096309545411339,
        "precision": 0.17231538144711794,
        "recall": 0.24550898203592814
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004462699098596061,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004462699098596061,
        "precision": 0.004065987820044297,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06147046012315473,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06147046012315473,
        "precision": 0.053478995529105844,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0016313813138567122,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0016313813138567122,
        "precision": 0.0014981309128863079,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030341376356562474,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0030341376356562474,
        "precision": 0.0026233247790134018,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.07242495805370057,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.07242495805370057,
        "precision": 0.06350435864828133,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024673583830878993,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0024673583830878993,
        "precision": 0.002078580048050942,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004286492836117724,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004286492836117724,
        "precision": 0.0036545842864127345,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.07920245644796543,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07920245644796543,
        "precision": 0.06999715156228217,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007193665467364286,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007193665467364286,
        "precision": 0.0006926319843665503,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010002217786648925,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0010002217786648925,
        "precision": 0.0008882254041351539,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0552228875582169,
        "f1": 0.03608683583733484,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.03608683583733484,
        "precision": 0.031622012693203645,
        "recall": 0.0552228875582169
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002438454248235228,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002438454248235228,
        "precision": 0.0018396782048791189,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.04920557191016273,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04920557191016273,
        "precision": 0.043142814899301926,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.001711120152184438,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.001711120152184438,
        "precision": 0.0012793835532907475,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004586526246610408,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.004586526246610408,
        "precision": 0.00392279328514002,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0023272327266126444,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0023272327266126444,
        "precision": 0.0019637353422369596,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00030480954751630824,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.00030480954751630824,
        "precision": 0.00017703398781981195,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007043416080050002,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0007043416080050002,
        "precision": 0.0006853982730994634,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008126774271903369,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0008126774271903369,
        "precision": 0.0007435510553973866,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006759910814865954,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006759910814865954,
        "precision": 0.0006706802819397298,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008079232764912272,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0008079232764912272,
        "precision": 0.0007413170853616695,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000740230682093681,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.000740230682093681,
        "precision": 0.000704957991704066,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.02861659273435264,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.02861659273435264,
        "precision": 0.0243334586841817,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00067114526772727,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00067114526772727,
        "precision": 0.0006682485626237466,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.01974903208878881,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.01974903208878881,
        "precision": 0.016973575831221104,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006672842699179484,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006672842699179484,
        "precision": 0.0006663115606519122,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 4.608011231580015e-06,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 4.608011231580015e-06,
        "precision": 2.3084570207621488e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.012892581225509616,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.012892581225509616,
        "precision": 0.011264104654758385,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008182011414982093,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0008182011414982093,
        "precision": 0.0007492954800880649,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007362130426346821,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007362130426346821,
        "precision": 0.0007025295475633303,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04258150365934797,
        "f1": 0.02419536233524109,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.02419536233524109,
        "precision": 0.020630732764538723,
        "recall": 0.04258150365934797
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.021034353020380963,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.021034353020380963,
        "precision": 0.018395971527000992,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008367377991268518,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008367377991268518,
        "precision": 0.0007629237168186853,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03372414758064511,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.03372414758064511,
        "precision": 0.03089136822501423,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006717009582941679,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006717009582941679,
        "precision": 0.0006685280123048804,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.002425242047459623,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.002425242047459623,
        "precision": 0.0019485916346720746,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.01790026285376024,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.01790026285376024,
        "precision": 0.015541659875750314,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006664655973847438,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0006664655973847438,
        "precision": 0.0006659012758962392,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0009610408812005619,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0009610408812005619,
        "precision": 0.0008467912659529426,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004484509377911363,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004484509377911363,
        "precision": 0.004090671001109847,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.025856560088097013,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.025856560088097013,
        "precision": 0.022459314175881043,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.1370592149035263,
        "f1": 0.10139931776658323,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10139931776658323,
        "precision": 0.08993153663812346,
        "recall": 0.1370592149035263
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000735667162474656,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.000735667162474656,
        "precision": 0.0007012416702179621,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06520292747837658,
        "f1": 0.045225803677321694,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.045225803677321694,
        "precision": 0.03940930068674579,
        "recall": 0.06520292747837658
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002958688043496571,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.002958688043496571,
        "precision": 0.0026201405110254077,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.12375249500998003,
        "f1": 0.08883666049334712,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08883666049334712,
        "precision": 0.0789420871010888,
        "recall": 0.12375249500998003
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015760321831723332,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0015760321831723332,
        "precision": 0.0014657858737387114,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026349373762390867,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0026349373762390867,
        "precision": 0.002153850621914494,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.13375410351458256,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13375410351458256,
        "precision": 0.1198840008221246,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003398842736259856,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.003398842736259856,
        "precision": 0.003152656418165239,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.08172420034348352,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08172420034348352,
        "precision": 0.07302818605213814,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005029971162971969,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005029971162971969,
        "precision": 0.004077788776566404,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0013900965606797639,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0013900965606797639,
        "precision": 0.0013607191640805799,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006986459024773741,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0006986459024773741,
        "precision": 0.0004771891257540648,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.07252162341982701,
        "f1": 0.053783658668007606,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.053783658668007606,
        "precision": 0.04841998302577144,
        "recall": 0.07252162341982701
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004082640433791431,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004082640433791431,
        "precision": 0.0034418459426149056,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.04889647813212449,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04889647813212449,
        "precision": 0.04400523233484247,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.00477278728131481,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00477278728131481,
        "precision": 0.004477574548112911,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0034161835060038653,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0034161835060038653,
        "precision": 0.0028754872360862247,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005559432527002763,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.005559432527002763,
        "precision": 0.004568593632047267,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0003329581994626018,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0003329581994626018,
        "precision": 0.0002010717829714382,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000856344037014909,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.000856344037014909,
        "precision": 0.0007681517131752464,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008281977710261104,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0008281977710261104,
        "precision": 0.000752437757286316,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006749741282682537,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0006749741282682537,
        "precision": 0.0006701682344476794,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007966720878793243,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0007966720878793243,
        "precision": 0.0007349666433816016,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001504897600178659,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.001504897600178659,
        "precision": 0.0014246681240693217,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03366132084694774,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.03366132084694774,
        "precision": 0.028546795560106718,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007069183021913322,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0007069183021913322,
        "precision": 0.0006866600424737315,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.020245310245310247,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.020245310245310247,
        "precision": 0.017325730834941228,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006671688762053486,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0006671688762053486,
        "precision": 0.0006662536994975567,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.810960953535739e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 7.810960953535739e-05,
        "precision": 4.123240283760976e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.015928822583933414,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.015928822583933414,
        "precision": 0.014089556940900114,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008332318986364539,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0008332318986364539,
        "precision": 0.0007586219286712106,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.030777283377171647,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.030777283377171647,
        "precision": 0.02632795387824545,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007429278425329801,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007429278425329801,
        "precision": 0.0007063087882897703,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.02392992038898674,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.02392992038898674,
        "precision": 0.020876377569065754,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008510504793547548,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0008510504793547548,
        "precision": 0.0007648372804835259,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.020009025498047457,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.020009025498047457,
        "precision": 0.016819959195672883,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008085006636893265,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0008085006636893265,
        "precision": 0.0007396499978297116,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0020348285551436843,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0020348285551436843,
        "precision": 0.0017298764473197747,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.01721180054513388,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.01721180054513388,
        "precision": 0.01350009172783018,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013317181151324185,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0013317181151324185,
        "precision": 0.0013311954637800195,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00028327046134568346,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.00028327046134568346,
        "precision": 0.00016064919006606243,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008326300741470402,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0008326300741470402,
        "precision": 0.000760864380916695,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.013017077634900811,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.013017077634900811,
        "precision": 0.012260597751504282,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.011143360241969588,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.011143360241969588,
        "precision": 0.01059498133114384,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003935211991272005,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.003935211991272005,
        "precision": 0.003747714024153626,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.0208417703876698,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.0208417703876698,
        "precision": 0.020047292702719353,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03811804551250769,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.03811804551250769,
        "precision": 0.03348413651097369,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.012701850772581702,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.012701850772581702,
        "precision": 0.012118381747597287,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.012158487983623427,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.012158487983623427,
        "precision": 0.009925766552513059,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.015749852692589203,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.015749852692589203,
        "precision": 0.014528291088074746,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.277634202255548e-05,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 8.277634202255548e-05,
        "precision": 4.3838296876508e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.03296141697599651,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.03296141697599651,
        "precision": 0.031086460984605793,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007351315767848147,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0007351315767848147,
        "precision": 0.0007013745660681596,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.029721793324587735,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.029721793324587735,
        "precision": 0.025378359200946724,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007476720826865317,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0007476720826865317,
        "precision": 0.0007089535623089055,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.023133350534566985,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.023133350534566985,
        "precision": 0.02020907824700566,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007891363115859757,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0007891363115859757,
        "precision": 0.000732305151518237,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.033443446676615224,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.033443446676615224,
        "precision": 0.02857254553611582,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013539060556849631,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.013539060556849631,
        "precision": 0.013090238026370896,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.01057356954558678,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.01057356954558678,
        "precision": 0.009916259270620545,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.04287899342013572,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.04287899342013572,
        "precision": 0.03932955024294876,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.021780299624611,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.021780299624611,
        "precision": 0.020592967406719974,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0029333364679543683,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0029333364679543683,
        "precision": 0.002444277345565157,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00324993798008113,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00324993798008113,
        "precision": 0.0028082723442004885,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.02123342722791934,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02123342722791934,
        "precision": 0.01880496099081883,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03196924300970079,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03196924300970079,
        "precision": 0.02797135683862231,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001163744137330232,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.001163744137330232,
        "precision": 0.0010258494375499788,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.04191444697201476,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04191444697201476,
        "precision": 0.037527450955433694,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.00407166436358053,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.00407166436358053,
        "precision": 0.0035274202361081234,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.03562127986857303,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03562127986857303,
        "precision": 0.03238552575044799,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0018740297183410955,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0018740297183410955,
        "precision": 0.0016525390776887781,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003169949309249656,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.003169949309249656,
        "precision": 0.002805306494594585,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05149169231005558,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05149169231005558,
        "precision": 0.04570149109197947,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0031051722408578534,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0031051722408578534,
        "precision": 0.0029215511945626937,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.04198587691601663,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04198587691601663,
        "precision": 0.037903593166400885,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0034287216833455915,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0034287216833455915,
        "precision": 0.0028984056240169355,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05218693229513693,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.05218693229513693,
        "precision": 0.04654091438561714,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002025142768256393,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002025142768256393,
        "precision": 0.002010716803106611,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006799723496522309,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0006799723496522309,
        "precision": 0.0006726950140123792,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020503204934342657,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020503204934342657,
        "precision": 0.0017842668417431297,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.029117265893712996,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.029117265893712996,
        "precision": 0.026303751041334703,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0033984820499694374,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0033984820499694374,
        "precision": 0.003147145356126122,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003716772803599151,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003716772803599151,
        "precision": 0.003048491943085325,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003168528842697746,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.003168528842697746,
        "precision": 0.0029763607607918986,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.348986283262364e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 8.348986283262364e-05,
        "precision": 4.419772728869461e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.0039531728228636e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 2.0039531728228636e-05,
        "precision": 1.015791547683679e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.85287246530086e-05,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 6.85287246530086e-05,
        "precision": 3.542703459744838e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006758199492738622,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0006758199492738622,
        "precision": 0.0006705940598217963,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008157549425198259,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0008157549425198259,
        "precision": 0.0005746146969950932,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007363863678693973,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0007363863678693973,
        "precision": 0.0007028069955649911,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.024023195676297196,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.024023195676297196,
        "precision": 0.020570372332014676,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007241347391403049,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0007241347391403049,
        "precision": 0.0006958510476009914,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006885653168495832,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.006885653168495832,
        "precision": 0.005914118245889716,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0011114771535677298,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0011114771535677298,
        "precision": 0.000999298420021177,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.760939999801822e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 8.760939999801822e-05,
        "precision": 4.6580896339020474e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0043061682258117755,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0043061682258117755,
        "precision": 0.0034921902850128337,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.7455715388985e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 8.7455715388985e-05,
        "precision": 4.5776330147885535e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03029813389094826,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.03029813389094826,
        "precision": 0.025880754124267102,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.724078856484114e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 8.724078856484114e-05,
        "precision": 4.639611548304161e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.0166243192176986,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0166243192176986,
        "precision": 0.015114878223319628,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.024565737973516258,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.024565737973516258,
        "precision": 0.021940809537675122,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.784841712601834e-05,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 8.784841712601834e-05,
        "precision": 4.577780606080519e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.0495422705701793e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 3.0495422705701793e-05,
        "precision": 1.5481029436936144e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0027555890944026694,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0027555890944026694,
        "precision": 0.0021169949771623485,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014633952057417982,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.014633952057417982,
        "precision": 0.01261553953025848,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.2648973282838632e-06,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.2648973282838632e-06,
        "precision": 6.330504230992503e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00145508101461491,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00145508101461491,
        "precision": 0.0011134822201808417,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0011088933244621866,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011088933244621866,
        "precision": 0.000998003992015968,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.05737903202386001,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05737903202386001,
        "precision": 0.05395811311479974,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.1394856271103776,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1394856271103776,
        "precision": 0.1266221525203561,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002003842049570609,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.002003842049570609,
        "precision": 0.001999936923078854,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.09503740511724543,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.09503740511724543,
        "precision": 0.08707021304652128,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.013125732661660805,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.013125732661660805,
        "precision": 0.011338510894238152,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.20625415834996674,
        "f1": 0.1666533952587233,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1666533952587233,
        "precision": 0.15438635715581822,
        "recall": 0.20625415834996674
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.026874152190186785,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.026874152190186785,
        "precision": 0.02450475858454116,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.05190576038879432,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05190576038879432,
        "precision": 0.04569062932336385,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.023919191808413367,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.023919191808413367,
        "precision": 0.021925273876210717,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.0825016633399867,
        "f1": 0.0566683789921525,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0566683789921525,
        "precision": 0.04979039035925264,
        "recall": 0.0825016633399867
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003233809912816614,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003233809912816614,
        "precision": 0.0023535820774676394,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04729540438123272,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04729540438123272,
        "precision": 0.04267364741416638,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008194772946928336,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0008194772946928336,
        "precision": 0.000514538510151908,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.028564009827712816,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.028564009827712816,
        "precision": 0.027647285691286765,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.027535941884696345,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.027535941884696345,
        "precision": 0.0238432013634805,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001766584576961414,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001766584576961414,
        "precision": 0.0013744059065670243,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01719965630746959,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01719965630746959,
        "precision": 0.015575778679898764,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02911786138274338,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02911786138274338,
        "precision": 0.02708486276693991,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.03483401954317267,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03483401954317267,
        "precision": 0.03274019995045376,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011189741728663885,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0011189741728663885,
        "precision": 0.000925421883505716,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014603455677490081,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.014603455677490081,
        "precision": 0.01357770746377779,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.010524208563292326,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.010524208563292326,
        "precision": 0.009494241220321983,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003947269774828007,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.003947269774828007,
        "precision": 0.003708063558121507,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.01611282125905054,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.01611282125905054,
        "precision": 0.015404878747824284,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.016258553325824474,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.016258553325824474,
        "precision": 0.01433394327766873,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.011724746754686873,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.011724746754686873,
        "precision": 0.011120325103952052,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003078659954531677,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.003078659954531677,
        "precision": 0.0028974256881016463,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.008471944998891106,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.008471944998891106,
        "precision": 0.007950765136393879,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014718500281854462,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0014718500281854462,
        "precision": 0.0012142931118894287,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.02459421300686139,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.02459421300686139,
        "precision": 0.023235238310765436,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010733644743322393,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0010733644743322393,
        "precision": 0.0008957382428236591,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0017544895639471998,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0017544895639471998,
        "precision": 0.0011397643355253652,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009874431032115664,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0009874431032115664,
        "precision": 0.0008475350411239112,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0036792087466857326,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0036792087466857326,
        "precision": 0.0029724101580389005,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022695610344256715,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.022695610344256715,
        "precision": 0.021883217691600926,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027617604297577687,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0027617604297577687,
        "precision": 0.0024617903739501657,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0038346587248782858,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0038346587248782858,
        "precision": 0.003373210007001248,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014560734809367974,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.014560734809367974,
        "precision": 0.013552869840294992,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.0317200297261228,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.0317200297261228,
        "precision": 0.029513920561824752,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.009916873778778817,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.009916873778778817,
        "precision": 0.009227997745699185,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001043293479266091,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0001043293479266091,
        "precision": 5.411795740330642e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 8.948702013144749e-07,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 8.948702013144749e-07,
        "precision": 4.4773620099415346e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.009301087685199964,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.009301087685199964,
        "precision": 0.008588469104543873,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.00865980247540842,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.00865980247540842,
        "precision": 0.008321939102899328,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004740697195873812,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.004740697195873812,
        "precision": 0.004510899264256449,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.011119175789834472,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.011119175789834472,
        "precision": 0.010993516842284425,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.03608456973568854,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.03608456973568854,
        "precision": 0.032073349877741096,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008474067694698769,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.008474067694698769,
        "precision": 0.008007667193211372,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.037383993465231274,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.037383993465231274,
        "precision": 0.0320848172194575,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.01128960889923617,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.01128960889923617,
        "precision": 0.010335423646554013,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2842310968334106e-05,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 3.2842310968334106e-05,
        "precision": 1.6733218131861726e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.06919494344644045,
        "f1": 0.050799789479855924,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.050799789479855924,
        "precision": 0.046390169820253964,
        "recall": 0.06919494344644045
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.013144180730982526,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.013144180730982526,
        "precision": 0.01099882771082219,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2642851198480865e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 3.2642851198480865e-05,
        "precision": 1.6633235389429172e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.015724256466761677,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.015724256466761677,
        "precision": 0.013448307229331255,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.04119500974497546,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04119500974497546,
        "precision": 0.03899517002403078,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 3.582675569826216e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 3.582675569826216e-05,
        "precision": 1.8066052936333827e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.013504541453880584,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.013504541453880584,
        "precision": 0.011554255283422847,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.012058530871363922,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.012058530871363922,
        "precision": 0.01168622232418148,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007420170395161022,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.007420170395161022,
        "precision": 0.006216025989220203,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.01276984109184876,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.01276984109184876,
        "precision": 0.011854537197175882,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002141017111076991,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0002141017111076991,
        "precision": 0.00011937068432253534,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012189977466432991,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0012189977466432991,
        "precision": 0.000998940466078652,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022662097618947205,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.022662097618947205,
        "precision": 0.021283596633808716,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.028691836677709356,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.028691836677709356,
        "precision": 0.026308418459477765,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00233656833789901,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00233656833789901,
        "precision": 0.002221744780970802,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.027816362946934313,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.027816362946934313,
        "precision": 0.026262936433758884,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.008350559293802141,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.008350559293802141,
        "precision": 0.006745796943662083,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.032513452218385974,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.032513452218385974,
        "precision": 0.030163505284701072,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00071285999429712,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.00071285999429712,
        "precision": 0.0006899780685542495,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.06875124647379495,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.06875124647379495,
        "precision": 0.06227710424317211,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0026049533505210385,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0026049533505210385,
        "precision": 0.00213530582498529,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.018797325982954725,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.018797325982954725,
        "precision": 0.01732091372809936,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026112012609605657,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0026112012609605657,
        "precision": 0.002181394786185205,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0020934107223276456,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0020934107223276456,
        "precision": 0.0017836392536751487,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015246050452809405,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0015246050452809405,
        "precision": 0.0014331747336326413,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000393526864531005,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.000393526864531005,
        "precision": 0.00025288224719862903,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.025934011042637414,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.025934011042637414,
        "precision": 0.02460295333758933,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002442190424332267,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002442190424332267,
        "precision": 0.0022618667784977163,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00042916553033573894,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00042916553033573894,
        "precision": 0.00027128631970473933,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.028488999013467315,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.028488999013467315,
        "precision": 0.026685781875402634,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014590734029315882,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.014590734029315882,
        "precision": 0.013573133910111163,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.023884516274735836,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.023884516274735836,
        "precision": 0.022665557759679437,
        "recall": 0.028609447771124417
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}